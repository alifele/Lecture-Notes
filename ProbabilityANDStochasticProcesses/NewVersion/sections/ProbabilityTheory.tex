\chapter{Probability Theory}

%\section[Fundamental Concepts]{\hyperlink{toc}{Fundamental Concepts}}
\section{Foundamentals}

The main concept in the field of statistics and probability is the set theory. Basically all we deal with the sets. The whole theroy of statistics can be built on that. Let's discuss some foundamental concepts in statistics and then build the theory.

\subsection{Random Experiment}
To understand the meaning of random experiment, do not over think! The first thing that comes into our minds when we hear the word "random experiment" is its definition! In a nutshell, random experiment is an experiment that its outcome is unkown to us. Like:

\begin{itemize}
	\item Tossing two coin
	\item Rolling a dice
	\item Measuring the number of possible ReadWrite operations on a piece of EEPROM chip
\end{itemize}

Do not overthink about that. Yes we can go further and discuss stuff like "we can compute the exact movement of dice or coin so it is not random but determenistic" and etc. Here I will not touch the philosophical topics that are very deep and do not necessarily converge the a unified point of view!

The random experiments can be modeled and despite the fact that a random experiment is random, we can deduce many useful information from modeling that. To model a random experiment, we use three important concepts: sample space, events, probability. In the following section, we will discuss each of them in detail.


\subsection{Sample Space}

\begin{definition}[Sample Space]
	
	Sample space $\Omega$ is simply a set that contains \emph{all possible outcomes} of a random experiment/
	
\end{definition}

For each of random experiments described above, we can define a sample space. For example:

\begin{itemize}
	\item $\Omega$ of Tossing Tow Coins: $$\Omega = \{ HH,HT,TH,TT \}$$
	\item $\Omega$ of Rolling a Dice: $$\Omega = \{ 1,2,3,4,5,6 \}$$
	\item $\Omega$ of Rolling Two Dices: $$\Omega = \{ (1,1),(1,2), \ldots, (1,6), \ldots ,(6,6)  \}$$
	\item $\Omega$ of Number of possible ReadWrite operations on a EEPROM chip: $$\Omega = \mathbb{N}$$
\end{itemize}



\subsection{Events}
\begin{definition}[Events]
	Event $E$ is a set of outcomes of a random experiment and is the subset of sample space $\Omega$. 
	$$E \in \Omega$$
\end{definition}


For example for any of the sample spaces specified above, we can define so many possible events. In fact any set that is a subset of the sample space is a valid event of that sample space. For example:

\begin{itemize}
	
	\item Tossing Three Coins
	\begin{itemize}
		\item There are at least on Heads: $$E = \{ HHH,HHT,HTH,THH,HTT,THT,TTH \}$$
		\item There are only two Tails: $$E = \{ TTH,THT,HTT \}$$
	\end{itemize}
	
	\item Rolling Two Dices
	\begin{itemize}
		\item The sum of two dices is 4: $$E = \{ (1,3),(2,2),(3,1) \}$$
		\item there are at least one prime number in the outcome:
		$$E = \{ (1,2),(1,3),(1,5),(2,1),(3,1),(5,1),(2,2),(2,3),(2,5), \ldots ,(5,5)\}$$
	\end{itemize}
	
\end{itemize}

Since we have define everything on the basics of set theory, then now we can correspond the everyday concepts to specific operations in the set theory.

\begin{example}{The Mapping Between Everyday Language and Sets in the Theory of Probability}
	
	\begin{itemize}
		\item At least one of two events $A,B \in \Omega$ happens: $E = A \cup B$.
		\item Tow events $A,B \in \Omega$ occures at the same time: $E = A \cap B$.
		\item Event $A \in \Omega$ does not happen: $E = \overline{A} = \Omega - A$.
		\item The event $A$ happens but $B$ does not happen: $E = A - B$.
		
	\end{itemize}
	
\end{example}



In probability and statistics, we are dealing with three important concepts: sample space $\Omega$, event $E$, and probability $P$.


\begin{definition}[Disjoint events]
	
	If two events has no common elements (i.e. $A \cap B = \varnothing$) then we say that two events are \emph{disjoint}. Basically, if two sets in the venn diagram has nothing is common they are considerent to be disjoint sets.
	
	
	For example for the random experiment of tossing two coins, the events 1) both coins are heads: $A = \{HH\}$ and 2) both coins are tails: $B = \{TT\}$. Two events $A,B$  are two disjoint events. \textbf{Two events being  disjoing is NOT the same as being independent}. We will talk about independet events in future.
	
\end{definition}

Note that since the events are basically sets, we can use theorems of set theory to solve the problems. 

\begin{theorem}[De Morgan's Laws]
	
	If $A,B$ are two sets then:
	
	$$\overline{A \cap B} = \overline{A} \cup \overline{B}$$
	
	$$\overline{A \cup B} = \overline{A} \cap \overline{B}$$
	
\end{theorem}

\begin{proof}
	the proof is left as an excerise!
\end{proof}


\subsection{Probability}

The last foundamental ingeridient in modeling a random experiment, is to define a probability for each event. The probability should intuitively reflect how likely an event is probable to happen. This probability should satisfy some foundamental properties which are explained as follows.

\begin{definition}[Axioms of probability (Kolmogorov axioms)]
	
	Suppose that $A, B \in \Omega$ is an event and $\mathbb{P}$ is a probability function. Then $\prob$ should satisfy the following properites:
	
	\begin{enumerate}[(I)]
		\item $ 0 \leq \prob(A) \leq 1$
		\item $\prob(\Omega) = 1$
		\item For the events $E_1, E_2, ..., E_n \in \Omega$ that are mutually exclusive (i.e. disjoint events): $$\prob(\bigcup_{i} E_i) = \sum_i \prob(E_i).$$
		The last property is known as the countable additivity of the probability measure.
	\end{enumerate}
	
\end{definition}
\begin{remark}
	Note that we do not require the uncountable additivity property. That is because every set $ \Omega $ can be written as a disjoint union of singletons $ \Omega = \cup_{x\in\Omega}\set{x} $ and this leads to contradiction when $ \Omega $ a continuous set (like the interval $ [0,1] $). We will see more about this later.
\end{remark}

These axioms are called the foundamental axioms of probability and also the Kolmogorov axioms. We are free to define any kind of probabilty function that we want but it is important that 1) It should align with our common sense, 2) It should satisfy the Kolmogorov axioms. 

Using the axioms above, we can observe and prove several interesting properties of the probability function. In the following box we have expressed some of them.

\begin{theorem}[Basic Properties of the Probability Function]
	
	Suppose that $\prob$ is a probability function and $A,B \in \Omega$ are events of the sample space $\Omega$. We can show that the probability function has the following properties:
	
	\begin{enumerate}
		
		\item $\prob(\varnothing) = 0$
		
		\item If $A \subset B$ then $\prob(A) \leq \prob(B)$.
		
		\item $\prob(\overline{A}) = 1 - \prob(A)$.
		
		\item $\prob(A \cup B) = \prob(A) + \prob(B) - \prob(A \cap B)$.
		
	\end{enumerate}
	
\end{theorem}


\begin{proof}
	The properties can be proved using the basic set theory theorems.
	
	\begin{enumerate}
		
		\item Since $\emptyset$ is the complement of $\Omega$, so these two sets are disjoint (i.e. $\emptyset \cap \Omega = \emptyset$). On the other hand from the set theory we know that $\emptyset \cup \Omega = \Omega$. So $\prob(\emptyset \cup \Omega) = \prob(\Omega)$. On the other hand, using the third axiom we can write: $\prob(\emptyset \cup \Omega) = \prob(\emptyset) + \prob(\Omega)$. Comparing the two recent equations we can conclude that $\prob(\emptyset) = 0$.
		
		
		
	\end{enumerate}
	
	
	
	The proofs for 2,3,4 are left as a exercise. However, the solutions can be found in the book "Statistical Modeling and Computation by Kroese" chapter 1. 
	
	
\end{proof}



\begin{example}[Defining a simple probability function]
	
	Let's define a probability function for the rolling n dice experiment that is both aligned with our common sense and also satisfy the Kolmogorov equations. Suppose that the $\Omega$ is the sample space and $E \in \Omega$ is an event. Then let's define:
	
	$$\prob(E) = \frac{\lvert E \rvert}{\lvert \Omega \rvert}$$
	
	in which the $\lvert E \rvert$ means the cardinality (number of elements) of the set $E$.
	
\end{example}

Utilizing the properties of the probability function, we can derive some very important notions, one of which is reflected in the following proposition.

\begin{proposition}[Conditional expansion - Law of total probabilities]
	Let $(\Omega, \mathcal{F}, \prob)$ be a probability space. Let $\mathfrak{F}$ be a finite collection of events $\mathfrak{F} = \set{F_1,F_2,\cdots, F_n}$ that partitions $\Omega$. I.e.
	\begin{enumerate}[(i)]
		\item $F_i \cap F_j = \emptyset \qquad i\neq j$,
		\item $\bigcap_{i} F_i = \Omega$.
	\end{enumerate}
	Let $E \in \mathcal{F}$ be any nonempty event. Then we can write
	\[  \prob(E) = \sum_{i} \prob(E|F_i)\prob(F_i). \]
\end{proposition}
\begin{proof}
	Since $\mathfrak{F}$ partitions $\Omega$ and $E \neq \emptyset$, then $\set{E\cap F_i}_i$ is a partition of $E$. Thus
	\[ \prob(E) = \prob(\bigcup_i (E \cap F_i)) = \sum_i \prob(E \cap F_i) = \sum_i \prob(E|F_i)\prob(F_i). \]
	This completes the proof.
\end{proof}


In dealing with random variables, either continuous or discrete, using the notion of the law of total probabilities helps us to simplify some of the calculations significantly. The following examples are some places that we use this idea to simplify calculations by a lot. 

\begin{example}
	Let $ X_1, X_2, X_3, \cdots $ be i.i.d. real-valued random variable. Let $ T $ be a positive integer valued random variable. Define the the real-valued random variable $ N $ as 
	\[ N = \sum_{i=1}^{T} X_i. \]
	What is the probability generating function for $ N $.
	
	\begin{solution}
		For the generating probability function we have
		\[ G_N(s) = \E{s^N} = \E{s^{X_1+X_2+\cdots+X_T}}. \]
		The problem in evaluating the expression above is that the number of random variables $ X_i $ to be summed up is also a random variable. So the first step is to make this a non-random variable buy conditional expansion.
		\[ G_N(s) = \E{s^N} = \sum_{i\in\N}\E{s^{X_1+\cdots+X_T}\big|T=i}\prob(T=i) = \sum_{i\in\N}\E{s^{X_1+\cdots+X_i}}\prob(T=i) \]
		Since $ X_i $ are all i.i.d., then we can write
		\[ G_N(s) = \sum_{i\in\N}(\E{s^{X_1}})^n\prob(T=i) = G_T(G_{X_1}(s)). \]
	\end{solution}
\end{example}

\begin{example}
	Let $ X,Y $ be two independent random variables. Define $ Z = X+Y $. Find the PDF of $ Z $. 
	\begin{solution}
		First, We need to find $ F_Z(z) = \prob(Z<z) $. For this we can write
		\[ F_Z(z) = \prob(X+Y < z) \]
		Again, we can use conditional expansion to write
		\[ F_Z(z) = \int_{\R} \prob(X+Y<z\big| Y = y)f_Y(y)\ dy = \int_{\R} \prob(X<z-y)f_Y(y)\ dy  = \int_{\R} F_X(z-y)f_Y(y)\ dy. \]
		Then differentiating $ F_z $ with respect to $ z $ we will get the PDF 
		\[ f_Z(z) = \frac{d }{dz}F_Z(z) =  \int_{\R} f_X(z-y)f_Y(y)\ dy = (f_X * f_Y)(z).\]
	\end{solution}
\end{example}

\begin{example}
	Let $ X,Y $ be two real valued random variable, not necessarily independent. Calculate $ \prob(X<Y) $.
	\begin{solution}
		To calculate this we can again use the law of total probabilities. In particular
		\[ \prob(X<Y) = \int_{\R}\prob(X<y)f_Y(y)\ dy = \int_{\R}F_{X|Y}(y)f_Y(y)\ dy. \]
	\end{solution}
\end{example}





\subsection{Isomorphism between random experiments}
Often, there is this intuition that certain random experiments are really the same, although they might look very different from each other. For instance, consider two random experiments. In one, we are playing a dice successively and asking what is the probability that after 5 plays, 1 is not appeared. The second experiment is that we have 6 Urns and we place balls in them successively, i.e. at each step one ball is placed in one of the urns and the chance of a ball to end up in any of the urns in equal. These two experiment, although very different, but looks very similar. There is one way that we can formalize this wage intuition, and that is the notion of isomorphism between sets. We say two sets are isomorphic if there is a bijection between them. And the reason that the previously mentioned experiments feel the same is that the sample space $\Omega$ of these two experiments are in fact isomorphic. 

\section{Random Variables}
Often, we are interested in the some measurements of the outcome of a random experiment rather than knowing the outcome it self. For instance, if the experiment of tossing two dice, we might be interested in asking the question if the sum of two dice is 6, and not concerned over whether the actual outcome was (3,3) or (2,4), etc. These quantities of interest are called random variables. The following definition put this into a more formal definition.

\begin{definition}
	Let $(\Omega, E, \prob)$ be a probability space. Then a random variable $X$ is a function $X: \Omega \to S$, where $S$ called the state space.
\end{definition}

\begin{remark}
	The state space $S$ must have some properties, i.e. being measurable, etc. You can read more about this on the Wikipedia of random variables. Also, the state space $S$ if often $\R$, or in the case of a discrete time Markov chain, $S$ is a finite set (that can be the edge set of a graph).
\end{remark}

Since the value of a random variable is determined by the outcomes of the random experiment, we can assign probabilities to the possible values of the random variable. We use the following notation for this purpose.

\begin{definition}[Notation for probability of random variables]
	Let $X$ be a random variable. Then we define event 
	\[ E = \set{X = a} = \set{\omega \in \Omega: X(\omega) = a}. \]
	Then the following notations are usually used interchangeably:
	\[ \prob(X=a) = \prob(\set{X=a})  \]
	both of which is simply $\prob(E)$.
\end{definition}

\begin{example}
	Let $X$ be a random variable defined to be the sum of two fair dice. Then 
	\begin{align*}
		&\prob(\set{X =2}) = \prob(\set{(1,1)}) = \frac{1}{36},\\
		&\prob(\set{X=3}) = \prob(\set{(1,2),(2,1)}) = \frac{2}{36},\\
		&\prob(\set{X=13}) = \prob(\emptyset) = 0.
	\end{align*}
\end{example}

\begin{example}
	Suppose that we toss a coin having probability $p$ of coming up heads. We continue tossing the coin until we see a heads. Let the random variable $N$ be the number of times we toss the coin. Describe this random variable.
	
	\begin{solution}
		Although, we can always solve this kind of questions in an ad hoc way by just simply following our intuition, but it is always a best practice to try to fine tune our abstract thinking with our intuitive understandings in these kind of example. Then we can use of abstract thinking capability to solve problems that are almost impossible to address by solely depending on the intuition. So, it is a good idea to try to see how does the set $\Omega$ look like. The set $\Omega$ will be the set of all finite string of all $T$ letters terminated with $H$. In other words
		\[ \Omega = \set{H,TH, TTH, TTTH, TTTTH, \cdots}. \]
		Then the random variable $N: \Omega \to \Z$ is basically the length of the string. For instance, if $\omega = TTH \in \Omega$, then $N(\omega) = 3$. Let's calculate
		\[ \prob(N = 3) = \prob(\set{\omega \in \Omega: N(\omega) = 3}). \]
		To solve this, we need to define appropriate events and then condition our probability on those events. Define $F_n$ be the event where the $n$ first outcomes are tails. For instance
		\[ F_1 = \set{TH, TTH, TTTH,\cdots},\ F_2 = \set{TTH, TTTH, TTTTH, \cdots},\ \cdots.\]
		And let $E = \set{N=3} = \set{TTH}$. Then we can condition $\prob(E)$ on $F_2$ 
		\[ \prob(E) = \prob(E|F_2) \prob(F_2) + \prob(E|F_2^c) \prob(F_2^c). \]
		Note that $F_2^c = \set{H, TH}$, this $\prob(E|F_2^c) = \prob(E \cap F_2^c)/\prob(F_2^c) = 0$. Now we need to determine $\prob(F_2)$. Again, we can condition this event on $F_1$. Then we can write
		\[ \prob(F_2) = \prob(F_2|F_1)\prob(F_1) + \prob(F_2|F_1^c) \prob(F_1^c). \]
		with the same argument as above $\prob(F_2|F_1^c) = 0$. Combining these equations we will get
		\[ \prob(E) = \prob(E|F_2) \prob(F_2|F_1) \prob(F_1). \]
		Now these probabilities are easy to calculate which leads to the final answer
		\[ \prob(E) = (1-p)(1-p) p.  \]
		And by induction we can conclude
		\[ \prob(\set{N = n}) = (1-p)^n p.  \]
	\end{solution}
\end{example}


\begin{example}
	Suppose that independent trials, each of which results in $m$ possible outcomes with respective probabilities $p_1, p_2, \hdots,p_m$ such that $\sum_{i=1}^{m}p_i = 1$. Are continually performed. Let $X$ be the number of trials needed until each outcome has occurred at least once. Describe the properties of this random variable.
	\begin{solution}
		It is sometime a good idea to try to imagine what does the sample space look like. Let $\Sigma=\set{s_1, s_2, s_3, \hdots, s_m}$ be a set of $m$ distinct symbols. Then each time we are continually performing the experiment, we are getting each of these symbols with corresponding probability $p_m$. Thus the sample space will be the set of all infinite sequences of these symbols. In other words
		\[ \Omega = \set{\text{all infinite sequence of symbols from $\Sigma$}}. \]
		Then the random number $X(\omega)$ for $\omega \in \Omega$ is basically the length of the prefix string of $\omega$ in which any of the symbols in $\Sigma$ has been occurred at least once. 
	\end{solution}
\end{example}



\subsection{Cumulative Distribution of Random Variable}
The notion of the cumulative distribution of a random variable comes handy in most of the future calculations. Also, this distribution can be used to derive other notions of distributions what are extremely important in applications. 

\begin{definition}[Cumulative distribution]
	Let $X$ be a random variable $X:\Omega \to \R$. Then the cumulative distrubition $F: \R \to \R$ is defined as
	\[ F(x) = \prob(\set{X \leq x}).  \]
\end{definition}

\begin{proposition}
	The cumulative distribution of a random variable has the following properties.
	\begin{enumerate}[(i),itemsep=0pt, topsep=5pt]
		\item $\prob(a<X\leq b) = F(b) - F(a).$
		\item $F(x)$ is a non-decreasing function of $x$.
	\end{enumerate}
\end{proposition}
\begin{proof}
	\begin{enumerate}[(i)]
		\item 
		\[ \prob(\set{a<X\leq b}) = \prob(\set{X\leq b} \cap \set{X\leq a}^c) = -\prob(\Omega) + \prob(\set{X\leq b}) + \underbrace{\prob(\set{X\leq a}^c)}_{1-\prob(\set{X\leq a})} = F(b) - F(a).  \]
		\item Let $b_1, b_2 \in \R$ and $b_1 \leq b_2$. Then $\set{X\leq b_1} \subseteq \set{X\leq b_2}$. This implies $$\prob(\set{X\leq b_1}) \leq \prob(\set{X\leq b_2}) \implies F(b_1) \leq F(b_2).$$
		This implies that $F(x)$ is a non-decreasing function. 
	\end{enumerate}
\end{proof}


\section{Probability Generating Function}
In this section we will go through the details of the probability generating function. We start with the following definition.

\begin{definition}[Probability Generating Function]
	Let $ X $ be a random variable with state space $ S = \Z_+ $. Then the probability generating function for this random variable is a function define as
	\[  G_X(s) = \E{s^X} = \sum_{x \in S}s^x \prob(X=x).  \]
\end{definition}

In different areas of mathematics, we often can define something algebraic that is very easy to handle (like differentiation, etc) and carries the important information of the object under study. One of these algebraic symbolic objects is the Tutte polynomial, Chromatic polynomial, matching polynomial, etc. These polynomials are kind of modeling the object under study with tools that are easy to handle. The probability generating function is one of those symbolic objects. Because of the way that is crafted, it carries most of the information about the random variable, while the actual object as a function might have poor properties. This will be more clear in the following proposition. In a nutshell, the probability generating function is more of a symbolic thing rather than actual function with meaning full properties. That is why we generally evaluate this function (and its derivatives) at point 0 or 1. 


\begin{proposition}[Properties of the probability generating function]
	Let $ X $ be a random variable, and $ G_X(s) $ its probability generating function. Then we have
	\begin{enumerate}[(i)]
		\item $ G_X(1) = 1 $.
		\item $ \E{X} = G_X'(1)  $.
		\item $ \var{X} = G_X''(1) - G_X'(1)^2 + G_X'(1) $
		\item Let $X, Y$ be independent random variables. Then we have
		\[  G_{X+Y}(s) = G_X(s) G_Y(s). \]
		\item Let $ X_1, X_2, \cdots $ be iid random variables, and $ N $ be a random variable taking values in $ \Z_+ $. Define $ T = X_1 + X_2 + \cdots + X_N $. Then we have
		\[ G_T(s) = (G_N \circ G_{X_1})(s). \]
	\end{enumerate}
\end{proposition}

\begin{proof}
	The proof for part i,ii, iii, and iv basically follows immediately from the definition. So we will only provide the proof for part iv.\\
	$ T $ is the sum of $ N $ iid random variables where $ N $ is itself a random variable. We can make it a normal variable by using the law of total probabilities.
	\[ G_T(s) = G_{\sum_i^N X_i}(s) = \sum_{n=0}^{\infty}  G_{\sum_i^n X_i}(s) \prob(N = n)  = \sum_{n=0}^{\infty}(G_{X_1})^n\prob(N=n) = G_N(G_{X_1})(s) \]
	and this completes the proof.
\end{proof}

The item (iv) in the proposition above is very important, as it makes the hard calculations easy to do. See the following example for more details.

\begin{example}
	We select a number $ N $ from $ \set{1,2,3,\cdots,100} $ randomly and then generate $ N $ random numbers $ X_1, X_2, \cdots X_N $ from the distribution $ \operatorname{Unif}[0,1]$. Then we compute $ T = X_1 + X_2 + \cdots +X_N $. What is the average of $ T $? 
	
	\begin{solution}
		We know that 
		\[ \E{T} = G'_T(1). \]
		Thus we need to calculate the probability generating function $ G_T(s) $. From part (iv) of the proposition above we know that $ G_T = G_N \circ G_{X_1} $. Thus we will have
		\[ G'_T = G_{X_1}' G_N'\circ G_{X_1}.  \]
		Thus evaluating at $ s=1 $ we will have
		\[ G'_T(1) = G_{X_1}'(1) G_N'(\underbrace{G_{X_1}(1)}_{1}) = \E{X_1} \E{N}. \]
		On the other hand we have $ \E{N} = 50 $ and $ \E{X_1} = 1/2 $. Then 
		\[ \E{T} = 25. \]
		The following figure shows this fact (i.e. convergence of the average value of $ T $ to 25 when we increase the number of experiments.)
		\begin{figure}[h!]
			\centering
			\includegraphics[width=0.5\linewidth]{Images/convergenceOfAverageExp.pdf}
		\end{figure}
		
 	\end{solution}
 	
\end{example}


\section{Some more deep notes}
This section has the definitions and discussions that I leaned through a course on the rigorous probability.

\begin{definition}[Algebra or Field of a Set]
	A field of sets is a pair $ (X,\mathcal{F}) $, where $ X $ is a set and $ \mathcal{F} $ is collection of subsets of $ X $ such that 
	\begin{enumerate}[(i),noitemsep]
		\item $ \emptyset \in \mathcal{F} $,
		\item $ A \in \mathcal{F} \implies A^c \in \mathcal{F} $,
		\item $ A_1, A_2 \in \mathcal{F} \implies A_1 \cup A_2 \in \mathcal{F} $.
	\end{enumerate}
	\begin{remark}
		It follows from the definition above that $ \Omega \in \mathcal{F} $ and also $ A_1 \cap A_2 \in \mathcal{F} $ if $ A_1,A_2 \in \mathcal{F} $.
	\end{remark}
\end{definition}
Note that in the notion of the algebra of a set, the algebra is closed only for finite intersections or finite unions. 

\begin{definition}[$ \sigma\text{-algebra} $ of a set]
	The $ \sigma\text{-algebra} $ of a set is an algebra of the set such that it is also closed under countable union and intersection.
\end{definition}

\begin{definition}[Semi-algebra]
	The collection $ \mathcal{I} $ is a semi-algebra of the subsets of $ \Omega $ if
	\begin{enumerate}[(i)]
		\item $ \emptyset \in \mathcal{I} $,
		\item $ A_1, A_2 \in \mathcal{I} \implies A_1 \cap A_2 \in \mathcal{I} $,
		\item For $ A \in \mathcal{I} $, $ A^c = \dot\cup_{i=1}^{n}A_i $ for some $ n \in \N $. 
	\end{enumerate}
\end{definition}


\begin{theorem}[Extension Theorem]
	Let $ \Omega  $ be a set, and $ \mathcal{I} $ be a semi-algebra of the subsets of it. Let $ P: \mathcal{I} \to [0,1] $ such that is satisfies the following properties
	\begin{enumerate}[(i),nosep]
		\item $ P(\emptyset) = 0  $,
		\item $ P(\Omega) = 1 $,
		\item $ P(\dot\cup_{i=1}^{n} A_i) \geq \sum_{i=1}^n P(A_i) $ for $\qquad  A_1,\cdots,A_n, \dot\cup_{i=1}^{n} A_i \in \mathcal{I}$.
		\item $ P(A) \leq \sum_i P(A_i) $ for $ A_1,\cdots \in I, A \subseteq \cup_i A_i $.
	\end{enumerate}
	Then there exist a valid probability space $ (\Omega, \mathcal{M}, \prob^*) $ such that $ \mathcal{M} \supset \mathcal{I} $ and $ \prob(A)= \prob^*(A)$ for all $ A \in \mathcal{I} $.
\end{theorem}
\begin{remark}
	By ``there exists a valid probability space'' we mean that $ \mathcal{M} $ is a $ \sigma\text{-algebra} $ and $ \prob^* $ is a countably additive probability measure. Also, it is worth mentioning that the property $ (iii) $ is called \emph{finite super additivity}.
\end{remark}
In the following propositions we will see more easy-to-check characterizations of this theorem.


\section{Summary and Tricks}
\begin{summary}[Improving finite additivity to countable additivity]
	In question \autoref{prob:countableAdditivity} we improve the finite additivity property of $ \prob^* $ to countable additivity, and we used two facts for that purpose. First, use the monotnonicity property, and second, use the countable sub additivity property. I.e. if we know that for $ A_1, A_2, \cdots, A_n \in \mathcal{M} $ disjoint we have
	\[ \prob^*(\bigcup_{i=1}^{n} A_i) = \sum_{i=1}^n \prob(A_i). \]
	Then let $ A_1,\cdots $ be a countable collection of disjoint sets in $ \mathcal{M} $. So for any $ m\in \N $ we have
	\[ \sum_{n<m} \prob^*(A_n) = \prob^*(\bigcup_{n<m} A_n) \leq \prob^*(\bigcup_n A_n), \]
	where for the last inequality we used the monotonicity property of $ \prob^* $. Since this is true for all $ m\in \N $ we can conclude that 
	\[ \sum_{n} A_n \prob^*(A_n) \leq \prob^*(\bigcup_n A_n). \]
	Now form the countable subadditivity we have
	\[ \sum_{n} A_n \prob^*(A_n) \geq \prob^*(\bigcup_n A_n). \]
	This implies 
	\[ \sum_{n} A_n \prob^*(A_n) = \prob^*(\bigcup_n A_n). \]
\end{summary}

\section{Solved Problems}
\begin{problem}[From Ross]
	Ben can talk a course in compute science or chemistry. If she takes the computer science course, then she will get A grade with probability $\frac{1}{2}$. If she takes the chemistry course, then she will get A grade with probability $\frac{1}{3}$. She decides to base her decision on the flip of a fair coin. What is the probability that she gets an A in chemistry?
\end{problem}
\begin{solution}
	We define the following events
	\begin{quote}
		$A$: she will get an A grade.\\
		$CO$: she will take the computer science course.\\
		$CH$: she will take the chemistry course.
	\end{quote}
	Then the question is basically asking for $\prob(A \cap CH)$. We can compute it by
	\[ \prob(A \cap CH) = \prob(A|CH)\prob(CH) = \frac{1}{3}\cdot\frac{1}{2} = \frac{1}{6}. \]
\end{solution}

\begin{problem}
	And urn contains seven black balls and five white balls. We draw two times from the urn. Given that the each ball has the same probability to be drawn, what is the probability that both balls drawn are black?
\end{problem}
\begin{solution}
	This question nicely demonstrates the fact that there are many ways to define the event spaces, and not all of them are very useful in computing the desired probability. Define
	\begin{quote}
		$E$: two drawn balls are black.
	\end{quote}
	The question is in fact asking $\prob(E)$. But this even is not very useful in any progress with the solution. Thus we need to define some finer events
	\begin{quote}
		$E_1$: The first drawn ball is black.\\
		$E_2$: The second drawn ball is black.
	\end{quote}
	It is clear that $E = E_1 \cap E_2$. These two finer events allows us to compute the probability of interest given the data we have in our hand.
	\[ \prob(E_1 \cap E_2) = \prob(E_2 | E_1) \prob(E_1) = \frac{6}{11} \cdot \frac{7}{12} \]
\end{solution}

\begin{problem}[From Ross]
	Three men at a party through their hats into the center of the room, and then, after mixing the hats, each pick a hat randomly. What is the probability if non of them get their own hat back.
\end{problem}
\begin{solution}
	There are a million ways to tack a probability problem. We can construct a suitable sample space and then compute the probabilities explicitly, or we can use the properties of the probability function to computer the desired probability without any need to construct the sample space. Here, we will demonstrate two ways.
	
	\textbf{Solving the problem by utilizing the properties of the probability function.} First we need to define some suitable events. There are again many ways to define event sets and each have their own pros and cons. We proceed with the following definition.
	\begin{quote}
		$E_i$: The person $i$ ``selects'' his own hat.  
	\end{quote}
	Also, with this particular construction of the event sets, it is much more easier to compute the complementary probability of the desired probability first and then compute the desired one by simply subtracting it from 1. The complement of the event ``no men gets his own hat back'' is ``at least one man gets his hat back'' which is $\prob(E_1\cup E_2 \cup E_3)$. To compute the terms of this we first need to calculate $\prob(E_i)$, $\prob(E_i \cap E_j)$ where $i\neq j$ and also $\prob(E_1 \cap E_2 \cap E_3)$. We know that $\prob(E_i) = 1/3$ for $i=1,2,3$. That is because it is equally likely he selects any of the hats at the center. For $\prob(E_i\cap E_j)$ we can write
	\[ \prob(E_i\cap E_j) = \prob(E_i|E_j)\prob(E_j) = \frac{1}{2}\cdot \frac{1}{3} =  \frac{1}{6}.   \]
	In which we used the fact that $\prob(E_i|E_j)$ is $\frac{1}{2}$ for distinct $i,j$. That is because given person $j$ selects his hat correctly, then there are two possibilities for $E_i$ to select his hat (he can pick the correct one or the wrong one). Lastly for $\prob(E_1\cap E_2\cap E_3)$ we write
	\[ \prob(E_1\cap E_2\cap E_3) = \prob(E_1|E_2\cap E_3)\prob(E_2\cap E_3) = \prob(E_1|E_2\cap E_3) \prob(E_2 | E_3) \prob(E_3) = 1 \cdot \frac{1}{2} \cdot \frac{1}{3} = \frac{1}{6}.  \]
	Thus 
	\[ \prob(E_1 \cup E_2 \cup E_3) = (1) - (1/2) + (1/6) = \frac{4}{6}. \]
	Then the probability of interest will be
	\[ \prob(E) = 1-\frac{4}{6} = \frac{1}{3}. \]
	
	\textbf{Solving by constructing a sample space.} A suitable sample space for this problem can be the set of all permutations on three letters. This set is
	\[ \Omega = 
	\set{\begin{pmatrix}
			a & b & c \\
			\boxed{a} & \boxed{b} & \boxed{c}
		\end{pmatrix},
		\begin{pmatrix}
			a & b & c \\
			\boxed{a} & c & b
		\end{pmatrix},
		\begin{pmatrix}
			a & b & c \\
			b & a & \boxed{c}
		\end{pmatrix},
		\begin{pmatrix}
			a & b & c \\
			b & c & a
		\end{pmatrix},
		\begin{pmatrix}
			a & b & c \\
			c & a & b
		\end{pmatrix},
		\begin{pmatrix}
			a & b & c \\
			c & \boxed{b} & a
	\end{pmatrix}}.
	\]
	Note that the elements in the box represents the fixed point of the permutation. The probability of interest is basically the number of permutations that has no fixed point. As it is clear from the set $\Omega$, the probability is
	\[ \prob(E) = \frac{2}{6} = \frac{1}{3}. \]
\end{solution}

\begin{problem}[Conditional probability mass function (from Ross)]
	Let $ X,Y $ be two random variables with the joint probability mass function given as 
	\[ P(1,1) = 0.5 \qquad P(1,2)=0.1,\qquad P(2,1)=0.1, \qquad P(2,2)=0.3. \]
	Calculate the conditional probability mass function of $ X $ given that $ Y = 1 $.
\end{problem}
\begin{solution}
	We will use the following identity
	\[ P_{X|Y}(x|y) = \prob(X=x|Y=y) = \frac{\prob(X=x,Y=y)}{\prob(Y=y)}. \]
	Observe that 
	\[ \prob(Y=y) = \sum_x \prob(Y=y,X=x) \]
	thus $ \prob(Y=1) = 0.5 + 0.1 = 0.6. $
	So we will have
	\[ P_{X|Y}(1|1) = \frac{0.5}{0.6} = \frac{5}{6}, \qquad P_{X|Y}(2|1) = \frac{0.1}{0.6} = \frac{1}{6}. \]
\end{solution}

\begin{problem}[Conditional probability mass function for geometric random variables (from Ross)]
	Let $ X_1,X_2 $ be two independent random variables with geometric distributions with parameters $ (n_1,p) $ and $ (n_2,p) $. Calculate the conditional probability mass function of $ X_1 $ given that $ X_1+X_2 = m $.
\end{problem}
\begin{solution}
	First, observe that $ Y = X_1 + X_2 $ is a binomial distribution with parameter $ (n_1+n_2, p) $. Thus we can write
	\[ P_{X_1|Y}(k|m) = \prob(X_1 = k | Y = m) = \frac{\prob(X_1 = k, X_1+X_2 = m)}{\prob(X_1+X_2 = m)} = \frac{\prob(X_1=k, X_2 = m-k)}{\prob(Y = m)} \]
	Since the random variables $ X_1 $ and $ X_2 $ are independent, we can write
	\[ P_{X_1|Y}(k|m) = \frac{\prob(X_1=k)\prob(X_2 = m-k)}{\prob(Y=m)} = \frac{\binom{n_1}{k}\binom{n_2}{m-k}}{\binom{n_1+n_2}{m}}. \]
\end{solution}

\begin{problem}[Conditional probability mass function for Poisson random variables (from Ross)]
	Let $ X,Y $ be two independent Poisson random variables with parameters $ \lambda_1 $ and $ \lambda_2 $ respectively. Calculate the conditional probability mass function for $ X $ given that $ X_1 + X_2 = n $.
\end{problem}
\begin{solution}
	First observe that $ Z = X + Y $ is a Poisson random variable with parameter $ \lambda_1 + \lambda_2 $. Thus we will have
	\[ P_{X|X+Y}(m|n) = \frac{\prob(X=m|X+Y=n)}{\prob(X+Y = n)} = \frac{\prob(X=m,Y=n-m)}{\prob(X+Y = n)} \]
	Given that $ X,Y $ are independent random variables then we can write
	\[ P_{X|X+Y}(m,n) = \frac{\prob(X=m)\prob(Y=n-m)}{\prob(X+Y=n)} = \frac{\lambda_1^n \lambda_2^{n-m}n!}{m!(n-m)!(\lambda_1+\lambda_2)^n} = \binom{n}{m} (\frac{\lambda_1}{\lambda_1+\lambda_2})^m ( \frac{\lambda_2}{\lambda_1+\lambda_2})^{n-m} \]
	Thus the conditional probability mass function of $ X $ given that $ X+Y = n $ will be a binomial random variable with parameter $ (n,\lambda_1/(\lambda_1+\lambda_2)) $. We can now easily compute the conditional expectation value as
	\[ \E{X|X+Y = n} = \frac{n\lambda_1}{\lambda_1 + \lambda_2} \]
\end{solution}

\begin{problem}
	Let $ X,Y $ be two discrete random variables. Prove that 
	\[ \E{\E{X|Y}} = \E{X}. \]
\end{problem}
\begin{solution}
	We start with the definition of the expectation of a discrete random variable.

	\begin{align*}
		\E{\E{X|Y}} &= \sum_y \E{X|Y=y} \prob(Y=y) = \sum_y \sum_x x\prob(X=x|Y=y)\prob(Y=y) \\
		& = \sum_{x,y} x\prob(X=x,Y=y) = \sum_x x \sum_y \prob(X=x,Y=y) = \sum_x x\prob(X=x) = \E{X}
	\end{align*}
\end{solution}

\begin{problem}[The expectation of a random number of random variables (from Ross)]
	Let the expected number of injures in an industrial field be 4 per week. Also, assume that the number of workers injured at each incidence are independent random variables with average 2. Then what is the expected number of injuries in one week?
\end{problem}
\begin{solution}
	Let $ X_1,X_2,\cdots $ be i.i.d random variables representing the number of workers injured at each incidence. We are interested in 
	\[ \E{X_1+\cdots+X_N} \]
	where $ N $ is a random variable representing the number of incidences occurred in a week. By the law of conditional expectation we can write
	\[ \E{X_1 + \cdots + X_N} = \sum_n \E{X_1+\cdots+X_n}\prob(N=n) = \sum_n n\E{X} \prob(N=n) = \E{X} \E{N}.\]
	Thus the average number of workers injured in a week will be 8. 
\end{solution}

\begin{problem}[An alternative way to compute the expectation of a geometric random variable]
	Consider a coin with probability $ p $ to fall heads. What is the expectation value of the number of tosses required until we get the first head?
\end{problem}
\begin{solution}
	Let $ X_1,X_2,\cdots $ be Bernoulli random variables with parameter $ p $. Let $ N $ be a random variable denoting the number of tosses required until we get the first heads. We can condition the expected value of $ E $ to the first outcome.
	\[ \E{N} = \E{N|X_1 = H }\underbrace{\prob(X_1 = H)}_{=p} + \E{N|X_1=T}\underbrace{\prob(X_1=T}_{=1-p})  \]
	Observe that 
	\[ \E{N|X_1=H} =1 ,\qquad \E{N|X_1=T} = 1+\E{N}.\]
	Thus we will have
	\[ \E{N} = \frac{1}{p}. \]
\end{solution}

\begin{problem}[Trapped miner (from Ross)]
	A miner is trapped in the mine and has three doors in front of him. He is equally likely to choose any of the three. The first door will take him to safety after 2 hours of walking, the second door will take him to the mine again after 3 hours of walking, and the third door will take him to the mine again after 5 hours of walking. What is the expected time that the miner will arrive to safety?
\end{problem}
\begin{solution}
	Let $ X_1,X_2,\cdots $ be random variables denoting the doors that the miner choose at each time that he attempts to escape. Furthermore, let $ T $ be a random variable showing the the time it takes for the miner to escape. To calculate $ \E{T} $ we can condition it on the first door choice. I.e.
	\[ \E{T} = \E{T|X_1 =1}\prob(X_1=1) + \E{T|X_1 =2}\prob(X_1=2)+\E{T|X_1 =3}\prob(X_1=3) \]
	Observe that 
	\[ \prob(X_1=1) = \prob(X_1=2) = \prob(X_1=3) = 1/3. \]
	Also
	\[  \E{T|X_1 =1} = 2,\qquad  \E{T|X_1 =2} = 3+\E{T}, \qquad \E{T|X_1 =3} = 3+\E{T}. \]
	Thus we will have
	\[ \E{T} = 10. \]
	So on average it will take the miner to exit the mine in 10 hours. Note that this does not guarantee that the miner will eventually escape. It is possible that we will get in trap by repeatedly choosing the door number 3.
\end{solution}
 
\begin{problem}[From Rosenthal]
	Suppose that $ \Omega = \set{1,2}, $ with $ \prob(\emptyset) = 0 $ and $ \prob(\set{1,2}) = 1 $. Suppose $ \prob(\set{1}) = \frac14 $. Prove that $ \prob $ is countably additive if and only if $ \prob(\set{2})=\frac34 $.
\end{problem}
\begin{solution}
	The proof has two parts
	\begin{itemize}
		\item [$ \boxed{\Longrightarrow} $] Since $ \prob $ is countably additive, then 
		\[ \prob(\set{1} \dot\cup \set{2}) = \prob(\set{1}) + \prob(\set{2}) = 1. \]
		This implies $ \prob(\set{2}) = 3/4 $.
		\item [$ \boxed{\Longleftarrow} $] Assume $ \prob(\set{2}) = 3/4 $. Then it is very straightforward to check that for every disjoint subset $ A,B \subset \Omega $, we have
		\[ \prob(A \dot\cup B) = \prob(A) + \prob(B). \]
		Thus we conclude that $ \prob $ is countably additive.
	\end{itemize}
\end{solution}

\begin{problem}[From Rosenthal]
	Suppose $ \Omega = \set{1,2,3} $ and $ \mathcal{F} $ is a the collection of all subsets of $ \Omega $. Find (with proof) necessary and sufficient conditions on the real numbers $ x,y,z $ such that there exists a countably additive probability measure $ \prob $ on $ \mathcal{F} $ such that $ x = \prob\set{1,2}, y=\prob\set{2,3}, z=\prob\set{1,3} $.
\end{problem}
\begin{solution}
	To find the necessary conditions, we assume that $ \prob $ is an additive probability measure. Let $ a = \prob\set{1}, b=\prob\set{2} $, and $ c = \prob\set{3} $. Then the countable additivity implies
	\[ a+b=x,\qquad b+c=y,\qquad a+c=z. \]
	Then due to countable additivity, and the fact that $ \prob $ is a probability measure (i.e. $ \prob\set{1,2,3} = 1 $), we have $ a+b+c = 1 $, thus we need to have
	\[ x+y+z = 2. \tag{\eighthnote} \]
	Further, we solve the $ a,b,c $ in terms of $ x,y,z $ are require the singleton probabilities to be positive. We have
	\[ a = \frac{x-y+z}{2},\qquad b = \frac{x+y-z}{2},\qquad c=\frac{-x+y+z}{2}. \]
	One of the necessary conditions is also to have
	\[ x-y+z\geq0,\qquad x+y-z\geq0,\qquad -x+y+z \geq0. \tag{\twonotes}  \]
	The two conditions ($ \eighthnote $) and $ (\twonotes) $  together are the necessary and sufficient conditions for $ \prob $ to be a valid probability measure.
\end{solution}

\begin{problem}[From Rosenthal]
	Suppose that $ \Omega = \N $ is the set of positive integers, and $ \prob $ is defined for all $ A\subseteq \Omega $ by $ \prob(A) = 0 $ if $ A $ is finite, and $ \prob(A) = 1 $ if $ A $ is infinite. Is $ \prob $ finitely additive?
\end{problem}
\begin{solution}
	Not it is not. Consider the partitioning of the set $ \Omega $ by the even $ E $ and odd $ O $ integers.
	\[ \prob(\Omega) = \prob(E) + \prob(O) \implies 1 = 2, \]
	which is not true. Thus $ \prob $ is not finitely additive.
\end{solution}

\begin{problem}[From Rosenthal]
	Suppose that $ \Omega = \N $, and $ \prob $ is defined for all $ A \subseteq \Omega $ by $ \prob(A) = \abs{A} $ if $ A $ is finite, and $ P(A)=\infty $ if $ A $ is infinite.  This $ P $ is of course not a probability measure (in fact it is counting measure), however we can still ask the following: (be the convention $ \infty+\infty = \infty $)
	\begin{enumerate}[(I)]
		\item Is $ \prob $ finitely additive?
		\item Is $ \prob $ countably additive?
	\end{enumerate}
\end{problem}
\begin{solution}
	\begin{enumerate}[(I)]
		\item Yes. $ \prob $ being finitely additive is equivalent being additive for disjoint $ A,B \subset \Omega $. There are three cases for these choices
		\begin{enumerate}[(i)]
			\item $ A,B $ are both finite. In this case $ \prob(A\dot\cup B) = \prob(A) + \prob(B) $ since $ 0=0+0 $.
			\item $ A,B $ are both infinite. In this case $ \prob(A\dot\cup B) = \prob(A) + \prob(B) $ since $ \infty+\infty = \infty $.
			\item One of the sets $ A,B $ is infinite. Then $ \prob(A\dot\cup B) = \prob(A) + \prob(B) $ since $ 0+\infty = \infty. $
		\end{enumerate}
		\item No. We will show this by counterexample. We can write $ \Omega = \dot\bigcup_{i\in \N}\set{i} $. Then the countable additivity implies
		\[ \prob(\Omega) = \prob(\dot\bigcup_{i\in \N}\set{i}) \implies 1 = 0.\]
		which is not true.
	\end{enumerate}
\end{solution}


\begin{problem}[From Rosenthal]
	Let $ \mathcal{I} $ be the set of all intervals in $ [0,1] $ (open, closed, half-open, singleton, empty set). Show that $ \mathcal{I} $ is a semi-algebra.
\end{problem}
\begin{solution}
	By definition of $ \mathcal{I} $ we have $ \emptyset\in \mathcal{I} $. Let $ A_1, A_2 $ be two intervals in $ [0,1] $. If $ A_1,A_2 $ are disjoint, then $ A_1\cap A_2 \in \mathcal{I} $. If they are not disjoint, then without loss of generality we can assume that 
	\[ A_1 = \set{x\in[0,1]\ |\ a<x<b}, A_2 = \set{x\in[0,1]\ |\ c<x<d}, \]
	where $ a<c<b<d $. Thus $ A_1\cap A_2 = (c,b) $. So $ \mathcal{I} $ is closed under finite intersection. The proof is the same for any other choices of $ A_1,A_2 $ (i.e. being closed set, etc). To show the third property, again, without the loss of generality, let $ A = (a,b) $. Then $ A^c = (-\infty,a] \dot\cup [b,\infty) $. For other choices of $ A $ (i.e. being closed, etc) we will have a similar argument. Thus we conclude that the collection $ \mathcal{I} $ is a semi-algebra of the subsets of $ [0,1] $.
\end{solution}

\begin{problem}[From Rosenthal]
	Let $ \mathcal{I} $ be the semi-algebra consisting of all intervals in $ [0,1] $. Define
	\[ \mathcal{B}_0 = \set{\text{all finite unions of elements of $ \mathcal{I} $}.} \]
	Show that $ \mathcal{B}_0 $ is not a $ \sigma\text{-algebra} $.
\end{problem}
\begin{solution}
	Along with many other sets, $ \mathcal{I} $ contains all of the singletons, so does $ \mathcal{B}_0 $. Consider the following collection
	\[ \mathcal{A} = \set{\set{x}\ :\ x \in \Q \cap [0,1]}. \]
	By definition, all of the sets in the collection $ \mathcal{A} $ belongs to $ \mathcal{B}_0 $. However, the following countable union
	\[ \dot\bigcup_{A \in \mathcal{A}} A = [0,1] \cap \Q \]
	does not belong to $ \mathcal{B}_0 $ (as it is not possible to generate with only finite unions of the elements of singletons in $ \mathcal{I} $).
\end{solution}

\begin{problem}[From Rosenthal]
	Prove that the outer measure $ \prob^* $ is countably sub-additive, i.e.
	\[ \prob^*(\bigcup_{n=1}^{\infty} B_n) \leq \sum_{n=1}^{\infty} \prob^*(B_n) \qquad \text{for any $ B_1,B_2,\cdots \in \Omega $}.\]
\end{problem}
\begin{solution}
	This problem is the proof of Lemma 2.3.6 in Rosenthal. See the text for more context. A very quick review on the context is that we have a semi-algebra $ \mathcal{I} $ of the subsets of $ \Omega $, and we have the function $ \prob: \mathcal{I} \to [0,1] $ that satisfies the properties required for the extension theorem, hence there exist a valid probability space $ (\Omega, \mathcal{M}, \prob^*) $, where $ \mathcal{M} $ is a $ \sigma\text{-algebra} $ and $ \prob^* $ is a probability measure (which is also the outer measure). The proof of this question is as follows. 
	
	Fix $ \epsilon>0 $. Since the outer measure is the infimum of the sum of the probabilities on all $ \mathcal{I} $ covers, then for each $ B_n $ we can find a collection $ \set{C_{nk}} $ where $ C_{nk}\in\mathcal{I} $ such that 
	\[ \sum_k \prob(C_{nk}) \leq \prob^*(B_n) + \epsilon2^{-n}. \]
	On the other hand, since $ \set{C_{nk}}_{nk} $ covers $ \bigcup_n B_n $, then again from the properties of inf we have
	\[ \prob^*(\bigcup_n B_n) \leq \sum_{nk} \prob(C_{nk}). \]
	combining these two we will get
	\[  \prob^*(\bigcup_n B_n) \leq \sum_n \prob^*(B_n) + \epsilon. \]
	Since this is true for all $ \epsilon>0 $, then it implies that 
	\[  \prob^*(\bigcup_n B_n) = \sum_n \prob^*(B_n). \]
\end{solution}

\begin{problem}[From Rosenthal]
	\label{prob:countableAdditivity}
	If $ A_1,A_2,\cdots \in \mathcal{M} $ are disjoint, then prove that 
	\[ \prob^*(\dot\bigcup_n A_n) = \sum_n \prob^*(A_n). \]
\end{problem}
\begin{solution}
	First, we start to show the finite additivity, and then using the properties of monotnonicity and sub-additivity, we will prove the countable additivity as well. Let $ A_1, A_2 \in \mathcal{M} $ disjoint. In particular, since $ A_1 \in \mathcal{M} $, from the definition of $ \mathcal{M} $ (see page 12 Rosenthal), then
	\[ \prob^*(A_1 \cup A_2) = \prob^*(A_1^c \cap (A_1\cup A_2)) + \prob^*(A_1 \cap (A_1 \cup A_2)) = \prob^*(A_2) + \prob^*(A_1). \]
	This implies that for any finite disjoint collection of $ A_i $ we have the additivity property (by induction). Now for any $ m \in \N $ we have
	\[  \sum_{n<m} \prob^*(A_n)  = \prob^*(\bigcup_{n\leq m}A_n)  \leq \prob^*(\bigcup_n A_n) \]
	where the last inequality follows form the monotnonicity property of $ \prob^* $. Since this is true for all $ m \in \N $, then we conclude that 
	\[ \prob^*(\bigcup_n A_n) \geq \sum_n \prob^*(A_n). \]
	On the other hand, from the sub-additivity property we have
	\[ \prob^*(\bigcup_n A_n) \leq \sum_n \prob^*(A_n). \]
	These two implies that 
	\[ \prob^*(\bigcup_n A_n) = \sum_n \prob^*(A_n). \]
\end{solution}

\begin{problem}[From Rosenthal]
	Let $ \mathcal{M} $ be the $ \sigma\text{-algebra} $ we get from the extension theorem, where by definition it contains all of the sets like $ A \in \Omega $ for which the outer measure is additive on the union of $ A \cap E $ and $ A^c \cap E $ for $ \forall E \subset \Omega  $. In other words
	\[ \mathcal{M} = \set{A \subseteq \Omega\ :\ \prob^*(A\cap E) + \prob^*(A^c \cap E) = \prob^*(E) \quad \text{for all } E \subset \Omega}. \]
	Prove that $ \mathcal{M} $ is an algebra.
\end{problem}
\begin{solution}
	Let $ A = \Omega $. Then
	\[ \prob^*(A \cap E) + \prob^*(A^c\cap E) = \prob^*(E) + \prob^*(\emptyset) = \prob^*(E). \]
	So we conclude that $ \Omega \in \mathcal{M} $. Also, it follows immediately from the definition of $ \mathcal{M} $ that if $ A \in \mathcal{M} $ then $ A^c \in \mathcal{M} $. Now it remains to show if $ A_1, A_2 \in \mathcal{M} $ then $ A_1\cap A_2 \in \mathcal{M} $. Let $ E \subset \Omega $. Then 
	\begin{align*}
		&\prob^*(E \cap (A_1 \cap A_2)) + \prob^*(E \cap (A_1 \cap A_2)^c ) \\
		&= \prob^*(E\cap (A_1\cap A_2)) + \prob^*(E\cap A_1^c \cap A_2) + \prob^*(E\cap A_1 \cap A_2^c) + \prob^*(E\cap A_1^c \cap A_2^c) \\
		&\leq \prob^*(E\cap A_1\cap A_2) + \prob^*(E \cap A_1^c \cap A_2) + \prob^*(E \cap A_1 \cap A_2^c) + \prob^*(E\cap A_1^c \cap A_2^c)\\
		&=\prob^*(E\cap A_2) + \prob^*(E\cap A_2^c) \qquad \text{(because $ A_1 \in \mathcal{M} $)} \\
		&=\prob^*(E) \qquad \text{(because $ A_2 \in \mathcal{M} $)}.
	\end{align*}
	On the other hand, from the sub-additivity property we know that 
	\[ \prob^*(E\cap (A_1\cap A_2)) + \prob^*(E \cap (A_1\cap A_2)^c) \geq \prob^*(E). \]
	Thus we conclude that 
	\[ \prob^*(E\cap (A_1\cap A_2)) + \prob^*(E\cap (A_1\cap A_2)^c) = \prob^*(E). \]
	This implies that $ A_1\cap A_2 \in \mathcal{M} $ and this finishes the proof.
\end{solution}


\begin{problem}[From Rosenthal]
	Let $ A_1,A_2,\cdots \in \mathcal{M} $ be disjoint. For each $ m\in \N $, let $ B_m = \bigcup_{n\leq m} A_n $. Prove that for all $ m\in \N $, and for all $ E \subseteq \Omega $ we have
	\[ \prob^*(E\cap B_m) = \sum_{n\leq m} \prob^*(E\cap A_n). \]
\end{problem}
\begin{solution}
	First, observe that this statement is true for $ m=1 $ in a trivial way. For $ m=2 $, since $ A_2 \in \mathcal{M} $, then we can expand $ E\cap B_2 $ according to $ A_2 $, i.e.
	\[ \prob^*(E\cap B_2) = \prob^*((E\cap B_2)\cap A_2) + \prob^*((E \cap B_2)\cap A_2^c) \]
	On the other hand $ (E\cap B_2)\cap A_2 = E \cap A_2 $ and $ (A\cap B_2)\cap A_2^c = E\cap B_1 = E\cap A_1 $. Thus we can write
	\[ \prob^*(E\cap B_2) = \prob^*(E\cap A_1) + \prob^*(E\cap A_2). \]
	In general, for $ m \in \N $ we can write
	\[ \prob^*(E\cap B_m) = \prob^*(E\cap A_m) + \prob^*(E\cap B_{m-1}). \]
	Thus using induction we can write
	\[ \prob^*(E\cap B_m) = \sum_{n\leq m }\prob^*(E\cap A_n). \]
\end{solution}

\begin{problem}[From Rosenthal]
	\begin{enumerate}[(a)]
		\item In what step of the proof of proposition 1.2.6 in (Rosenthal) the expression (1.2.1) was used?
		\item Give an example of a countably additive set function $ \prob $, defined on all subsets of $ [0,1] $, which satisfies $ (1.2.3) $ and $ (1.2.5) $, but not $ (1.2.1) $.
	\end{enumerate}
\end{problem}
\begin{solution}
	\begin{enumerate}[(a)]
		\item We used $ (1.2.1) $ at the last step of drawing the contradiction by assigning the probability $ 1 $ to $ \prob((0,1]) $.
		\item 
	\end{enumerate}
\end{solution}