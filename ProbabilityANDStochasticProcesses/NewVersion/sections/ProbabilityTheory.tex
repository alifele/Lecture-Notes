\chapter{Probability Theory}

%\section[Fundamental Concepts]{\hyperlink{toc}{Fundamental Concepts}}
\section{Foundamentals}

The main concept in the field of statistics and probability is the set theory. Basically all we deal with the sets. The whole theroy of statistics can be built on that. Let's discuss some foundamental concepts in statistics and then build the theory.

\subsection{Random Experiment}
To understand the meaning of random experiment, do not over think! The first thing that comes into our minds when we hear the word "random experiment" is its definition! In a nutshell, random experiment is an experiment that its outcome is unkown to us. Like:

\begin{itemize}
	\item Tossing two coin
	\item Rolling a dice
	\item Measuring the number of possible ReadWrite operations on a piece of EEPROM chip
\end{itemize}

Do not overthink about that. Yes we can go further and discuss stuff like "we can compute the exact movement of dice or coin so it is not random but determenistic" and etc. Here I will not touch the philosophical topics that are very deep and do not necessarily converge the a unified point of view!

The random experiments can be modeled and despite the fact that a random experiment is random, we can deduce many useful information from modeling that. To model a random experiment, we use three important concepts: sample space, events, probability. In the following section, we will discuss each of them in detail.


\subsection{Sample Space}

\begin{definition}[Sample Space]
	
	Sample space $\Omega$ is simply a set that contains \emph{all possible outcomes} of a random experiment/
	
\end{definition}

For each of random experiments described above, we can define a sample space. For example:

\begin{itemize}
	\item $\Omega$ of Tossing Tow Coins: $$\Omega = \{ HH,HT,TH,TT \}$$
	\item $\Omega$ of Rolling a Dice: $$\Omega = \{ 1,2,3,4,5,6 \}$$
	\item $\Omega$ of Rolling Two Dices: $$\Omega = \{ (1,1),(1,2), \ldots, (1,6), \ldots ,(6,6)  \}$$
	\item $\Omega$ of Number of possible ReadWrite operations on a EEPROM chip: $$\Omega = \mathbb{N}$$
\end{itemize}



\subsection{Events}
\begin{definition}[Events]
	Event $E$ is a set of outcomes of a random experiment and is the subset of sample space $\Omega$. 
	$$E \in \Omega$$
\end{definition}


For example for any of the sample spaces specified above, we can define so many possible events. In fact any set that is a subset of the sample space is a valid event of that sample space. For example:

\begin{itemize}
	
	\item Tossing Three Coins
	\begin{itemize}
		\item There are at least on Heads: $$E = \{ HHH,HHT,HTH,THH,HTT,THT,TTH \}$$
		\item There are only two Tails: $$E = \{ TTH,THT,HTT \}$$
	\end{itemize}
	
	\item Rolling Two Dices
	\begin{itemize}
		\item The sum of two dices is 4: $$E = \{ (1,3),(2,2),(3,1) \}$$
		\item there are at least one prime number in the outcome:
		$$E = \{ (1,2),(1,3),(1,5),(2,1),(3,1),(5,1),(2,2),(2,3),(2,5), \ldots ,(5,5)\}$$
	\end{itemize}
	
\end{itemize}

Since we have define everything on the basics of set theory, then now we can correspond the everyday concepts to specific operations in the set theory.

\begin{example}{The Mapping Between Everyday Language and Sets in the Theory of Probability}
	
	\begin{itemize}
		\item At least one of two events $A,B \in \Omega$ happens: $E = A \cup B$.
		\item Tow events $A,B \in \Omega$ occures at the same time: $E = A \cap B$.
		\item Event $A \in \Omega$ does not happen: $E = \overline{A} = \Omega - A$.
		\item The event $A$ happens but $B$ does not happen: $E = A - B$.
		
	\end{itemize}
	
\end{example}



In probability and statistics, we are dealing with three important concepts: sample space $\Omega$, event $E$, and probability $P$.


\begin{definition}[Disjoint events]
	
	If two events has no common elements (i.e. $A \cap B = \varnothing$) then we say that two events are \emph{disjoint}. Basically, if two sets in the venn diagram has nothing is common they are considerent to be disjoint sets.
	
	
	For example for the random experiment of tossing two coins, the events 1) both coins are heads: $A = \{HH\}$ and 2) both coins are tails: $B = \{TT\}$. Two events $A,B$  are two disjoint events. \textbf{Two events being  disjoing is NOT the same as being independent}. We will talk about independet events in future.
	
\end{definition}

Note that since the events are basically sets, we can use theorems of set theory to solve the problems. 

\begin{theorem}[De Morgan's Laws]
	
	If $A,B$ are two sets then:
	
	$$\overline{A \cap B} = \overline{A} \cup \overline{B}$$
	
	$$\overline{A \cup B} = \overline{A} \cap \overline{B}$$
	
\end{theorem}

\begin{proof}
	the proof is left as an excerise!
\end{proof}


\subsection{Probability}

The last foundamental ingeridient in modeling a random experiment, is to define a probability for each event. The probability should intuitively reflect how likely an event is probable to happen. This probability should satisfy some foundamental properties which are explained as follows.

\begin{definition}[Axioms of probability (Kolmogorov axioms)]
	
	Suppose that $A, B \in \Omega$ is an event and $\mathbb{P}$ is a probability function. Then $\prob$ should satisfy the following properites:
	
	\begin{enumerate}[(I)]
		\item $ 0 \leq \prob(A) \leq 1$
		\item $\prob(\Omega) = 1$
		\item For the events $E_1, E_2, ..., E_n \in \Omega$ that are mutually exclusive (i.e. disjoint events): $$\prob(\bigcup_{i} E_i) = \sum_i \prob(E_i).$$
		The last property is known as the countable additivity of the probability measure.
	\end{enumerate}
	
\end{definition}
\begin{remark}
	Note that we do not require the uncountable additivity property. That is because every set $ \Omega $ can be written as a disjoint union of singletons $ \Omega = \cup_{x\in\Omega}\set{x} $ and this leads to contradiction when $ \Omega $ a continuous set (like the interval $ [0,1] $). We will see more about this later.
\end{remark}

These axioms are called the foundamental axioms of probability and also the Kolmogorov axioms. We are free to define any kind of probabilty function that we want but it is important that 1) It should align with our common sense, 2) It should satisfy the Kolmogorov axioms. 

Using the axioms above, we can observe and prove several interesting properties of the probability function. In the following box we have expressed some of them.

\begin{theorem}[Basic Properties of the Probability Function]
	
	Suppose that $\prob$ is a probability function and $A,B \in \Omega$ are events of the sample space $\Omega$. We can show that the probability function has the following properties:
	
	\begin{enumerate}
		
		\item $\prob(\varnothing) = 0$
		
		\item If $A \subset B$ then $\prob(A) \leq \prob(B)$.
		
		\item $\prob(\overline{A}) = 1 - \prob(A)$.
		
		\item $\prob(A \cup B) = \prob(A) + \prob(B) - \prob(A \cap B)$.
		
	\end{enumerate}
	
\end{theorem}


\begin{proof}
	The properties can be proved using the basic set theory theorems.
	
	\begin{enumerate}
		
		\item Since $\emptyset$ is the complement of $\Omega$, so these two sets are disjoint (i.e. $\emptyset \cap \Omega = \emptyset$). On the other hand from the set theory we know that $\emptyset \cup \Omega = \Omega$. So $\prob(\emptyset \cup \Omega) = \prob(\Omega)$. On the other hand, using the third axiom we can write: $\prob(\emptyset \cup \Omega) = \prob(\emptyset) + \prob(\Omega)$. Comparing the two recent equations we can conclude that $\prob(\emptyset) = 0$.
		
		
		
	\end{enumerate}
	
	
	
	The proofs for 2,3,4 are left as a exercise. However, the solutions can be found in the book "Statistical Modeling and Computation by Kroese" chapter 1. 
	
	
\end{proof}



\begin{example}[Defining a simple probability function]
	
	Let's define a probability function for the rolling n dice experiment that is both aligned with our common sense and also satisfy the Kolmogorov equations. Suppose that the $\Omega$ is the sample space and $E \in \Omega$ is an event. Then let's define:
	
	$$\prob(E) = \frac{\lvert E \rvert}{\lvert \Omega \rvert}$$
	
	in which the $\lvert E \rvert$ means the cardinality (number of elements) of the set $E$.
	
\end{example}

Utilizing the properties of the probability function, we can derive some very important notions, one of which is reflected in the following proposition.

\begin{proposition}[Conditional expansion - Law of total probabilities]
	Let $(\Omega, \mathcal{F}, \prob)$ be a probability space. Let $\mathfrak{F}$ be a finite collection of events $\mathfrak{F} = \set{F_1,F_2,\cdots, F_n}$ that partitions $\Omega$. I.e.
	\begin{enumerate}[(i)]
		\item $F_i \cap F_j = \emptyset \qquad i\neq j$,
		\item $\bigcap_{i} F_i = \Omega$.
	\end{enumerate}
	Let $E \in \mathcal{F}$ be any nonempty event. Then we can write
	\[  \prob(E) = \sum_{i} \prob(E|F_i)\prob(F_i). \]
\end{proposition}
\begin{proof}
	Since $\mathfrak{F}$ partitions $\Omega$ and $E \neq \emptyset$, then $\set{E\cap F_i}_i$ is a partition of $E$. Thus
	\[ \prob(E) = \prob(\bigcup_i (E \cap F_i)) = \sum_i \prob(E \cap F_i) = \sum_i \prob(E|F_i)\prob(F_i). \]
	This completes the proof.
\end{proof}


In dealing with random variables, either continuous or discrete, using the notion of the law of total probabilities helps us to simplify some of the calculations significantly. The following examples are some places that we use this idea to simplify calculations by a lot. 

\begin{example}
	Let $ X_1, X_2, X_3, \cdots $ be i.i.d. real-valued random variable. Let $ T $ be a positive integer valued random variable. Define the the real-valued random variable $ N $ as 
	\[ N = \sum_{i=1}^{T} X_i. \]
	What is the probability generating function for $ N $.
	
	\begin{solution}
		For the generating probability function we have
		\[ G_N(s) = \E{s^N} = \E{s^{X_1+X_2+\cdots+X_T}}. \]
		The problem in evaluating the expression above is that the number of random variables $ X_i $ to be summed up is also a random variable. So the first step is to make this a non-random variable buy conditional expansion.
		\[ G_N(s) = \E{s^N} = \sum_{i\in\N}\E{s^{X_1+\cdots+X_T}\big|T=i}\prob(T=i) = \sum_{i\in\N}\E{s^{X_1+\cdots+X_i}}\prob(T=i) \]
		Since $ X_i $ are all i.i.d., then we can write
		\[ G_N(s) = \sum_{i\in\N}(\E{s^{X_1}})^n\prob(T=i) = G_T(G_{X_1}(s)). \]
	\end{solution}
\end{example}

\begin{example}
	Let $ X,Y $ be two independent random variables. Define $ Z = X+Y $. Find the PDF of $ Z $. 
	\begin{solution}
		First, We need to find $ F_Z(z) = \prob(Z<z) $. For this we can write
		\[ F_Z(z) = \prob(X+Y < z) \]
		Again, we can use conditional expansion to write
		\[ F_Z(z) = \int_{\R} \prob(X+Y<z\big| Y = y)f_Y(y)\ dy = \int_{\R} \prob(X<z-y)f_Y(y)\ dy  = \int_{\R} F_X(z-y)f_Y(y)\ dy. \]
		Then differentiating $ F_z $ with respect to $ z $ we will get the PDF 
		\[ f_Z(z) = \frac{d }{dz}F_Z(z) =  \int_{\R} f_X(z-y)f_Y(y)\ dy = (f_X * f_Y)(z).\]
	\end{solution}
\end{example}

\begin{example}
	Let $ X,Y $ be two real valued random variable, not necessarily independent. Calculate $ \prob(X<Y) $.
	\begin{solution}
		To calculate this we can again use the law of total probabilities. In particular
		\[ \prob(X<Y) = \int_{\R}\prob(X<y)f_Y(y)\ dy = \int_{\R}F_{X|Y}(y)f_Y(y)\ dy. \]
	\end{solution}
\end{example}





\subsection{Isomorphism between random experiments}
Often, there is this intuition that certain random experiments are really the same, although they might look very different from each other. For instance, consider two random experiments. In one, we are playing a dice successively and asking what is the probability that after 5 plays, 1 is not appeared. The second experiment is that we have 6 Urns and we place balls in them successively, i.e. at each step one ball is placed in one of the urns and the chance of a ball to end up in any of the urns in equal. These two experiment, although very different, but looks very similar. There is one way that we can formalize this wage intuition, and that is the notion of isomorphism between sets. We say two sets are isomorphic if there is a bijection between them. And the reason that the previously mentioned experiments feel the same is that the sample space $\Omega$ of these two experiments are in fact isomorphic. 

\section{Random Variables}
Often, we are interested in the some measurements of the outcome of a random experiment rather than knowing the outcome it self. For instance, if the experiment of tossing two dice, we might be interested in asking the question if the sum of two dice is 6, and not concerned over whether the actual outcome was (3,3) or (2,4), etc. These quantities of interest are called random variables. The following definition put this into a more formal definition.

\begin{definition}
	Let $(\Omega, E, \prob)$ be a probability space. Then a random variable $X$ is a function $X: \Omega \to S$, where $S$ called the state space.
\end{definition}

\begin{remark}
	The state space $S$ must have some properties, i.e. being measurable, etc. You can read more about this on the Wikipedia of random variables. Also, the state space $S$ if often $\R$, or in the case of a discrete time Markov chain, $S$ is a finite set (that can be the edge set of a graph).
\end{remark}

Since the value of a random variable is determined by the outcomes of the random experiment, we can assign probabilities to the possible values of the random variable. We use the following notation for this purpose.

\begin{definition}[Notation for probability of random variables]
	Let $X$ be a random variable. Then we define event 
	\[ E = \set{X = a} = \set{\omega \in \Omega: X(\omega) = a}. \]
	Then the following notations are usually used interchangeably:
	\[ \prob(X=a) = \prob(\set{X=a})  \]
	both of which is simply $\prob(E)$.
\end{definition}

\begin{example}
	Let $X$ be a random variable defined to be the sum of two fair dice. Then 
	\begin{align*}
		&\prob(\set{X =2}) = \prob(\set{(1,1)}) = \frac{1}{36},\\
		&\prob(\set{X=3}) = \prob(\set{(1,2),(2,1)}) = \frac{2}{36},\\
		&\prob(\set{X=13}) = \prob(\emptyset) = 0.
	\end{align*}
\end{example}

\begin{example}
	Suppose that we toss a coin having probability $p$ of coming up heads. We continue tossing the coin until we see a heads. Let the random variable $N$ be the number of times we toss the coin. Describe this random variable.
	
	\begin{solution}
		Although, we can always solve this kind of questions in an ad hoc way by just simply following our intuition, but it is always a best practice to try to fine tune our abstract thinking with our intuitive understandings in these kind of example. Then we can use of abstract thinking capability to solve problems that are almost impossible to address by solely depending on the intuition. So, it is a good idea to try to see how does the set $\Omega$ look like. The set $\Omega$ will be the set of all finite string of all $T$ letters terminated with $H$. In other words
		\[ \Omega = \set{H,TH, TTH, TTTH, TTTTH, \cdots}. \]
		Then the random variable $N: \Omega \to \Z$ is basically the length of the string. For instance, if $\omega = TTH \in \Omega$, then $N(\omega) = 3$. Let's calculate
		\[ \prob(N = 3) = \prob(\set{\omega \in \Omega: N(\omega) = 3}). \]
		To solve this, we need to define appropriate events and then condition our probability on those events. Define $F_n$ be the event where the $n$ first outcomes are tails. For instance
		\[ F_1 = \set{TH, TTH, TTTH,\cdots},\ F_2 = \set{TTH, TTTH, TTTTH, \cdots},\ \cdots.\]
		And let $E = \set{N=3} = \set{TTH}$. Then we can condition $\prob(E)$ on $F_2$ 
		\[ \prob(E) = \prob(E|F_2) \prob(F_2) + \prob(E|F_2^c) \prob(F_2^c). \]
		Note that $F_2^c = \set{H, TH}$, this $\prob(E|F_2^c) = \prob(E \cap F_2^c)/\prob(F_2^c) = 0$. Now we need to determine $\prob(F_2)$. Again, we can condition this event on $F_1$. Then we can write
		\[ \prob(F_2) = \prob(F_2|F_1)\prob(F_1) + \prob(F_2|F_1^c) \prob(F_1^c). \]
		with the same argument as above $\prob(F_2|F_1^c) = 0$. Combining these equations we will get
		\[ \prob(E) = \prob(E|F_2) \prob(F_2|F_1) \prob(F_1). \]
		Now these probabilities are easy to calculate which leads to the final answer
		\[ \prob(E) = (1-p)(1-p) p.  \]
		And by induction we can conclude
		\[ \prob(\set{N = n}) = (1-p)^n p.  \]
	\end{solution}
\end{example}


\begin{example}
	Suppose that independent trials, each of which results in $m$ possible outcomes with respective probabilities $p_1, p_2, \hdots,p_m$ such that $\sum_{i=1}^{m}p_i = 1$. Are continually performed. Let $X$ be the number of trials needed until each outcome has occurred at least once. Describe the properties of this random variable.
	\begin{solution}
		It is sometime a good idea to try to imagine what does the sample space look like. Let $\Sigma=\set{s_1, s_2, s_3, \hdots, s_m}$ be a set of $m$ distinct symbols. Then each time we are continually performing the experiment, we are getting each of these symbols with corresponding probability $p_m$. Thus the sample space will be the set of all infinite sequences of these symbols. In other words
		\[ \Omega = \set{\text{all infinite sequence of symbols from $\Sigma$}}. \]
		Then the random number $X(\omega)$ for $\omega \in \Omega$ is basically the length of the prefix string of $\omega$ in which any of the symbols in $\Sigma$ has been occurred at least once. 
	\end{solution}
\end{example}



\subsection{Cumulative Distribution of Random Variable}
The notion of the cumulative distribution of a random variable comes handy in most of the future calculations. Also, this distribution can be used to derive other notions of distributions what are extremely important in applications. 

\begin{definition}[Cumulative distribution]
	Let $X$ be a random variable $X:\Omega \to \R$. Then the cumulative distrubition $F: \R \to \R$ is defined as
	\[ F(x) = \prob(\set{X \leq x}).  \]
\end{definition}

\begin{proposition}
	The cumulative distribution of a random variable has the following properties.
	\begin{enumerate}[(i),itemsep=0pt, topsep=5pt]
		\item $\prob(a<X\leq b) = F(b) - F(a).$
		\item $F(x)$ is a non-decreasing function of $x$.
	\end{enumerate}
\end{proposition}
\begin{proof}
	\begin{enumerate}[(i)]
		\item 
		\[ \prob(\set{a<X\leq b}) = \prob(\set{X\leq b} \cap \set{X\leq a}^c) = -\prob(\Omega) + \prob(\set{X\leq b}) + \underbrace{\prob(\set{X\leq a}^c)}_{1-\prob(\set{X\leq a})} = F(b) - F(a).  \]
		\item Let $b_1, b_2 \in \R$ and $b_1 \leq b_2$. Then $\set{X\leq b_1} \subseteq \set{X\leq b_2}$. This implies $$\prob(\set{X\leq b_1}) \leq \prob(\set{X\leq b_2}) \implies F(b_1) \leq F(b_2).$$
		This implies that $F(x)$ is a non-decreasing function. 
	\end{enumerate}
\end{proof}


\section{Probability Generating Function}
In this section we will go through the details of the probability generating function. We start with the following definition.

\begin{definition}[Probability Generating Function]
	Let $ X $ be a random variable with state space $ S = \Z_+ $. Then the probability generating function for this random variable is a function define as
	\[  G_X(s) = \E{s^X} = \sum_{x \in S}s^x \prob(X=x).  \]
\end{definition}

In different areas of mathematics, we often can define something algebraic that is very easy to handle (like differentiation, etc) and carries the important information of the object under study. One of these algebraic symbolic objects is the Tutte polynomial, Chromatic polynomial, matching polynomial, etc. These polynomials are kind of modeling the object under study with tools that are easy to handle. The probability generating function is one of those symbolic objects. Because of the way that is crafted, it carries most of the information about the random variable, while the actual object as a function might have poor properties. This will be more clear in the following proposition. In a nutshell, the probability generating function is more of a symbolic thing rather than actual function with meaning full properties. That is why we generally evaluate this function (and its derivatives) at point 0 or 1. 


\begin{proposition}[Properties of the probability generating function]
	Let $ X $ be a random variable, and $ G_X(s) $ its probability generating function. Then we have
	\begin{enumerate}[(i)]
		\item $ G_X(1) = 1 $.
		\item $ \E{X} = G_X'(1)  $.
		\item $ \var{X} = G_X''(1) - G_X'(1)^2 + G_X'(1) $
		\item Let $X, Y$ be independent random variables. Then we have
		\[  G_{X+Y}(s) = G_X(s) G_Y(s). \]
		\item Let $ X_1, X_2, \cdots $ be iid random variables, and $ N $ be a random variable taking values in $ \Z_+ $. Define $ T = X_1 + X_2 + \cdots + X_N $. Then we have
		\[ G_T(s) = (G_N \circ G_{X_1})(s). \]
	\end{enumerate}
\end{proposition}

\begin{proof}
	The proof for part i,ii, iii, and iv basically follows immediately from the definition. So we will only provide the proof for part iv.\\
	$ T $ is the sum of $ N $ iid random variables where $ N $ is itself a random variable. We can make it a normal variable by using the law of total probabilities.
	\[ G_T(s) = G_{\sum_i^N X_i}(s) = \sum_{n=0}^{\infty}  G_{\sum_i^n X_i}(s) \prob(N = n)  = \sum_{n=0}^{\infty}(G_{X_1})^n\prob(N=n) = G_N(G_{X_1})(s) \]
	and this completes the proof.
\end{proof}

The item (iv) in the proposition above is very important, as it makes the hard calculations easy to do. See the following example for more details.

\begin{example}
	We select a number $ N $ from $ \set{1,2,3,\cdots,100} $ randomly and then generate $ N $ random numbers $ X_1, X_2, \cdots X_N $ from the distribution $ \operatorname{Unif}[0,1]$. Then we compute $ T = X_1 + X_2 + \cdots +X_N $. What is the average of $ T $? 
	
	\begin{solution}
		We know that 
		\[ \E{T} = G'_T(1). \]
		Thus we need to calculate the probability generating function $ G_T(s) $. From part (iv) of the proposition above we know that $ G_T = G_N \circ G_{X_1} $. Thus we will have
		\[ G'_T = G_{X_1}' G_N'\circ G_{X_1}.  \]
		Thus evaluating at $ s=1 $ we will have
		\[ G'_T(1) = G_{X_1}'(1) G_N'(\underbrace{G_{X_1}(1)}_{1}) = \E{X_1} \E{N}. \]
		On the other hand we have $ \E{N} = 50 $ and $ \E{X_1} = 1/2 $. Then 
		\[ \E{T} = 25. \]
		The following figure shows this fact (i.e. convergence of the average value of $ T $ to 25 when we increase the number of experiments.)
		\begin{figure}[h!]
			\centering
			\includegraphics[width=0.5\linewidth]{Images/convergenceOfAverageExp.pdf}
		\end{figure}
		
 	\end{solution}
 	
\end{example}


\section{Some more deep notes}
This section has the definitions and discussions that I leaned through a course on the rigorous probability.

\begin{definition}[Algebra or Field of a Set]
	A field of sets is a pair $ (X,\mathcal{F}) $, where $ X $ is a set and $ \mathcal{F} $ is collection of subsets of $ X $ such that 
	\begin{enumerate}[(i),noitemsep]
		\item $ \emptyset \in \mathcal{F} $,
		\item $ A \in \mathcal{F} \implies A^c \in \mathcal{F} $,
		\item $ A_1, A_2 \in \mathcal{F} \implies A_1 \cup A_2 \in \mathcal{F} $.
	\end{enumerate}
	\begin{remark}
		It follows from the definition above that $ \Omega \in \mathcal{F} $ and also $ A_1 \cap A_2 \in \mathcal{F} $ if $ A_1,A_2 \in \mathcal{F} $.
	\end{remark}
\end{definition}
Note that in the notion of the algebra of a set, the algebra is closed only for finite intersections or finite unions. 

\begin{definition}[$ \sigma\text{-algebra} $ of a set]
	The $ \sigma\text{-algebra} $ of a set is an algebra of the set such that it is also closed under countable union and intersection.
\end{definition}

\begin{definition}[Semi-algebra]
	The collection $ \mathcal{I} $ is a semi-algebra of the subsets of $ \Omega $ if
	\begin{enumerate}[(i)]
		\item $ \emptyset \in \mathcal{I} $,
		\item $ A_1, A_2 \in \mathcal{I} \implies A_1 \cap A_2 \in \mathcal{I} $,
		\item For $ A \in \mathcal{I} $, $ A^c = \dot\cup_{i=1}^{n}A_i $ for some $ n \in \N $. 
	\end{enumerate}
\end{definition}


\begin{theorem}[Extension Theorem]
	Let $ \Omega  $ be a set, and $ \mathcal{I} $ be a semi-algebra of the subsets of it. Let $ P: \mathcal{I} \to [0,1] $ such that is satisfies the following properties
	\begin{enumerate}[(i),nosep]
		\item $ P(\emptyset) = 0  $,
		\item $ P(\Omega) = 1 $,
		\item $ P(\dot\cup_{i=1}^{n} A_i) \geq \sum_{i=1}^n P(A_i) $ for $\qquad  A_1,\cdots,A_n, \dot\cup_{i=1}^{n} A_i \in \mathcal{I}$.
		\item $ P(A) \leq \sum_i P(A_i) $ for $ A_1,\cdots \in I, A \subseteq \cup_i A_i $.
	\end{enumerate}
	Then there exist a valid probability space $ (\Omega, \mathcal{M}, \prob^*) $ such that $ \mathcal{M} \supset \mathcal{I} $ and $ \prob(A)= \prob^*(A)$ for all $ A \in \mathcal{I} $.
\end{theorem}
\begin{remark}
	By ``there exists a valid probability space'' we mean that $ \mathcal{M} $ is a $ \sigma\text{-algebra} $ and $ \prob^* $ is a countably additive probability measure. Also, it is worth mentioning that the property $ (iii) $ is called \emph{finite super additivity}.
\end{remark}
In the following propositions we will see more easy-to-check characterizations of this theorem.


\section{Summary and Tricks}
\begin{summary}[Improving finite additivity to countable additivity]
	In question \autoref{prob:countableAdditivity} we improve the finite additivity property of $ \prob^* $ to countable additivity, and we used two facts for that purpose. First, use the monotnonicity property, and second, use the countable sub additivity property. I.e. if we know that for $ A_1, A_2, \cdots, A_n \in \mathcal{M} $ disjoint we have
	\[ \prob^*(\bigcup_{i=1}^{n} A_i) = \sum_{i=1}^n \prob(A_i). \]
	Then let $ A_1,\cdots $ be a countable collection of disjoint sets in $ \mathcal{M} $. So for any $ m\in \N $ we have
	\[ \sum_{n<m} \prob^*(A_n) = \prob^*(\bigcup_{n<m} A_n) \leq \prob^*(\bigcup_n A_n), \]
	where for the last inequality we used the monotonicity property of $ \prob^* $. Since this is true for all $ m\in \N $ we can conclude that 
	\[ \sum_{n} A_n \prob^*(A_n) \leq \prob^*(\bigcup_n A_n). \]
	Now form the countable subadditivity we have
	\[ \sum_{n} A_n \prob^*(A_n) \geq \prob^*(\bigcup_n A_n). \]
	This implies 
	\[ \sum_{n} A_n \prob^*(A_n) = \prob^*(\bigcup_n A_n). \]
\end{summary}

\begin{summary}[Quantifiers to Cup and Cap!]
	Let $ \set{A_i}_{i\in I} $ be a collection of sets. Then $ x\in \bigcup_i A_i $ means that $ \exists n \in I $ such that $ x \i A_n $. Similarly, $ x\in \bigcap_i A_i $ means that $ \forall n \in I $ we have $ x \in A_n $. According to this, we can construct much more complicated statements. For instance, 
	\[ x \in \bigcup_{n=1}^{\infty} \bigcap_{k>n}^{\infty} \bigcup_{m>k}^{\infty}{A_k} \]
	in words meas that 
	\[ \exists n \in \N \st \forall k > n \ \exists m >k \st x \in A_k. \]
	This makes these statements more easier to follow. We have used this in Problem \autoref{prob:capcupcapcup}.
\end{summary}

\begin{summary}[Pre-image v.s. Image]
	The pre-image preserves the union, intersection, and complement, i.e.
	\[ \inv{f}(A\cup B) = \inv{f}(A) \cup \inv{f}(B), \quad \inv{f}(A\cap B) = \inv{f}(A)\cap \inv{f}(B), \quad \inv{f}(A^c) = (\inv{f}(A))^c.  \]
	But the same is NOT true in the case of image. image preserves the union but not necessarily the intersection, or complement (for which we need extra properties like being injective or surjective).
\end{summary}

\section{Solved Problems}
\begin{problem}[From Ross]
	Ben can talk a course in compute science or chemistry. If she takes the computer science course, then she will get A grade with probability $\frac{1}{2}$. If she takes the chemistry course, then she will get A grade with probability $\frac{1}{3}$. She decides to base her decision on the flip of a fair coin. What is the probability that she gets an A in chemistry?
\end{problem}
\begin{solution}
	We define the following events
	\begin{quote}
		$A$: she will get an A grade.\\
		$CO$: she will take the computer science course.\\
		$CH$: she will take the chemistry course.
	\end{quote}
	Then the question is basically asking for $\prob(A \cap CH)$. We can compute it by
	\[ \prob(A \cap CH) = \prob(A|CH)\prob(CH) = \frac{1}{3}\cdot\frac{1}{2} = \frac{1}{6}. \]
\end{solution}

\begin{problem}
	And urn contains seven black balls and five white balls. We draw two times from the urn. Given that the each ball has the same probability to be drawn, what is the probability that both balls drawn are black?
\end{problem}
\begin{solution}
	This question nicely demonstrates the fact that there are many ways to define the event spaces, and not all of them are very useful in computing the desired probability. Define
	\begin{quote}
		$E$: two drawn balls are black.
	\end{quote}
	The question is in fact asking $\prob(E)$. But this even is not very useful in any progress with the solution. Thus we need to define some finer events
	\begin{quote}
		$E_1$: The first drawn ball is black.\\
		$E_2$: The second drawn ball is black.
	\end{quote}
	It is clear that $E = E_1 \cap E_2$. These two finer events allows us to compute the probability of interest given the data we have in our hand.
	\[ \prob(E_1 \cap E_2) = \prob(E_2 | E_1) \prob(E_1) = \frac{6}{11} \cdot \frac{7}{12} \]
\end{solution}

\begin{problem}[From Ross]
	Three men at a party through their hats into the center of the room, and then, after mixing the hats, each pick a hat randomly. What is the probability if non of them get their own hat back.
\end{problem}
\begin{solution}
	There are a million ways to tack a probability problem. We can construct a suitable sample space and then compute the probabilities explicitly, or we can use the properties of the probability function to computer the desired probability without any need to construct the sample space. Here, we will demonstrate two ways.
	
	\textbf{Solving the problem by utilizing the properties of the probability function.} First we need to define some suitable events. There are again many ways to define event sets and each have their own pros and cons. We proceed with the following definition.
	\begin{quote}
		$E_i$: The person $i$ ``selects'' his own hat.  
	\end{quote}
	Also, with this particular construction of the event sets, it is much more easier to compute the complementary probability of the desired probability first and then compute the desired one by simply subtracting it from 1. The complement of the event ``no men gets his own hat back'' is ``at least one man gets his hat back'' which is $\prob(E_1\cup E_2 \cup E_3)$. To compute the terms of this we first need to calculate $\prob(E_i)$, $\prob(E_i \cap E_j)$ where $i\neq j$ and also $\prob(E_1 \cap E_2 \cap E_3)$. We know that $\prob(E_i) = 1/3$ for $i=1,2,3$. That is because it is equally likely he selects any of the hats at the center. For $\prob(E_i\cap E_j)$ we can write
	\[ \prob(E_i\cap E_j) = \prob(E_i|E_j)\prob(E_j) = \frac{1}{2}\cdot \frac{1}{3} =  \frac{1}{6}.   \]
	In which we used the fact that $\prob(E_i|E_j)$ is $\frac{1}{2}$ for distinct $i,j$. That is because given person $j$ selects his hat correctly, then there are two possibilities for $E_i$ to select his hat (he can pick the correct one or the wrong one). Lastly for $\prob(E_1\cap E_2\cap E_3)$ we write
	\[ \prob(E_1\cap E_2\cap E_3) = \prob(E_1|E_2\cap E_3)\prob(E_2\cap E_3) = \prob(E_1|E_2\cap E_3) \prob(E_2 | E_3) \prob(E_3) = 1 \cdot \frac{1}{2} \cdot \frac{1}{3} = \frac{1}{6}.  \]
	Thus 
	\[ \prob(E_1 \cup E_2 \cup E_3) = (1) - (1/2) + (1/6) = \frac{4}{6}. \]
	Then the probability of interest will be
	\[ \prob(E) = 1-\frac{4}{6} = \frac{1}{3}. \]
	
	\textbf{Solving by constructing a sample space.} A suitable sample space for this problem can be the set of all permutations on three letters. This set is
	\[ \Omega = 
	\set{\begin{pmatrix}
			a & b & c \\
			\boxed{a} & \boxed{b} & \boxed{c}
		\end{pmatrix},
		\begin{pmatrix}
			a & b & c \\
			\boxed{a} & c & b
		\end{pmatrix},
		\begin{pmatrix}
			a & b & c \\
			b & a & \boxed{c}
		\end{pmatrix},
		\begin{pmatrix}
			a & b & c \\
			b & c & a
		\end{pmatrix},
		\begin{pmatrix}
			a & b & c \\
			c & a & b
		\end{pmatrix},
		\begin{pmatrix}
			a & b & c \\
			c & \boxed{b} & a
	\end{pmatrix}}.
	\]
	Note that the elements in the box represents the fixed point of the permutation. The probability of interest is basically the number of permutations that has no fixed point. As it is clear from the set $\Omega$, the probability is
	\[ \prob(E) = \frac{2}{6} = \frac{1}{3}. \]
\end{solution}

\begin{problem}[Conditional probability mass function (from Ross)]
	Let $ X,Y $ be two random variables with the joint probability mass function given as 
	\[ P(1,1) = 0.5 \qquad P(1,2)=0.1,\qquad P(2,1)=0.1, \qquad P(2,2)=0.3. \]
	Calculate the conditional probability mass function of $ X $ given that $ Y = 1 $.
\end{problem}
\begin{solution}
	We will use the following identity
	\[ P_{X|Y}(x|y) = \prob(X=x|Y=y) = \frac{\prob(X=x,Y=y)}{\prob(Y=y)}. \]
	Observe that 
	\[ \prob(Y=y) = \sum_x \prob(Y=y,X=x) \]
	thus $ \prob(Y=1) = 0.5 + 0.1 = 0.6. $
	So we will have
	\[ P_{X|Y}(1|1) = \frac{0.5}{0.6} = \frac{5}{6}, \qquad P_{X|Y}(2|1) = \frac{0.1}{0.6} = \frac{1}{6}. \]
\end{solution}

\begin{problem}[Conditional probability mass function for geometric random variables (from Ross)]
	Let $ X_1,X_2 $ be two independent random variables with geometric distributions with parameters $ (n_1,p) $ and $ (n_2,p) $. Calculate the conditional probability mass function of $ X_1 $ given that $ X_1+X_2 = m $.
\end{problem}
\begin{solution}
	First, observe that $ Y = X_1 + X_2 $ is a binomial distribution with parameter $ (n_1+n_2, p) $. Thus we can write
	\[ P_{X_1|Y}(k|m) = \prob(X_1 = k | Y = m) = \frac{\prob(X_1 = k, X_1+X_2 = m)}{\prob(X_1+X_2 = m)} = \frac{\prob(X_1=k, X_2 = m-k)}{\prob(Y = m)} \]
	Since the random variables $ X_1 $ and $ X_2 $ are independent, we can write
	\[ P_{X_1|Y}(k|m) = \frac{\prob(X_1=k)\prob(X_2 = m-k)}{\prob(Y=m)} = \frac{\binom{n_1}{k}\binom{n_2}{m-k}}{\binom{n_1+n_2}{m}}. \]
\end{solution}

\begin{problem}[Conditional probability mass function for Poisson random variables (from Ross)]
	Let $ X,Y $ be two independent Poisson random variables with parameters $ \lambda_1 $ and $ \lambda_2 $ respectively. Calculate the conditional probability mass function for $ X $ given that $ X_1 + X_2 = n $.
\end{problem}
\begin{solution}
	First observe that $ Z = X + Y $ is a Poisson random variable with parameter $ \lambda_1 + \lambda_2 $. Thus we will have
	\[ P_{X|X+Y}(m|n) = \frac{\prob(X=m|X+Y=n)}{\prob(X+Y = n)} = \frac{\prob(X=m,Y=n-m)}{\prob(X+Y = n)} \]
	Given that $ X,Y $ are independent random variables then we can write
	\[ P_{X|X+Y}(m,n) = \frac{\prob(X=m)\prob(Y=n-m)}{\prob(X+Y=n)} = \frac{\lambda_1^n \lambda_2^{n-m}n!}{m!(n-m)!(\lambda_1+\lambda_2)^n} = \binom{n}{m} (\frac{\lambda_1}{\lambda_1+\lambda_2})^m ( \frac{\lambda_2}{\lambda_1+\lambda_2})^{n-m} \]
	Thus the conditional probability mass function of $ X $ given that $ X+Y = n $ will be a binomial random variable with parameter $ (n,\lambda_1/(\lambda_1+\lambda_2)) $. We can now easily compute the conditional expectation value as
	\[ \E{X|X+Y = n} = \frac{n\lambda_1}{\lambda_1 + \lambda_2} \]
\end{solution}

\begin{problem}
	Let $ X,Y $ be two discrete random variables. Prove that 
	\[ \E{\E{X|Y}} = \E{X}. \]
\end{problem}
\begin{solution}
	We start with the definition of the expectation of a discrete random variable.

	\begin{align*}
		\E{\E{X|Y}} &= \sum_y \E{X|Y=y} \prob(Y=y) = \sum_y \sum_x x\prob(X=x|Y=y)\prob(Y=y) \\
		& = \sum_{x,y} x\prob(X=x,Y=y) = \sum_x x \sum_y \prob(X=x,Y=y) = \sum_x x\prob(X=x) = \E{X}
	\end{align*}
\end{solution}

\begin{problem}[The expectation of a random number of random variables (from Ross)]
	Let the expected number of injures in an industrial field be 4 per week. Also, assume that the number of workers injured at each incidence are independent random variables with average 2. Then what is the expected number of injuries in one week?
\end{problem}
\begin{solution}
	Let $ X_1,X_2,\cdots $ be i.i.d random variables representing the number of workers injured at each incidence. We are interested in 
	\[ \E{X_1+\cdots+X_N} \]
	where $ N $ is a random variable representing the number of incidences occurred in a week. By the law of conditional expectation we can write
	\[ \E{X_1 + \cdots + X_N} = \sum_n \E{X_1+\cdots+X_n}\prob(N=n) = \sum_n n\E{X} \prob(N=n) = \E{X} \E{N}.\]
	Thus the average number of workers injured in a week will be 8. 
\end{solution}

\begin{problem}[An alternative way to compute the expectation of a geometric random variable]
	Consider a coin with probability $ p $ to fall heads. What is the expectation value of the number of tosses required until we get the first head?
\end{problem}
\begin{solution}
	Let $ X_1,X_2,\cdots $ be Bernoulli random variables with parameter $ p $. Let $ N $ be a random variable denoting the number of tosses required until we get the first heads. We can condition the expected value of $ E $ to the first outcome.
	\[ \E{N} = \E{N|X_1 = H }\underbrace{\prob(X_1 = H)}_{=p} + \E{N|X_1=T}\underbrace{\prob(X_1=T}_{=1-p})  \]
	Observe that 
	\[ \E{N|X_1=H} =1 ,\qquad \E{N|X_1=T} = 1+\E{N}.\]
	Thus we will have
	\[ \E{N} = \frac{1}{p}. \]
\end{solution}

\begin{problem}[Trapped miner (from Ross)]
	A miner is trapped in the mine and has three doors in front of him. He is equally likely to choose any of the three. The first door will take him to safety after 2 hours of walking, the second door will take him to the mine again after 3 hours of walking, and the third door will take him to the mine again after 5 hours of walking. What is the expected time that the miner will arrive to safety?
\end{problem}
\begin{solution}
	Let $ X_1,X_2,\cdots $ be random variables denoting the doors that the miner choose at each time that he attempts to escape. Furthermore, let $ T $ be a random variable showing the the time it takes for the miner to escape. To calculate $ \E{T} $ we can condition it on the first door choice. I.e.
	\[ \E{T} = \E{T|X_1 =1}\prob(X_1=1) + \E{T|X_1 =2}\prob(X_1=2)+\E{T|X_1 =3}\prob(X_1=3) \]
	Observe that 
	\[ \prob(X_1=1) = \prob(X_1=2) = \prob(X_1=3) = 1/3. \]
	Also
	\[  \E{T|X_1 =1} = 2,\qquad  \E{T|X_1 =2} = 3+\E{T}, \qquad \E{T|X_1 =3} = 3+\E{T}. \]
	Thus we will have
	\[ \E{T} = 10. \]
	So on average it will take the miner to exit the mine in 10 hours. Note that this does not guarantee that the miner will eventually escape. It is possible that we will get in trap by repeatedly choosing the door number 3.
\end{solution}
 
\begin{problem}[From Rosenthal]
	Suppose that $ \Omega = \set{1,2}, $ with $ \prob(\emptyset) = 0 $ and $ \prob(\set{1,2}) = 1 $. Suppose $ \prob(\set{1}) = \frac14 $. Prove that $ \prob $ is countably additive if and only if $ \prob(\set{2})=\frac34 $.
\end{problem}
\begin{solution}
	The proof has two parts
	\begin{itemize}
		\item [$ \boxed{\Longrightarrow} $] Since $ \prob $ is countably additive, then 
		\[ \prob(\set{1} \dot\cup \set{2}) = \prob(\set{1}) + \prob(\set{2}) = 1. \]
		This implies $ \prob(\set{2}) = 3/4 $.
		\item [$ \boxed{\Longleftarrow} $] Assume $ \prob(\set{2}) = 3/4 $. Then it is very straightforward to check that for every disjoint subset $ A,B \subset \Omega $, we have
		\[ \prob(A \dot\cup B) = \prob(A) + \prob(B). \]
		Thus we conclude that $ \prob $ is countably additive.
	\end{itemize}
\end{solution}

\begin{problem}[From Rosenthal]
	Suppose $ \Omega = \set{1,2,3} $ and $ \mathcal{F} $ is a the collection of all subsets of $ \Omega $. Find (with proof) necessary and sufficient conditions on the real numbers $ x,y,z $ such that there exists a countably additive probability measure $ \prob $ on $ \mathcal{F} $ such that $ x = \prob\set{1,2}, y=\prob\set{2,3}, z=\prob\set{1,3} $.
\end{problem}
\begin{solution}
	To find the necessary conditions, we assume that $ \prob $ is an additive probability measure. Let $ a = \prob\set{1}, b=\prob\set{2} $, and $ c = \prob\set{3} $. Then the countable additivity implies
	\[ a+b=x,\qquad b+c=y,\qquad a+c=z. \]
	Then due to countable additivity, and the fact that $ \prob $ is a probability measure (i.e. $ \prob\set{1,2,3} = 1 $), we have $ a+b+c = 1 $, thus we need to have
	\[ x+y+z = 2. \tag{\eighthnote} \]
	Further, we solve the $ a,b,c $ in terms of $ x,y,z $ are require the singleton probabilities to be positive. We have
	\[ a = \frac{x-y+z}{2},\qquad b = \frac{x+y-z}{2},\qquad c=\frac{-x+y+z}{2}. \]
	One of the necessary conditions is also to have
	\[ x-y+z\geq0,\qquad x+y-z\geq0,\qquad -x+y+z \geq0. \tag{\twonotes}  \]
	The two conditions ($ \eighthnote $) and $ (\twonotes) $  together are the necessary and sufficient conditions for $ \prob $ to be a valid probability measure.
\end{solution}

\begin{problem}[From Rosenthal]
	Suppose that $ \Omega = \N $ is the set of positive integers, and $ \prob $ is defined for all $ A\subseteq \Omega $ by $ \prob(A) = 0 $ if $ A $ is finite, and $ \prob(A) = 1 $ if $ A $ is infinite. Is $ \prob $ finitely additive?
\end{problem}
\begin{solution}
	Not it is not. Consider the partitioning of the set $ \Omega $ by the even $ E $ and odd $ O $ integers.
	\[ \prob(\Omega) = \prob(E) + \prob(O) \implies 1 = 2, \]
	which is not true. Thus $ \prob $ is not finitely additive.
\end{solution}

\begin{problem}[From Rosenthal]
	Suppose that $ \Omega = \N $, and $ \prob $ is defined for all $ A \subseteq \Omega $ by $ \prob(A) = \abs{A} $ if $ A $ is finite, and $ P(A)=\infty $ if $ A $ is infinite.  This $ P $ is of course not a probability measure (in fact it is counting measure), however we can still ask the following: (be the convention $ \infty+\infty = \infty $)
	\begin{enumerate}[(I)]
		\item Is $ \prob $ finitely additive?
		\item Is $ \prob $ countably additive?
	\end{enumerate}
\end{problem}
\begin{solution}
	\begin{enumerate}[(I)]
		\item Yes. $ \prob $ being finitely additive is equivalent being additive for disjoint $ A,B \subset \Omega $. There are three cases for these choices
		\begin{enumerate}[(i)]
			\item $ A,B $ are both finite. In this case $ \prob(A\dot\cup B) = \prob(A) + \prob(B) $ since $ 0=0+0 $.
			\item $ A,B $ are both infinite. In this case $ \prob(A\dot\cup B) = \prob(A) + \prob(B) $ since $ \infty+\infty = \infty $.
			\item One of the sets $ A,B $ is infinite. Then $ \prob(A\dot\cup B) = \prob(A) + \prob(B) $ since $ 0+\infty = \infty. $
		\end{enumerate}
		\item No. We will show this by counterexample. We can write $ \Omega = \dot\bigcup_{i\in \N}\set{i} $. Then the countable additivity implies
		\[ \prob(\Omega) = \prob(\dot\bigcup_{i\in \N}\set{i}) \implies 1 = 0.\]
		which is not true.
	\end{enumerate}
\end{solution}


\begin{problem}[From Rosenthal]
	Let $ \mathcal{I} $ be the set of all intervals in $ [0,1] $ (open, closed, half-open, singleton, empty set). Show that $ \mathcal{I} $ is a semi-algebra.
\end{problem}
\begin{solution}
	By definition of $ \mathcal{I} $ we have $ \emptyset\in \mathcal{I} $. Let $ A_1, A_2 $ be two intervals in $ [0,1] $. If $ A_1,A_2 $ are disjoint, then $ A_1\cap A_2 \in \mathcal{I} $. If they are not disjoint, then without loss of generality we can assume that 
	\[ A_1 = \set{x\in[0,1]\ |\ a<x<b}, A_2 = \set{x\in[0,1]\ |\ c<x<d}, \]
	where $ a<c<b<d $. Thus $ A_1\cap A_2 = (c,b) $. So $ \mathcal{I} $ is closed under finite intersection. The proof is the same for any other choices of $ A_1,A_2 $ (i.e. being closed set, etc). To show the third property, again, without the loss of generality, let $ A = (a,b) $. Then $ A^c = (-\infty,a] \dot\cup [b,\infty) $. For other choices of $ A $ (i.e. being closed, etc) we will have a similar argument. Thus we conclude that the collection $ \mathcal{I} $ is a semi-algebra of the subsets of $ [0,1] $.
\end{solution}

\begin{problem}[From Rosenthal]
	Let $ \mathcal{I} $ be the semi-algebra consisting of all intervals in $ [0,1] $. Define
	\[ \mathcal{B}_0 = \set{\text{all finite unions of elements of $ \mathcal{I} $}.} \]
	Show that $ \mathcal{B}_0 $ is not a $ \sigma\text{-algebra} $.
\end{problem}
\begin{solution}
	Along with many other sets, $ \mathcal{I} $ contains all of the singletons, so does $ \mathcal{B}_0 $. Consider the following collection
	\[ \mathcal{A} = \set{\set{x}\ :\ x \in \Q \cap [0,1]}. \]
	By definition, all of the sets in the collection $ \mathcal{A} $ belongs to $ \mathcal{B}_0 $. However, the following countable union
	\[ \dot\bigcup_{A \in \mathcal{A}} A = [0,1] \cap \Q \]
	does not belong to $ \mathcal{B}_0 $ (as it is not possible to generate with only finite unions of the elements of singletons in $ \mathcal{I} $).
\end{solution}

\begin{problem}[From Rosenthal]
	Prove that the outer measure $ \prob^* $ is countably sub-additive, i.e.
	\[ \prob^*(\bigcup_{n=1}^{\infty} B_n) \leq \sum_{n=1}^{\infty} \prob^*(B_n) \qquad \text{for any $ B_1,B_2,\cdots \in \Omega $}.\]
\end{problem}
\begin{solution}
	This problem is the proof of Lemma 2.3.6 in Rosenthal. See the text for more context. A very quick review on the context is that we have a semi-algebra $ \mathcal{I} $ of the subsets of $ \Omega $, and we have the function $ \prob: \mathcal{I} \to [0,1] $ that satisfies the properties required for the extension theorem, hence there exist a valid probability space $ (\Omega, \mathcal{M}, \prob^*) $, where $ \mathcal{M} $ is a $ \sigma\text{-algebra} $ and $ \prob^* $ is a probability measure (which is also the outer measure). The proof of this question is as follows. 
	
	Fix $ \epsilon>0 $. Since the outer measure is the infimum of the sum of the probabilities on all $ \mathcal{I} $ covers, then for each $ B_n $ we can find a collection $ \set{C_{nk}} $ where $ C_{nk}\in\mathcal{I} $ such that 
	\[ \sum_k \prob(C_{nk}) \leq \prob^*(B_n) + \epsilon2^{-n}. \]
	On the other hand, since $ \set{C_{nk}}_{nk} $ covers $ \bigcup_n B_n $, then again from the properties of inf we have
	\[ \prob^*(\bigcup_n B_n) \leq \sum_{nk} \prob(C_{nk}). \]
	combining these two we will get
	\[  \prob^*(\bigcup_n B_n) \leq \sum_n \prob^*(B_n) + \epsilon. \]
	Since this is true for all $ \epsilon>0 $, then it implies that 
	\[  \prob^*(\bigcup_n B_n) = \sum_n \prob^*(B_n). \]
\end{solution}

\begin{problem}[From Rosenthal]
	\label{prob:countableAdditivity}
	If $ A_1,A_2,\cdots \in \mathcal{M} $ are disjoint, then prove that 
	\[ \prob^*(\dot\bigcup_n A_n) = \sum_n \prob^*(A_n). \]
\end{problem}
\begin{solution}
	First, we start to show the finite additivity, and then using the properties of monotnonicity and sub-additivity, we will prove the countable additivity as well. Let $ A_1, A_2 \in \mathcal{M} $ disjoint. In particular, since $ A_1 \in \mathcal{M} $, from the definition of $ \mathcal{M} $ (see page 12 Rosenthal), then
	\[ \prob^*(A_1 \cup A_2) = \prob^*(A_1^c \cap (A_1\cup A_2)) + \prob^*(A_1 \cap (A_1 \cup A_2)) = \prob^*(A_2) + \prob^*(A_1). \]
	This implies that for any finite disjoint collection of $ A_i $ we have the additivity property (by induction). Now for any $ m \in \N $ we have
	\[  \sum_{n<m} \prob^*(A_n)  = \prob^*(\bigcup_{n\leq m}A_n)  \leq \prob^*(\bigcup_n A_n) \]
	where the last inequality follows form the monotnonicity property of $ \prob^* $. Since this is true for all $ m \in \N $, then we conclude that 
	\[ \prob^*(\bigcup_n A_n) \geq \sum_n \prob^*(A_n). \]
	On the other hand, from the sub-additivity property we have
	\[ \prob^*(\bigcup_n A_n) \leq \sum_n \prob^*(A_n). \]
	These two implies that 
	\[ \prob^*(\bigcup_n A_n) = \sum_n \prob^*(A_n). \]
\end{solution}

\begin{problem}[From Rosenthal]
	Let $ \mathcal{M} $ be the $ \sigma\text{-algebra} $ we get from the extension theorem, where by definition it contains all of the sets like $ A \in \Omega $ for which the outer measure is additive on the union of $ A \cap E $ and $ A^c \cap E $ for $ \forall E \subset \Omega  $. In other words
	\[ \mathcal{M} = \set{A \subseteq \Omega\ :\ \prob^*(A\cap E) + \prob^*(A^c \cap E) = \prob^*(E) \quad \text{for all } E \subset \Omega}. \]
	Prove that $ \mathcal{M} $ is an algebra.
\end{problem}
\begin{solution}
	Let $ A = \Omega $. Then
	\[ \prob^*(A \cap E) + \prob^*(A^c\cap E) = \prob^*(E) + \prob^*(\emptyset) = \prob^*(E). \]
	So we conclude that $ \Omega \in \mathcal{M} $. Also, it follows immediately from the definition of $ \mathcal{M} $ that if $ A \in \mathcal{M} $ then $ A^c \in \mathcal{M} $. Now it remains to show if $ A_1, A_2 \in \mathcal{M} $ then $ A_1\cap A_2 \in \mathcal{M} $. Let $ E \subset \Omega $. Then 
	\begin{align*}
		&\prob^*(E \cap (A_1 \cap A_2)) + \prob^*(E \cap (A_1 \cap A_2)^c ) \\
		&= \prob^*(E\cap (A_1\cap A_2)) + \prob^*(E\cap A_1^c \cap A_2) + \prob^*(E\cap A_1 \cap A_2^c) + \prob^*(E\cap A_1^c \cap A_2^c) \\
		&\leq \prob^*(E\cap A_1\cap A_2) + \prob^*(E \cap A_1^c \cap A_2) + \prob^*(E \cap A_1 \cap A_2^c) + \prob^*(E\cap A_1^c \cap A_2^c)\\
		&=\prob^*(E\cap A_2) + \prob^*(E\cap A_2^c) \qquad \text{(because $ A_1 \in \mathcal{M} $)} \\
		&=\prob^*(E) \qquad \text{(because $ A_2 \in \mathcal{M} $)}.
	\end{align*}
	On the other hand, from the sub-additivity property we know that 
	\[ \prob^*(E\cap (A_1\cap A_2)) + \prob^*(E \cap (A_1\cap A_2)^c) \geq \prob^*(E). \]
	Thus we conclude that 
	\[ \prob^*(E\cap (A_1\cap A_2)) + \prob^*(E\cap (A_1\cap A_2)^c) = \prob^*(E). \]
	This implies that $ A_1\cap A_2 \in \mathcal{M} $ and this finishes the proof.
\end{solution}


\begin{problem}[From Rosenthal]
	Let $ A_1,A_2,\cdots \in \mathcal{M} $ be disjoint. For each $ m\in \N $, let $ B_m = \bigcup_{n\leq m} A_n $. Prove that for all $ m\in \N $, and for all $ E \subseteq \Omega $ we have
	\[ \prob^*(E\cap B_m) = \sum_{n\leq m} \prob^*(E\cap A_n). \]
\end{problem}
\begin{solution}
	First, observe that this statement is true for $ m=1 $ in a trivial way. For $ m=2 $, since $ A_2 \in \mathcal{M} $, then we can expand $ E\cap B_2 $ according to $ A_2 $, i.e.
	\[ \prob^*(E\cap B_2) = \prob^*((E\cap B_2)\cap A_2) + \prob^*((E \cap B_2)\cap A_2^c) \]
	On the other hand $ (E\cap B_2)\cap A_2 = E \cap A_2 $ and $ (A\cap B_2)\cap A_2^c = E\cap B_1 = E\cap A_1 $. Thus we can write
	\[ \prob^*(E\cap B_2) = \prob^*(E\cap A_1) + \prob^*(E\cap A_2). \]
	In general, for $ m \in \N $ we can write
	\[ \prob^*(E\cap B_m) = \prob^*(E\cap A_m) + \prob^*(E\cap B_{m-1}). \]
	Thus using induction we can write
	\[ \prob^*(E\cap B_m) = \sum_{n\leq m }\prob^*(E\cap A_n). \]
\end{solution}

\begin{problem}[From Rosenthal]
	In this question covers some of the proves for constructing a uniform probability measure on $ \Omega = [0,1] $. Let $ \mathcal{I} $ be the set of all intervals in $ \Omega $, and let $ \mathcal{P}:\mathcal{I} \to [0,1] $ be a function that assigns the length of an interval to that interval. We want to prove that $ \mathcal{P} $ satisfies the property (2.3.3) of extension theorem (2.3.1) in Rosenthal. I.e. we want to prove that for $ A, A_1,\cdots \in \mathcal{I} $ such that $ A \subset \cup_{i}A_i$ satisfies 
	\[ \prob(A) \leq \sum_{i} \prob(A_i). \]
\end{problem}
\begin{solution}
	We will do this in three parts. 
	\begin{enumerate}[(i)]
		\item Step 1. First, we prove that for any finite $ A, A_1,\cdots,A_n \in\mathcal{I} $ collection where $ A \subset \cup_{i=1}^{n} A_i $ we have
		\[ \prob(A) \leq \sum_{i=1}^{n} \prob(A_i). \]
		To see this let $ A_1,A_2, A \in \mathcal{I} $ such that $ A \subset A_1 \cup A_2 $. We also assume that $ A_1\cap A \neq \emptyset $ as well as $ A_2 \cap A \neq \emptyset $. This is to ensure that we do not have redundant interval in our collection that does not cover $ A $. Note that from any collection of intervals we can put aside the redundant intervals and do our reasoning here and then finally at the last step consider the redundant intervals as well. So our assumption above does not lose the generality of the proof. Let $ a_i, b_i $ represent the left (right) endpoints of the intervals $ A_i $ and $ a_0,b_0 $ represent the left (right) endpoints of the interval $ A $. In order to the intervals $ A_1, A_2 $ to cover $ A $ white neither of them are redundant we need to have
		\[ \min\set{a_1,a_2} \leq a_0 \leq a_2 \leq b_1 \leq b_0 \leq \max\set{b_1,b_2}. \]
		Then it follows that 
		\[ b_0 - a_0 \leq (b_1 - a_1) + (b_2 - a_2). \]
		Thus this implies that 
		\[ \prob(A) \leq \prob(A_1) + \prob(A_2). \]
		We can generalize this by induction to any finite number of intervals.
		\item Step 2. We now want to prove that for any countable \emph{open} intervals $ A_1,A_2,\cdots \in \mathcal{I} $ such that $ A \subset \cup_n A_n $ for $ A \in \mathcal{I} $ closed, we have
		\[ \prob(A) \leq \sum_n \prob(A_n). \]
		To see this, we will use the Heine-Borel theorem. Since the collection $ \set{A_1,A_2,\cdots} $ is an open cover for the closed set $ A $. if $ A $ is the whole space $ \Omega $, then the inequality that we want to show follows immediately (LHS is 1 while RHS is infinite). However, if $ A $ is not the whole space, then it is bounded. Thus $ A $ is closed and bounded, hence compact (by Heine-Borel). So the open cover has a finite sub-cover and this completes the proof by reducing this case to case (i) above.
		\item Step 3. We now want to show that if $ A_1,A_2,\cdots \in \mathcal{I} $ is any countable collection of intervals, and if $ A \subset \cup_n A_n $ for any $ A \in \mathcal{I} $ then 
		\[ \prob(A) \leq \sum_{i=1}^\infty\prob(A_i).  \]
		{\color{red} \noindent TODO: TO BE COMPLETED}
	\end{enumerate}

\end{solution}


\begin{problem}[From Rosenthal]
	Let $ \mathcal{A} = \set{(-\infty,x]\ :\ x\in \R} $. Prove that $ \sigma(\mathcal{A}) = \mathcal{B} $, i.e. that the smallest $ \sigma $-algebra of subsets of $ \R $ which contains $ \mathcal{A} $ is equal to the Borel $ \sigma $-algebra of subsets of $ \R $.
\end{problem}
\begin{solution}
	By definition, we know that $ \mathcal{B} $ is the smallest $ \sigma\text{-algebra} $ that contains all of the intervals. However, we claim that the $ \sigma\text{-algebra} $ $ \sigma(\mathcal{A}) $ also contains all of intervals. To see this, let $ I $ be an interval which will have different cases $(-\infty,a),(-\infty,a],(a,b),[a,b],(a,b],[a,b),(a,\infty),[a,\infty) $. Each of these sets can be constructing by using the sets in $ s \sigma(\mathcal{A}) $ and using its sigma-algebra properties. Thus we showed that $ \sigma(\mathcal{A}) $ contains $ \mathcal{I} $ the set of all intervals. However, by definition $ \mathcal{B} $ was the smallest $ \sigma\text{-algebra} $ containing all of intervals. Thus the $ \sigma\text{-algebra} $ generated by $ \mathcal{A} $ (i.e. the smallest $ \sigma\text{-algebra} $ by definition) is equal to $ \mathcal{B} $. 
\end{solution}

\begin{problem}[From Rosenthal]
	Prove the following statements. 
	\begin{enumerate}[(a)]
		\item Prove that the Cantor set $ K $ and its complement $ K^c $ is in $ \mathcal{B} $, the Borel set of the subset of $ [0,1] $.
		\item Prove that $ K,K^c \in \mathcal{M} $, where $ \mathcal{M} $ is the $ \sigma\text{-algebra} $ by the extension applied for the uniform distribution on $ [0,1] $ (see theorem 2.4.4 Rosenthal).
		\item Prove that $ K^c \in \mathcal{B}_1 $ where $ \mathcal{B}_1 $ is defined by (2.2.6) Rosenthal (i.e. the set of all finite or countable unions of intervals $ \mathcal{I} $).
		\item Prove that $ \mathcal{B}_1 $ is not a $ \sigma\text{-algebra} $.
		
	\end{enumerate}
\end{problem}
\begin{solution}
	\begin{enumerate}[(a)]
		\item In the construction of the cantor set, at each step we remove the middle 1/3 of the intervals. So starting with $ I_0 = [0,1] $ at the first step we will get $ I_1 =  [0,1/3]\cup[2/3,1] $, etc. The Cantor set is $ I_0 \cap I_1 \cap I_2 \cap \cdots $. Since $ I_i \in \mathcal{B} $ for all $ i \in \N $, and $ \mathcal{B} $ is a $ \sigma\text{-algebra} $ and is closed under countable intersection, then $ K \in \mathcal{B} $ as well. It follows immediately that $ K^c \in \mathcal{B} $ as well, as $ \mathcal{B} $ is closed under complement.
		\item Since $ \mathcal{M} \supset \mathcal{B}$, and as we showed above that $ K,K^c \in \mathcal{B} $, then $ K,K^c \in \mathcal{M} $ as well.
		\item From the construction given in part (a), we have
		\[ K = I_0 \cap I_1 \cap I_2 \cap \cdots. \]
		From the De Morgan's law we will have
		\[ K^c = I_0^c \cup I_1^c \cup I_2^c \cup \cdots. \]
		Thus by definition of $ \mathcal{B}_1 $ we have $ K^c \in \mathcal{B}_1 $.
		\item First, observe that (see Rosenthal page 17) that the Cantor set is uncountable. So there is no way to construct it by finite or countable union of singletons (which are in $ \mathcal{I} $). We can not construct it with the finite or countable union of any intervals as $ K $ is a nowhere dense set. I.e. for every interval $ (a,b) \in \mathcal{I} $ containing $ x \in K $ there exists, $ y\in \R $ such that $ y \notin K $. To put this precisely, let $ I_1,I_2,I_3,\cdots $ is collection of intervals such that $ I = \cup_n I_n $. Since $ K $ is nowhere dense, for any $ I_i $ in the collection that contains $ x \in K $ we can find some $ y \in \R $ that $ y \notin K $. This is a contradiction and we have $ I \subset \cup_n I_n $.
		\item As we saw above, $ K^c \in \mathcal{B}_1 $ but $ K \notin \mathcal{B}_1 $. Thus $ \mathcal{B}_1 $ is not closed under complement, thus it is not a $ \sigma\text{-algebra} $.
	\end{enumerate}
\end{solution}

\begin{problem}[An extension of the extension theorem (from Rosenthal)]
	Let $ \mathcal{I} $ be a semialgebra of subsets of $ \Omega $. Let $ \prob:\mathcal{I}\to [0,1] $ with $ \prob(\emptyset) = 0 $ and $ \prob(\Omega) = 1 $, satisfying 
	\[ \prob(\bigcup_n A_n) \geq \sum_n \prob(A_n)\ \qquad \text{for $ A_1,A_2,\cdots \in \mathcal{I} $ \emph{disjoint}, and $ \bigcup_n A_n \in \mathcal{I} $}, \]
	as well as 
	\[ \prob(A) \leq \prob(B), \qquad A \subseteq B, \]
	and
	\[ \prob(\bigcup_n B_n) \leq \sum_n \prob(B_n) \qquad \text{for $ B_1,B_2,\cdots \in \mathcal{I} $, and $ \bigcup_n B_n \in \mathcal{I} $}.\]
	Then there exist a valid probability space $ (\Omega, \mathcal{M},\prob^*) $ such that $ \prob $ and $ \prob^* $ agree on the elements of $ \mathcal{I} $
\end{problem}
\begin{solution}
	According to the extension theorem 2.3.1 we need to prove that these alternative statements implies $ 2.3.3 $. Let $ A, A_1,A_2,\cdots \in \mathcal{I} $ (note that the union of $ A_i $s do not belong to $ \mathcal{I} $ necessarily). Define
	\[ B_n = A_n \cap A. \]
	Then we will have $ A = \cup_n B_n $, thus $ \cup_n B_n \in \mathcal{I} $. So
	\[ \prob(A) = \prob(\bigcup_n B_n) \leq \sum_n \prob(B_n) \leq \sum_n \prob(A_n). \]
\end{solution}
\begin{observation}
	In the prove above, one might attempt 
	\[ \prob(A) \leq \prob(\bigcup_i A_i) \leq \sum_i \prob(A_i) \]
	where for the first inequality we use the monotnonicity (as $ A \subset \bigcup_i A_i $) and for the second inequality we use the countable sub additivity given in the statement of the theorem. However, this prove is \emph{wrong!}. Because we are not allowed to use the second inequality, as it does not satisfies the requirements for the sub-additivity statement to work. That is because $ \bigcup_n A_n $ may not be in $ \mathcal{I} $ necessarily.
\end{observation}

\begin{problem}[Uniqueness property of the extension theorem (from Rosenthal)]
	Let $ \mathcal{I},\prob, \prob^* $ be the same as in Theorem 2.3.1 (Rosenthal). Let $ \mathcal{F} $ be any $ \sigma\text{-algebra} $ with $ \mathcal{I} \subseteq \mathcal{F} \subseteq \Omega $. Let $ \Q $ be any probability measure on $ \mathcal{F} $, such that $ \Q(A) = \prob(A) $ for all $ A \in \mathcal{I} $. Then prove that $ \Q(A) = \prob^*(A) $ for all $ A \in \mathcal{F} $.
\end{problem}
\begin{solution}
	Let $ A \in \mathcal{F} $, and $ A_i \in \mathcal{I} $ for $ i=1,2,\dots $ such that $ A \subseteq \bigcup_i A_i $. Since $ \Q $ is a probability measure, then 
	\[ \Q(A) \leq \Q(\bigcup_i A_i) \leq \sum_i \Q(A_i). \]
	Then we can write
	\begin{align*}
		\prob^*(A) &= \inf_{\substack{A_1,A_2,\cdots \in \mathcal{I} \\ A \subseteq \bigcup_i A_i}}\sum_i \prob(A_i) \\
		&= \inf_{\substack{A_1,A_2,\cdots \in \mathcal{I} \\ A \subseteq \bigcup_i A_i}}\sum_i \Q (A_i) \\
		&\geq \inf_{\substack{A_1,A_2,\cdots \in \mathcal{I} \\ A \subseteq \bigcup_i A_i}}\Q(\bigcup_i A_i)\\
		&\geq \inf_{\substack{A_1,A_2,\cdots \in \mathcal{I} \\ A \subseteq \bigcup_i A_i}}\Q(A)\\
		& = \Q(A).
	\end{align*}
	However, we could do the same with $ A^c \in \mathcal{F} $, which would lead to
	\[ \prob^*(A^c) \geq \Q(A^c). \]
	Since $ \prob^*(A^c) = 1 - \prob^*(A) $ and $ \Q(A^c) = 1 - \Q(A) $, then this implies  $  \prob^*(A) \geq \Q(A)  $. Thus $ \prob^*(A) = \Q(A) $.
\end{solution}


\begin{problem}[Properties of Random Variables (from Rosenthal)]
	\label{prob:capcupcapcup}
	Prove the followings.
	\begin{enumerate}[(i)]
		\item If $ X,Y $ are random variables and $ c\in\R $, then $ X+c, cX, X^2, X+Y,  $ and $ XY $ are random variables. 
		\item If $ Z_1,Z_2,\cdots $ are random variables such that $ \lim_{n\to \infty} Z_n(\omega) $ exists for all $ \omega\in \Omega $,, and $ Z(w) = \lim_{n\to \infty}Z_n(\Omega) $, then $ Z $ is also a random variable.
	\end{enumerate}
\end{problem}

\begin{solution}
	the proves are as follows.
	\begin{enumerate}[(i)]
		\item \begin{enumerate}[(a)]
			\item $ \inv{(X+c)}((-\infty,x]) = \set{w\ :\ X(w)+c \leq x} = \set{w\ :\ X(w)\leq x-c} = \inv{X}((0\-\infty,x-c]) \in \mathcal{F} $.
			\item Assume $ c\neq 0 $. Then $ \inv{(cX)}((-\infty, x]) = \set{w\ :\ cX(w) \leq x} = \set{w\ :\ X(w) \leq x/c}  = \inv{X}((-\infty,x/c]) \in \mathcal{F}. $ For the case were $ c=0 $, then $ cX \equiv 0 $ on all $ \Omega $, and this is a random variable as $ (\inv{cX})((0,x]) = \emptyset$ if $ x < 0 $ and $ (\inv{cX})((0,x]) = \Omega $ if $ x\geq 0 $.
			\item $ X^2((-\infty,a]) = \set{w\ :\ X^2 \leq a} = \set{w\ :\ X \in [-\sqrt{a},\sqrt{a}]} \in \mathcal{F} $.
			\item $ \inv{(X+Y)}((\infty,x]) = \set{w\ :\ X(w)+Y(w) < x} = \bigcup_{r\in \Q}(\set{X < r} \cap \set{Y<x-r}) $. Since this is a countable union, thus in $ \mathcal{F} $.
			\item I have the following prove but I am not sure if it is a correct one or not. I feel that this is a correct proof as there seems to be nothing that can make it not to work.
			\[ \inv{(XY)}((-\infty,x]) = \set{XY < x} = \bigcup_{n\in\N} (\set{X<n} \cap \set{Y<x/n}). \]
			The following prove is the idea by Rosenthal. Once we know that $ X^2 $, $ X+Y $, and $ cX $ are random variables, then we can deduce $ XY $ is also a random variable as
			\[ XY = \frac{1}{2}((X+Y)^2 - X^2 - Y^2)) \]
		\end{enumerate}
		\item In a nutshell this statements claims that the point-wise convergence of a sequence of random variables is a random variable. We need to show that the event $ \set{Z\leq r} \in \mathcal{F} $. To see this, let $ w \in \set{Z\leq r} $. This means that $ Z(w) \leq r $. Since $ Z_n(\omega) \to Z(\omega) $ as $ n\to \infty $, then this implies that $ \forall m \in \N $ there exists $ N \in \N $ such that $ \forall n > N $ we have $ Z_n(\omega) \leq r + \frac{1}{m} $. Thus we can write
		\[ \set{Z(w) \leq r} = \bigcap_{m=1}^{\infty} \bigcup_{N=1}^{\infty} \bigcap_{n=N}^{\infty} \set{ Z_n(\omega) \leq r + \frac{1}{m}} \]
	\end{enumerate}
\end{solution}

\begin{problem}
	Let $ f:\R \to \R $ be continouse or piece-wise continuous function. Then $ f $ is a Borel function.
\end{problem}
\begin{solution}
	We first prove the statement for a continuous function. To show that $ f $ is a Borel function we need to show $ \inv{f}(B) \in \mathcal{B} $ for $ B \in \mathcal{B}$. Since the pre-image preserves the union, intersection, and complements, and by definition for a continuous function the pre-image of an open set is an open set, and using the fact that we can write any Borel set as a countable intersection, union, or complements of open sets then we conclude that $ \inv{f}(B) \in \mathcal{B} $.
	A second way to show this is observe that $ \inv{f}((x,\infty)) \in \mathcal{B} $ as $ (x,\infty) $ is open and $ f $ is continuous, thus its pre-image is also an open set thus a Borel set. Then its complement is also a Borel set, i.e.
	\[ (\inv{f}((x,\infty)))^c = \inv{f}((-\infty,x]) \in \mathcal{B}. \]
	Thus shows that $ f $ is a Borel function (since the pre-image of $ (0,x] $ is a Borel set.
	
	For the case where $ f $ is piece-wise continuous, by the definition of the piece-wise continuoity, $ f $ has at most countably many discontinuities. The we can write $ f $ as 
	\[ f(x) = f_1(x)\mathds{1}_{I_1}(x) + f_2(x)\mathds{1}_{I_2}(x) + f_3(x)\mathds{1}_{I_3}(x)  + \cdots + f_n(x)\mathds{1}_{I_n}(x),  \]
	where $ I_1,I_2,I_3\cdots,I_n  $ are disjoint intervals on which $ f_1,f_2,f_3,\cdots, f_n $ are continuous respectively. By the statement for the first part of the proof, we know that $ f_i $ is a Borel function (since it is continuous) as well as the indicator function $ \mathds{1}_{I_i} $. Their multiplication is also a Borel function and the sum of these Borel functions is a also a Borel function, thus $ f(x) $ is a Borel function.
\end{solution}

\begin{problem}
	Prove that if $ A,B $ are two independent events, then $ (A^c, B) $, $ (A,B^c) $, and $ (A^c, B^c) $ are pairwise independent.
\end{problem}
\begin{solution}
	Since $ A,B $ are independent, then $ \prob(A\cap B) = \prob(A) \prob(B)$. From the identity $ B = (B\cap A) \dot\cup (B\cap A^c) $. From the properties of the probability measure we have
	\[ \prob(B) = \underbrace{\prob(A\cap B)}_{\prob(A)\prob(B)} + \prob(A^c \cap B). \]
	Then we can write
	\[ \prob(A^c\cap B) = \prob(B) - \prob(A\cap B) = \prob(B) (1-\prob(A)) = \prob(B)\prob(A^c). \]
	Thus $ A^c,B $ are also independent events. We use a similar argument for $ A,B^c $. To show that the events $ A^c, B^c $ are also independent, we use the inclusion-exclusion principle. 
	\[ \prob(A^c\cap B^c) = 1 - \prob(A\cup B) = 1 - (\prob(A)+\prob(B) - \prob(A)\prob(B)) = (1-\prob(A))(1-\prob(B))=\prob(A^c)\prob(B^c). \]
	Another way of showing this without the inclusion-exclusion principle is to use the identity
	\[ A^c = (A^c\cap B) \dot\cup (A^c\cap B^c). \]
	Then 
	\[ \prob(A^c) = \underbrace{\prob(A^c\cap B)}_{\prob(A^c)\prob(B)} + \prob(A^c\cap B^c). \]
	We can write
	\[ \prob(A^c \cap B^c) = \prob(A^c)(1-\prob(B)) = \prob(A^c) \prob(B^c).  \]
\end{solution}
\begin{problem}
	Let $ X,Y $ be random variables, and $ f,g : \R \to \R $ be Borel functions. Then if $ X,Y $ are independent, $ f(X) $ and $ g(X) $ are also independent.
\end{problem}
\begin{solution}
	Since $ X,Y $ are independent, thus for any $ S_1,S_2 \in \mathcal{B} $ we have
	\[ \prob(\set{X \in S_1}\cap \set{Y\in S_2}) = \prob(\set{X\in S_1}) \prob(\set{Y \in S_2}). \]
	Consider
	\[ \prob(\set{f(X) \in S_1} \cap \set{g(Y) \in S_2})=\prob(\set{X \in \inv{f}(S_1)} \cap \set{Y \in \inv{g}(S_2)}) = \prob(\set{f(X) \in S_1}) \prob(\set{g(Y) \in S_2}). \]
	The equality above hods because for any $ S_1, S_2 \in \mathcal{B} $ we have $ \inv{f}(S_1),\inv{g}(S_2) \in \mathcal{B} $, that is because $ f,g $ are Borel functions.
\end{solution}

\begin{problem}[Continuity of probabilities]
	Prove that the probability measure function is continuous from bellow and above. I.e. for the continuity from below, let $ A, A_1, A_2,\cdots \in \mathcal{F} $ such that  $ \set{A_n}\nearrow A $, i.e. $ A_1 \subseteq A_2 \subseteq \cdots $ and $ A = \bigcup_n A_n $. Then $ \lim_{n\to \infty} \prob(A_n) = \prob(A) $. For the continuity from above, let $ A,A_1,A_2,\cdots \in \mathcal{F} $ such that $ \set{A_n}\searrow A $, i.e. $ A_1\subseteq A_2\subseteq \cdots $ and $ A = \bigcap_n A_n $, then $ \lim_{n\to \infty}\prob(A_n) = \prob(A) $.
\end{problem}
\begin{solution}
	First, we prove the probability from below. In general, one can observe that if $ \set{A_n}\nearrow A $, then $ \set{\prob(A_n)} $ indeed converges as this is a bounded monotone sequence in $ \R $. However, to show that this sequence converges to $ \prob(A) $, we do as following. Consider the following sets
	\[ B_1 = A_1, \qquad B_2 = A_2 \backslash A_1, \qquad B_3 = A_3 \backslash A_2, \cdots. \]
	Then $ A = \dot\cup B_n $. Thus $ \prob(A) = \sum_{n=1}^{\infty}\prob(B_n) $. Thus the series on the rand hand side converges. This implies that the corresponding partial sums also converges. However, by the construction we have
	\[ \prob(A_1) = \prob(B_1),\quad \prob(A_2) = \prob(B_1) + \prob(B_2)+ \cdots. \]
	Thus the converges of the partial sums implies the convergence of $ \set{\prob(A_n)} $.
	
	For the proof for the continuity from above, first observe that if for a collection $ A,A_1,A_2,\cdots \in \mathcal{F} $ we have $ \set{A_n} \searrow A $, then this is equivalent to $ \set{A^c_n}\nearrow A^c $. This follows from the De Morgan's law as well as the change of the direction of the inclusion $ \subseteq $ under taking complements. By hypothesis we have $ \set{A_n}\searrow A $, which is equivalent to$ \set{A^c_n}\nearrow A^c $. From the first part of the proof, it follows that $ \lim_{n\to \infty}\prob(A^c_n) = \prob(A^c) $. Thus
	\[ \lim_{n\to \infty}(1-\prob(A_n)) = 1 - \prob(A). \]
	Note that $ \prob(A_n) $ converges to some real number as $ n\to \infty $, because it is a bounded decreasing sequence. Thus by the laws of the limit we can write
	\[1 -  \lim_{n\to\infty} \prob(A_n) = 1 - \prob(A). \]
	Then it follows that 
	\[ \lim_{n\to \infty}\prob(A_n) = \prob(A). \]
\end{solution}

\begin{problem}[From Rosenthal]
	Let $ A_1,A_2,\cdots,A_n \in \mathcal{F} $. Generalize the principle of inclusion-exclusion to:
	\[ \prob(A_1\cup\cdots\cup A_n) = \sum_{i=1}^n A_i - \sum_{1\leq i < j \leq n} \prob(A_i \cap A_j) + \sum_{1\leq i < j < k \leq n} \prob(A_i \cap A_j \cap A_k) - \cdots \pm \prob(A_1\cap \cdots \cap A_n). \]
	\emph{Hint: Expand $ 1 - \prod_{i=1}^n (1-\mathds{1}_{A_i}) $, and take expectation of both sides.}
\end{problem}
\begin{solution}
	First, observe that $ \mathds{1}_{A^c} = 1 - \mathds{1}_A $. So
	\[ 1 - \prod_{i=1}^n(1-\mathds{1}_{A_i}) = 1 - \prod_{i=1}^n \mathds{1}_{A_i^c} = 1 - \mathds{1}_{A_1^c\cap\cdots\cap A_n^c} = \mathds{1}_{A_1\cup\cdots\cup A_n}.  \]
	On the other hand, 
	\[ 1 - \prod_{i=1}^n (1-\mathds{1}_{A_i}) = \sum_{i=1}^{n}\mathds{1}_{A_i}  - \sum_{1 \leq i < j \leq n} \mathds{1}_{A_i \cap A_j} + \cdots \pm \mathds{1}_{A_1\cap\cdots\cap A_n}.  \]
	So we have
	\[ \mathds{1}_{A_1\cup\cdots\cup A_n} = \sum_{i=1}^{n}\mathds{1}_{A_i}  - \sum_{1 \leq i < j \leq n} \mathds{1}_{A_i \cap A_j} + \cdots \pm \mathds{1}_{A_1\cap\cdots\cap A_n}. \]
	By applying the expectation to both sides we will get
	\[ \prob(A_1\cup\cdots\cup A_n) = \sum_{i=1}^n A_i - \sum_{1\leq i < j \leq n} \prob(A_i \cap A_j) + \sum_{1\leq i < j < k \leq n} \prob(A_i \cap A_j \cap A_k) - \cdots \pm \prob(A_1\cap \cdots \cap A_n). \]
\end{solution}

\begin{problem}[From Rosenthal]
	Let $ f(x) = ax^2 + bx + c $ be a second-degree polynomial function where $ a,b,c \in \R $.
	\begin{enumerate}[(a)]
		\item Find necessary and sufficient condition on $ a,b $ and $ c $ such that the equation $ \E{f(\alpha x)} = \alpha^2 \E{f(X)} $ holds for all $ \alpha \in \R $ and all random variable $ X $. 
		\item Find necessary and sufficient condition on $ a,b $ and $ c $ such that the equation $ \E{f(x-\beta)} = \E{f(x)} $ holds of all $ \beta \in \R $ and all random variable $ X $.
		\item Do parts $ (a) $ and $ (b) $ account for the properties of the variance function? Why or why not?
	\end{enumerate}
\end{problem}
\begin{solution}
	\begin{enumerate}[(a)]
		\item For the LHS we have
		\[ \E{\alpha^2 a x^2 + \alpha b x + c} = a\alpha^2 \E{x^2} + b\alpha \E{x} + c. \]
		And for the RHS we have
		\[ \alpha^2\E{f(x)} = a\alpha^2\E{x^2} + b\alpha^2 \E{x} + c\alpha^2. \] 
		Thus the necessary and sufficient condition for the equality to hold for every $ \alpha \in \R $ is to have
		\[ b = 0, \qquad c = 0. \]
		\item For the LHS we have
		\[ \E{f(x-\beta)} = a\E{x^2} + (b - 2a\beta)\E{x} + a\beta^2 - b\beta + c.  \]
		For the RHS we have
		\[ \E{f(x)} = a\E{x^2} + b\E{x} + c. \]
		This implies that we need to have 
		\[ a = 0, \qquad b = 0. \]
		I.e. the polynomial should be a constant polynomial.
		\item For the property $ \operatorname{Var}{(\alpha C)} = \alpha^2 \operatorname{Var}{(C)} $, it follows from the fact that in part (b) we found that for the polynomial we need to have $ b = 0 $ and $ c = 0 $. However, part (b) does not account for the property of variance that $ \operatorname{Var}(X+b) = \operatorname{Var}(X) $. Because in the case of $ \operatorname{Var} $ the constants of the polynomial depends on the random variable under consideration. I.e. we have
		\[ b = - 2 \E{X}, \qquad c = \E{X}^2. \]
	\end{enumerate}
\end{solution}

\begin{problem}[From Rosenthal]
	Let $ X_1,X_2,\cdots $ be independent, each with mean $ \mu $ and variance $ \sigma^2 $, and let $ N $ be an integer-valued random variable with mean $ m $ and variance $ v $, with $ N $ independent of all the $ X_i $. Let $ S = X_1 + X_2 + \cdots + X_n = \sum_{i=1}^{\infty} X_i \mathds{1}_{N\geq i} $. Compute $ \operatorname{Var}(S) $ and $ \E{S} $.
\end{problem}
\begin{solution}[Using the conditional expectation]
	For this problem we can either use the conditional expectation or use the first principles.
	\[ \E{S} = \E{X_1+\cdots+X_N} = \sum_n \E{X_1+\cdots+X_n}\prob(N = n) = \mu \sum_n n \prob(N=n) = \mu m. \] 
	Similarly we have
	\begin{align*}
		\E{S^2} &= \sum_n \E{S^2\ |\ N = n} \prob(N=n) \\
		&= \sum_n \E{(X_1+\cdots+X_n)^2} \prob(N=n) \\
		&= \sum_n \E{\sum_i X_i^2 + \sum_{i<j}X_iX_j} \prob(N=n) \\ 
		&= \sum_n (\sum_i \E{X_i^2} + 2\sum_{i<j}\E{X_iX_j}) \prob(N=n) \\
		&= \sum_n ((\sigma^2 + \mu^2)n + n(n-1)\mu^2) \prob(N=n)\\
		&= (\sigma^2 + \mu^2)m + \mu^2(v+m^2 - m).
	\end{align*}
	Where we have used $ \E{X_i^2} = \operatorname{Var}(X_i) + \E{X_i}^2 = \mu^2 + \sigma^2 $, and also used the fact that the sum $ \sum_{i<j} $ has $ \binom{n}{2} $ terms.
	Now we can compute the variance
	\[ \operatorname{Var}(S) = \E{S^2} - \E{S}^2 = (\sigma^2 + \mu^2)m + \mu^2(v+m^2 - m) - \mu^2 m^2 = \sigma^2 m + \mu^2 v. \]
\end{solution}
\begin{problem}[from Rosenthal]
	Let $ X,Z $ be independent random variables each with standard normal distribution. Let $ a,b\in \R $ (not both 0), and let $ Y = aX + bZ $.
	\begin{enumerate}[(a)]
		\item Compute $ \operatorname{Corr}(X,Y) $.
		\item Show that $ \abs{\Corr(X,Y)} \leq 1 $.
		\item Given necessary and sufficient conditions on the values of $ a $ and $ b $ such that $ \Corr(X,Y) = 1 $.
		\item Given necessary and sufficient conditions on the values of $ a $ and $ b $ such that $ \Corr(X,Y) = -1 $.
	\end{enumerate}
\end{problem}
\begin{solution}
	\begin{enumerate}[(a)]
		\item First, observe that 
		\[ \E{X} = \E{Z} = 0, \quad \Var(X) = \Var(Y) = 1, \quad \E{Y} = a+b, \quad \Var(Y) = a^2 + b^2 \]
		where we have used the properties of variance to compute $ \Var(Y) $. By the definition of correlation we have
		\[ \Corr(X,Y) = \frac{\operatorname{Cov}(X,Y)}{\sqrt{\Var(X)\Var(Y)}} = \frac{\E{XY} - \E{X}\E{Y}}{\sqrt{a^2+b^2}} = \frac{a}{\sqrt{a^2+b^2}}. \]
		
		\item It follows immediately by
		\[ \abs{\Corr(X,Y)} = \abs{\frac{1}{\sqrt{1+b^2/a^2}}} \leq 1. \]
		
		\item From our solution in part (a), the necessary and sufficient condition for $ \Corr(X,Y) = 1 $ is that $ b = 0 $ and $ a> 0 $.
		
		\item From the solution in part (a). the necessary and sufficient condition for $ \Corr(X,Y) = -1 $ is that $ b = 0 $ and $ a < 0 $.
	\end{enumerate}
	
\end{solution}

\begin{problem}[From Rosenthal]
	Let $ X,Y $ be independent general non-negative random variables, and let $ X_n = \Psi_n(X) $, where $ \Psi_n(x) = \min(n,2^{-n}\floor{2^nx}) $.
	\begin{enumerate}[(a)]
		\item Give an example of a sequence of functions $ \Phi_n: [0,\infty) \to [0,\infty) $ other than $ \Phi_n = \Psi_n $, such that for all $ x $ we have $ 0 \leq \Phi_n(x) \leq x $ and $ \set{\Phi_n(x)}\nearrow x $ as $ n \to \infty $.
		\item Suppose that $ Y_n = \Phi_n(Y) $ with $ \Phi_n $ as in part (a). Must $ X_n $ and $ Y_n $ be independent.
		\item Suppose $ \set{Y_n} $ is an arbitrary collection of non-negative random variables such that $ \set{Y_n} \nearrow Y $. Must $ X_n $ and $ Y_n $ be independent?
		
		\item Under the assumption of part (c), determine which quantities in 4.2.7 are necessarily equal?
	\end{enumerate}
\end{problem}
\begin{solution}
	\begin{enumerate}[(a)]
		\item Define
		\[ f_n(x) = \min\set{n, \frac{1}{2^n}(\frac{1}{2}(2^n x + \floor{2^n x})) }. \] 
		The graph of this function will be as follows.
		\begin{figure}[h!]
			\centering
			\includegraphics[width=0.2\linewidth]{Images/PhiFunction}
			\label{fig:phifunction}
		\end{figure}
		\FloatBarrier
		
		\item First observe that $ \Phi_n $ is a Borel measurable function as the pre-image of any open interval is a union of half open intervals or the empty set. Since $ X,Y $ are independent, then $ X_n, Y_n $ are also independent.
		
		\item No. We demonstrate a counterexample. Let 
		\[ Y_n = \max\set{\Psi_n(Y) - \frac{1}{n^2}\Psi_n(X) , 0}. \]
		
		\item Since $ \set{X_n} \nearrow X $ and $ \set{Y_n } \nearrow Y $, then $ \set{X_n Y_n} \nearrow XY $. Thus by the monotone convergence theorem we have
		\[ \E{XY} = \lim_n \E{X_n Y_n}. \]
		Also since (by monotone convergence theorem) $ \E{X} = \lim_n \E{X_n} $ and $ \E{Y} = \lim_n \E{Y_n} $ then by the limit laws we have
		\[ \lim_n \E{X_n} \E{Y_n} = \E{X} \E{Y}. \]
		
	\end{enumerate}
\end{solution}

\begin{problem}[From Rosenthal]
	Give examples of a random variable $ X $ defined on Lebesgue measure on $ [0,1] $, such that 
	\begin{enumerate}[(a)]
		\item $ \E{X^+} = \infty $ and $ 0 < \E{X^-} < \infty $.
		\item $ \E{X^-} = \infty $ and $ 0 < \E{X^+} < \infty $.
		\item $ \E{X^+} = \E{X^-} = \infty $.
		\item $ 0 < \E{X} < \infty $ but $ \E{X^2} = \infty $.
	\end{enumerate}
\end{problem}
\begin{solution}
	\begin{enumerate}[(a)]
		\item Define 
		\[ X^+ = 2\cdot \mathds{1}_{(1/2,3/4)} + \sum_{n=2}^\infty 2^n \cdot \mathds{1}_{(2^{-n}, 2^{-n+1})}, 
		\qquad 
		X^- = -2 \cdot \mathds{1}_{(3/4,1)}. \]
		Then $ \E{X^+} = 1/2 + 1 + 1 + \cdots = \infty, \qquad \E{X^-} = 1/2 $.
		
		\item Similar to part (a) but exchange $ X^- $ and $ X^+ $.
		
		\item Define
		\[ X^+ = \sum_{n\text{ even}} 2^n \cdot \mathds{1}_{(2^{-n}, 2^{-n+1})}, 
		\qquad 
		X^+ = \sum_{n\text{ odd}} 2^n \cdot \mathds{1}_{(2^{-n}, 2^{-n+1})}. \]
		Clearly
		\[ \E{X^+} = \E{X^-} = \infty. \]
		
		\item {\color{red} \noindent TODO: TO BE ADDED.}
 	\end{enumerate}
\end{solution}


%\begin{problem}[From Rosenthal]
%	\begin{enumerate}[(a)]
%		\item In what step of the proof of proposition 1.2.6 in (Rosenthal) the expression (1.2.1) was used?
%		\item Give an example of a countably additive set function $ \prob $, defined on all subsets of $ [0,1] $, which satisfies $ (1.2.3) $ and $ (1.2.5) $, but not $ (1.2.1) $.
%	\end{enumerate}
%\end{problem}
%\begin{solution}
%	\begin{enumerate}[(a)]
%		\item We used $ (1.2.1) $ at the last step of drawing the contradiction by assigning the probability $ 1 $ to $ \prob((0,1]) $.
%		\item 
%	\end{enumerate}
%\end{solution}