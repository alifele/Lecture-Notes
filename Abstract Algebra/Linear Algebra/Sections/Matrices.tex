\section{What is a Matrix}

A matrix is basically a notation convention that enables us to do some stuff more easily with a pencil and paper.  A very similar concept to this is the long division algorithm for for dividing two integers. For example consider the following long division (in French-European style) that we are all familiar with

\begin{equation*}
	\opdiv[decimalsepsymbol={,},displayintermediary=all,voperation=top]
	{198}{12}
\end{equation*}

So this notation and algorithms is to use some calculations more continent when is done by hand with a pen and paper. So the matrix notation can also be though as a computation convention. To make stuff more clear, consider the following example. \newline

\begin{example}{Simple Pen and Paper Calculations}
	Consider $V$ which is written as:
	\[ V = 2A + 3B + 4C \]
	
	Given the following relation between $A,B$, and $C$, rewrite $V$ in terms of $x,y$, and $z$.
	\begin{align*}
		A &= x + 2 y + 3 z \\
		B &= 2 x - y + z \\
		C &= -x -y + z
	\end{align*}
	
	\emph{Solution 1.}
	
	To write $V$ in terms of $x,y$, and $z$ we write:
	\begin{equation}
		V = 2 (x + 2 y + 3 z) + 3 (2 x - y + z) + 4 (-x -y + z)
		\label{example:SimplePenPaper:expandedForm}
	\end{equation}
	
	By arranging the terms using simple algebra we will have:
	
	\begin{equation}
		V = (2+6-4)x + (4-3-4)y + (6+3+4)z  = 4x -3y + 13z
		\label{example:SimplePenPaper:expanded2}
	\end{equation}


	\emph{Solution 2.}
	
	The calculations described in the first solution are not systematic. What I mean is that we started doing whatever we can do with you thinking about doing it in a more smart way that can also by systematically scaled to larger equations. This is where the matrices come into play. Matrices help us to do such calculations in a more algorithmic way (like the long division notation in which we do the calculations in a algorithmic way). \newline
	
	Let $\mathbb{B}$ be the set of all \emph{objects} that the $V$ is expanded in terms of and call this set as the \emph{basis} set. So for $\vect{V}= 2A + 3B + 4C$ we have the basis
	\[ \mathbb{B}_1 = \{ A,B,C \}. \]
	We can arrange the coefficients of $V$ in basis $\mathbb{B}_1$ in the following way:
	\begin{equation*}
		V_{\mathbb{B}_1}=
		\begin{pmatrix}
			2 \\
			3 \\
			4
		\end{pmatrix}_{\mathbb{B}_1}
	\end{equation*}
	We call it the coordinates of $V$ in the basis $\mathbb{B}_1$. Since we want to write the vector $V$ in terms of $x,y$, and $z$, we need to introduce the new basis $\mathbb{B}_2$ in the following way:
	
	\begin{equation*}
		\mathbb{B}_2 = \{ x,y,z \}
	\end{equation*}
	
	 Since $A,B$, and $C$ are expressed in terms of $x,y$, and $z$, we can arrange the coordinates of $A,B$, and $C$ in the basis $\mathbb{B}_2$ in the following way:
	 
	 \begin{equation*}
	 	L_{\mathbb{B}_1}^{\mathbb{B}_2} = \begin{pmatrix}
	 		1 & 2 & -1 \\
	 		2 & -1 & -1 \\
	 		3 & 1 & 1
	 	\end{pmatrix}_{\mathbb{B}_1}^{\mathbb{B}_2}
	 \end{equation*}
 
 	in which every column is the coefficients $A,B$, and $C$ in the basis $\mathbb{B}_2$ respectively. Note the subscript and the superscripts of the matrix. This matrix means that its columns contains the coordinates of the basis $\mathbb{B}_1$ in the new basis $\mathbb{B}_2$. So when it is applied to any vector that is described in basis $\mathbb{B}_1$, we will get the components of that vector in the basis $\mathbb{B}_2$. In other words:
 	
 	\begin{equation*}
 		V_{\mathbb{B}_2} = L_{\mathbb{B}_1}^{\mathbb{B}_2} V_{\mathbb{B}_1}
 	\end{equation*}
 
	\begin{equation}
		V_{\mathbb{B}_2} = 
		\begin{pmatrix}
			1 & 2 & -1 \\
			2 & -1 & -1 \\
			3 & 1 & 1
		\end{pmatrix}_{\mathbb{B}_1}^{\mathbb{B}_2}
		\begin{pmatrix}
			2 \\
			3 \\
			4
		\end{pmatrix}_{\mathbb{B}_1}
		\label{example:SomplePenPaper:matrixEquation}
	\end{equation}

	Considering the basic operations introduced with matrix notation, this matrix equation can be written in two ways as described below:
	
	\begin{equation}
		V_{\mathbb{B}_2} = 
		2 \begin{pmatrix}
			1 \\
			2 \\
			3
		\end{pmatrix}_{\mathbb{B}_2} 
		+ 3 \begin{pmatrix}
			2 \\
			-1 \\
			1
		\end{pmatrix}_{\mathbb{B}_2}
		+ 4 \begin{pmatrix}
			-1 \\
			-1 \\
			1
		\end{pmatrix}_{\mathbb{B}_2}
	\end{equation}

	The equation above is equivalent to equation \ref{example:SimplePenPaper:expandedForm} but described in other way! Also the other way to write the matrix equation \ref{example:SomplePenPaper:matrixEquation} is the following way in which we have used the matrix multiplication conventions:
	
	\begin{equation}
		V_{\mathbb{B}_2} = 
		\begin{pmatrix}
			1 & 2 & -1 \\
			2 & -1 & -1 \\
			3 & 1 & 1
		\end{pmatrix}_{\mathbb{B}_1}^{\mathbb{B}_2}
		\begin{pmatrix}
			2 \\
			3 \\
			4
		\end{pmatrix}_{\mathbb{B}_1}
		=\begin{pmatrix}
			(1*2) + (2*3) + (-1*4) \\
			(2*2) + (-1*3) + (-1*4) \\
			(3*2) + (1*3) + (1*4))
		\end{pmatrix}_{\mathbb{B}_2}	
		=\begin{pmatrix}
			4 \\
			-3 \\
			13
		\end{pmatrix}_{\mathbb{B}_2}		
	\end{equation}

	which is essentially equivalent to the equation \ref{example:SimplePenPaper:expanded2} but written in a different way.
	
	 
\end{example}




\section{Change of Basis Matrix}

As we discussed earlier, the matrix representation of a linear operator $\op{A} \in \vectSpace{L}(\vectSpace{V},\vectSpace{W})$ depends on the choice of basis $\mathbb{B}_{\vectSpace{V}}$ and $\mathbb{B}_\vectSpace{W}$ which are the basis of vector spaces $\vectSpace{V}$ and $ \vectSpace{W} $ respectively. Now suppose that that in the vector spaces $\vectSpace{V}$, the elements are described in basis $\mathbb{B}_1 = \{ \ket{e_i} \}_{i=1}^{N}$ but we want to change it to the basis $\basis{B}{2}{e'}{j}{N}$. We need to know the relation between these two basis that is assumed to be the following:

\begin{equation}
	\ket{e_i} = \sum_{j=1}^{N} \rho_{ji} \ket{e'_{j}}
	\label{equ:changeOfMatrix:eInTermsOfePrime}
\end{equation}

Consider the vector $\ket{v}$ that is described in the basis $\mathbb{B}_1$ in the following way: 

\begin{equation}
	\ket{v} = \sum_{i=1}^{N} \alpha_i \ket{e_i} 
	\label{equ:changeOfBasis:expansionOfvIne}
\end{equation}

\[ \ket{v} = \sum_{i=1}^{N} \alpha_i \ket{e_i} \] 

The coefficients of the expansion are called the \emph{coordinates} of $\ket{v}$ in the basis $\mathbb{B}_1$ and can be shown like:

\begin{equation}
	\underline{v}_{\mathbb{B}_1} = \begin{pmatrix}
		\alpha_1 \\
		\alpha_2 \\
		\vdots \\
		\alpha_N
	\end{pmatrix}_{\mathbb{B}_1}
\end{equation}

Now we can use the equation \ref{equ:changeOfMatrix:eInTermsOfePrime} to replace $\ket{e_i}$ in \ref{equ:changeOfBasis:expansionOfvIne} with $\ket{e'_j}$:

\begin{equation}
	\ket{v} = \sum_{i=1}^{N} \sum_{j=1}^{N}\alpha_i \rho_{ji} \ket{e'_j} = \sum_{j=1}^{N} \sum_{i=1}^{N}\rho_{ji} \alpha_i  \ket{e'_j}  = \sum_{j=1}^{N} \eta_j \ket{e'_j}
	\label{equ:chanbeOfBasis:vInNewBasis}
\end{equation}

in which $\eta_j = \sum_{i=1}^{N}\rho_{ji} \alpha_i $ is the coordinates of $ \ket{v} $ in the new basis $\mathbb{B}_2$:

\begin{equation*}
	\underline{v}_{\mathbb{B}_2} = \begin{pmatrix}
		\eta_1 \\
		\eta_2 \\
		\vdots \\
		\eta_N
	\end{pmatrix}_{\mathbb{B}_2}
\end{equation*}


The equation \ref{equ:chanbeOfBasis:vInNewBasis} can be written in the following matrix equation:

\begin{equation}
	\begin{pmatrix}
		\eta_1 \\
		\eta_2 \\
		\vdots \\
		\eta_N
	\end{pmatrix}_{\mathbb{B}_2} = 
	\underbrace{\begin{pmatrix}
			\rho_{11} & \rho_{12} & \cdots & \rho_{1N}\\
			\rho_{21} & \rho_{22} & \cdots & \rho_{2N}\\
			\vdots    & \vdots    & \ddots & \vdots\\
			\rho_{N1} & \rho_{N2} & \cdots & \rho_{NN} 
		\end{pmatrix}_{\mathbb{B}_1}^{\mathbb{B}_2}}_{R}
	\begin{pmatrix}
		\alpha_1 \\
		\alpha_2 \\
		\vdots \\
		\alpha_N
	\end{pmatrix}_{\mathbb{B}_1} 
\end{equation}

The matrix $R$ is called the change of basis matrix. \newline

\begin{example}{Change of Basis}
	Consider the following Cartesian plane:
	\input{Images/changeOfBasis_example1.tex}
	The vectors of the plain can be expressed using any arbitrary basis two of which are provided here as an example:
	\begin{align*}
		\mathbb{B}_1 &= \{ \ket{e_1}, \ket{e_2} \} = \{ 
		\begin{pmatrix}
			1 \\
			0
		\end{pmatrix}_{\mathbb{B}_1},
		\begin{pmatrix}
			0 \\
			1
		\end{pmatrix}_{\mathbb{B}_1}
		\} \\
		\mathbb{B}_2 &= \{ \ket{e'_1}, \ket{e'_2} \} = \{ 
		\begin{pmatrix}
			1 \\
			0
		\end{pmatrix}_{\mathbb{B}_2},
		\begin{pmatrix}
			0 \\
			1
		\end{pmatrix}_{\mathbb{B}_2}
		\} = 
		\{ 
		\begin{pmatrix}
			1 \\
			1
		\end{pmatrix}_{\mathbb{B}_1},
		\begin{pmatrix}
			-1 \\
			1
		\end{pmatrix}_{\mathbb{B}_1}
		\}
	\end{align*}

	It is clear that the vector $ \ket{v} $ can be expanded like: 
	\begin{equation}
		\ket{v} = 2\ket{e_1} + \ket{e_2}
		\label{equ:changeOfBasis:example:v_in_terms_of_B1}
	\end{equation}
	
	So we can write:
	\[ \underline{v}_{\mathbb{B}_1} = \begin{pmatrix}
		2 \\
		1
	\end{pmatrix}_{\mathbb{B}_1} \]
	in which $\underline{v}_{\mathbb{B}_1}$ is the coordinates of $ \ket{v} $ in the basis $ \mathbb{B}_1 $. Now suppose that we want to fine the coordinates of $ \ket{v} $ in the basis $ \mathbb{B}_2 $. To do that we need to write the $ \ket{e_1} $ and $ \ket{e_2} $ in terms of  $ \ket{e'_1} $ and $ \ket{e'_2} $ (i.e. find the coordinates of elements of $ \mathbb{B}_1 $ in the basis $ \mathbb{B}_2 $):
	
	\begin{equation}
		\begin{split}
			\ket{e_1} &= \ket{e'_1} - \ket{e'_2} \\
			\ket{e_2} &= \ket{e'_1} + \ket{e'_2} 
		\end{split}
		\label{equ:changeOfBasis:example:B1_in_terms_of_B2}
	\end{equation}

	This can be written in the column vector format:
	\begin{align*}
		\underline{e_1}_{\mathbb{B}_2} &= \begin{pmatrix}
			1 \\
			-1
		\end{pmatrix}_{\mathbb{B}_2} , \quad
		\underline{e_1}_{\mathbb{B}_2} = \begin{pmatrix}
			1 \\
			1
		\end{pmatrix}_{\mathbb{B}_2}
	\end{align*}
	By arranging these columns into the columns of matrix we will get the change of basis matrix:
	\begin{equation*}
		\mat{R} = \begin{pmatrix}
			1 & 1 \\
			-1 & 1
		\end{pmatrix}_{\mathbb{B}_1}^{\mathbb{B}_2}
	\end{equation*}

	By inserting \ref{equ:changeOfBasis:example:B1_in_terms_of_B2} in \ref{equ:changeOfBasis:example:v_in_terms_of_B1} we can get the expanded form of $ \ket{v} $ in the new basis $\mathbb{B}_2$.
	
	\begin{equation*}
		\ket{v} = 2 (\ket{e'_1} - \ket{e'_2}) + (\ket{e'_1} + \ket{e'_2} ) = 3 \ket{e'_1} -\ket{e'_2} 
	\end{equation*}

	The above calculations can also be done by applying the change of basis matrix $ \mat{R} $ on the coordinates of $ \ket{v} $ in $ \mathbb{B}_1 $, i.e. $ \underline{v}_{\mathbb{B}_1} $ :
	\begin{equation*}
		\underline{v}_{\mathbb{B}_2} = \begin{pmatrix}
			1 & 1 \\
			-1 & 1
		\end{pmatrix}_{\mathbb{B}_1}^{\mathbb{B}_2}
		\begin{pmatrix}
			2 \\
			1
		\end{pmatrix}_{\mathbb{B}_1} = 
	\begin{pmatrix}
		3 \\
		-1
	\end{pmatrix}_{\mathbb{B}_2}
	\end{equation*}
\end{example}







