\chapter{Markov Chain}
NOTE TO MYSELF: I prefer to develop whole theory of discrete Markov chains by defining the state space to be the set of symbols $\Sigma$ (at most countable). This is beneficial, because then the sample space of any Markov chain will be the set of all infinite sequences (strings) from the symbols from $\Sigma$. At some point in the future, I might rewrite this chapter, working consistently with $\Sigma$ as the state space.

We start with the definition of a Markov Chain.
\begin{notation}
	Let $(X_n)_{n\geq0}$ be a Markov chain on the state space $S$, $x\in S$, and let $E$ be an event. Then
	\[  \prob_x(E) = \prob(E|X_0=x) . \]
\end{notation}
The following proposition will be one of our main tools throughout the chapter.
\begin{proposition}[Conditional expansion]
	Let $(\Omega, \mathcal{F}, \prob)$ be a probability space. Let $\mathfrak{F}$ be a finite collection of events $\mathfrak{F} = \set{F_1,F_2,\cdots, F_n}$ that partitions $\Omega$. I.e.
	\begin{enumerate}[(i)]
		\item $F_i \cap F_j = \emptyset \qquad i\neq j$,
		\item $\bigcap_{i} F_i = \Omega$.
	\end{enumerate}
	Let $E \in \mathcal{F}$ be any nonempty event. Then we can write
	\[  \prob(E) = \sum_{i} \prob(E|F_i)\prob(F_i). \]
\end{proposition}
\begin{proof}
	Since $\mathfrak{F}$ partitions $\Omega$ and $E \neq \emptyset$, then $\set{E\cap F_i}_i$ is a partition of $E$. Thus
	\[ \prob(E) = \prob(\bigcup_i (E \cap F_i)) = \sum_i \prob(E \cap F_i) = \sum_i \prob(E|F_i)\prob(F_i). \]
	This completes the proof.
\end{proof}



\begin{proposition}[First step argument]
	Let $(X_n)_{n\geq 0}$ be a Markov chain on the state space $S$. Let $x\in S$, and $W,Z \subset S$. Let $B$ be any event. Then
	\[ \prob_x(B) = \sum_{y:x\sim y} \prob_y(B)P(x,y). \]
	\label{prop:FirstTimeStepArgument}
\end{proposition}
\begin{proof}
	To prove the proposition above, we Let $E_i = \{ X_0=x, X_1=y_i \}$ where $y_i \sim x$. So, in words, we say that the event $E_i$ has occurred if $X_1 = y_i$. It is clear that $E_i \cap E_j = \emptyset$ where $i\neq j$. Thus $\bigcup_{i}(B\cap E_i) = B$. Thus 
	\[ \prob_x(B) = \sum_{i} \prob_x(B \cap E_i) = \sum_{i}\prob_x(B|E_i)\prob_x(E_i). \]
	In which $\prob_x(E_i) = \prob(E_i|X_0=x) = \prob(X_1=y_i|X_0=x) = P(x,y_i)  $. Also \[\prob_x(B|E_i) = \prob(B|X_1=y_i, X_0=x) = \prob(B|X_1=y_i) = \prob_{y_i}(B),\]
	in which we have used the Markov property. Thus we can write
	\[ P_x(B) = \sum_i \prob_{y_i}(B)P(x,y_i). \]
\end{proof}


\section{Dissecting an Experiment}
The idea of the Markov chain, random variables, probability spaces, etc. might be quite confusing when the setting of a particular random experiment becomes large. Here in this section, we are going to explain the details of a random experiment explicitly. The random experiment is the following
\begin{quote}
	Assume we have 6 urns, and we put ball at each urn successively. What is the probability that there will be exactly 3 non-empty urns after 9 balls have been distributed?
\end{quote}

\subsubsection{Sample Space}
First, note that there are two things happening, that we can call experiments. First is that we are successively doing something, throwing dice and putting a ball inside the urn, and the second thing is that we can consider the whole thing to be a giant experiment by its own. Our convention, from now on, will be that we will call the whole thing as experiment, and we will consider each sub-experiment as sub-steps of the process. Intuitively, an experiment is something that we can repeat to observe different outcomes. It is true that the whole experiment is actually successive repetition of throwing dice, but we actually consider the largest meaningful setup to be our experiment and call the sub-experiment as the steps of the process. It is kind of confusing at first glance, but becomes more natural after a while. By the definition, the sample space of a random experiment, is the set of all possible outcomes. But what are the possible outcomes in our experiment? If we perform an experiment, then we can get an outcome like 
\[ 13423452113345666534243125555321453214512345312456341231456665435\hdots. \]
This outcome basically is saying that the outcome of the first dice throw was 1, the second dice throw was 3, the third was 4, and etc. If we repeat the experiment, we will get other outcomes. So the sample space is the set of all sequence of numbers consisting of $ \set{1,2,3,4,5,6,7,8} $. Thus, we can write
\[ \Omega = \set{13424\hdots, 54321\hdots, 65432\hdots, 12345\hdots, \cdots}. \]
So, each outcome, consists of sequence of random variables $ \set{Y_t} $, that is defined on the sample space $ \Omega_{\text{dice}} = [1,2,3,4,5,6] $. That is $ Y_{10} $ means the random variable associated with the dice throwing experiment at the time $ t $ of our main experiment. These random variables are all independent and identically distributed (i.e. they are iid).

\subsubsection{Markov Chain}
Let $ X_t $ be a random variable defined on $ \Omega $ that represents the number of full urns at time $ t $. Let $ \omega = 231234562342132453423\hdots $ and $ t = 10 $. Then $ X_10(\Omega) = 6 $, since by the time $ t $, we have put at least one ball at each urn and all of the urns are full. Since this is a Markov chain with state space $ S = \set{0,1,2,3,4,5,6} $, we can draw a transition diagram, and analyze the question more carefully. This is what we have done in \autoref{exm:MarkovChain-EmptyFullUrns}.

\section{Solved Problems}


\begin{example}
	An urn always contains 2 balls. Ball colors are red and blue. At each stage a ball  is randomly chosen and then replaced by a new ball, which with probability 0.8 is the same color, and with probability 0.2 is the opposite color, as the ball it replaces. If initially both balls are red, find the probability that the fifth ball selected is red. [This question is from Ross]
	\begin{solution}
		First, we need to translate this problem to a suitable Markov chain. There are many ways we can do so, each with its own pros and cons. The difference between all of these formulations come down to our choice for the state space (i.e. the co-domain of the random variable). For instance, we can assume that the state space is $S = \set{RR, RB, BB}$ that is the content of the Urn, or we can simply say that the state space is $S = \set{0,1,2}$ that is the number of red ball inside the Urn. Since these two sets are isomorphic (as there is a bijection between these two sets), but the actual choice depends on personal preference. Let's proceed with $S = \set{0,1,2}$. Then, we need to determine the transition matrix. We can do so by doing the first step argument. We start with $P(0,0)$. 
		\[ P(0,0) = \prob(X_1 = 0|X_0 =0) = \prob(X_1=0|X_0=0,E_R)\underbrace{\prob(E_R|X_0=0)}_{0} + \underbrace{\prob(X_1=0|X_0=0,E_B)}_{0.8}\underbrace{\prob(E_B|X_0=0)}_{1}, \]
		where $E_R$ is the event at which a red balls is drawn from the Urn, while $E_B$ is the event where a blue ball is drawn. The reason behind the values for the term above are very straight forward. For instance $\prob(E_R|X_0=0)=0$ because given the fact that number of red balls in the Urn is zero $(X_0 = 0)$, then the probability that we draw a red ball is zero (as there is not red balls in the Urn). For the term $\prob(X_1=0|X_0=0,E_B) = 0.8$, because given there is no red balls inside the urn, and also given the fact that the drawn ball is blue, the probability of ending up at the state $X_1=0$ (i.e. still no red balls) is that probability is that we replaced the drawn ball with a blue ball (same color) which has the probability $0.8$. Similarly, we can calculate the first step transition probabilities. 
		\begin{align*}
			&P(0,1) = \prob(X_1=1|X_0=0) = \prob_0(X_1=1) = \prob_0(X_1=1|E_R)\underbrace{\prob_0(E_R)}_{0} + \underbrace{\prob_0(X_1=1|E_B)}_{0.2}\underbrace{\prob_0(E_B)}_{1} = 0.2,\\
			&P(0,2) = \prob(X_1=2|X_0=0) = \prob_0(X_1=2) = \prob_0(X_1=2|E_R)\underbrace{\prob_0(E_R)}_{0} + \underbrace{\prob_0(X_1=2|E_B)}_{0}\underbrace{\prob_0(E_B)}_{1} = 0,\\
			&P(1,0) = \prob(X_1=0|X_0=1) = \prob_1(X_1=0) = \underbrace{\prob_1(X_1=0|E_R)}_{0.2}\underbrace{\prob_1(E_R)}_{0.5} + \underbrace{\prob_1(X_1=0|E_B)}_{0}\underbrace{\prob_1(E_B)}_{0.5} = 0.1.\\
			&P(1,1) = \prob(X_1=1|X_0=1) = \prob_1(X_1=1) = \underbrace{\prob_1(X_1=1|E_R)}_{0.8}\underbrace{\prob_1(E_R)}_{0.5} + \underbrace{\prob_1(X_1=1|E_B)}_{0.8}\underbrace{\prob_1(E_B)}_{0.5} = 0.8.
		\end{align*}
		and so on. Then we will have the following transition matrix for this problem.
		\[	M = \begin{pmatrix}
				0.8 & 0.2 & 0 \\
				0.1 & 0.8 & 0.1 \\
				0 & 0.2 & 0.8
			\end{pmatrix}\]
		with the following graph
		\begin{center}
			\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.5cm,
				semithick,scale=0.4]
				\tikzstyle{every state}=[circle, draw, fill=orange!50,
				inner sep=0pt, minimum size=15pt]
				
				\node[state] (A)              {$0$};
				\node[state] (B) [right of=A] {$1$};
				\node[state] (C) [right of=B] {$2$};
				
				\path 
				(A) edge [loop left] node {$0.8$} (A)
				(A) edge [bend left] node {$0.2$} (B)
				(B) edge [loop above] node {$0.8$} (B)
				(B) edge [bend left] node {$0.1$} (A)
				(B) edge [bend left] node {$0.1$} (C)
				(C) edge [bend left] node {$0.2$} (B)
				(C) edge [loop right] node {$0.86$} (C);
			\end{tikzpicture}
		\end{center}
		Now, we need to compute the probability that the fifth ball drawn is red. This means that we have already drawn four balls, and now we want to draw the fifth one. So, we need to consider the 4 step transition matrix, i.e. $M^4$. Then
		\[ M^4 = \begin{pmatrix}
			0.4872 & 0.4352 & 0.0776 \\
			0.2176 & 0.5648 & 0.2176 \\
			0.0776 & 0.4352 & 0.4872 \\
		\end{pmatrix} \]
		Given that we have started with 2 red balls, then the probability of finding the Urn with 0 red balls is $0.0776$, with 1 red ball is $0.4352$, and with 2 red balls is $0.4872$. So the probability that the next drawn balls is red is
		\[ \prob(E_R) = \underbrace{\prob(E_R|X_4=0)}_{0}\underbrace{\prob(X_4=0)}_{0.0776} + \underbrace{\prob(E_R|X_4=1)}_{0.5}\underbrace{\prob(X_4=1)}_{0.4352} + \underbrace{\prob(E_R|X_4=2)}_{1}\underbrace{\prob(X_4=2)}_{0.4872} = 0.7048.  \]
	\end{solution} 
	
\end{example}

\begin{example}[Turning non-Markov processes to Markov-chain]
	Suppose that whether or not it rains today depends on previous weather conditions through the last two days. Specifically, suppose that if it has rained for the past two days, then it will rain tomorrow with probability 0.7; if it rained today but not yesterday, then it will rain tomorrow with probability 0.5; if it rained yesterday but not today, then it will rain tomorrow with probability 0.4; if it has not rained in the past two days, then it will rain tomorrow with probability 0.2. [This question is from Ross]. Given that it rained on Monday and Tuesday, what is the probability that it will rain on Thursday?
	\begin{solution}
		This random process is not a Markov chain, the value of the random variable at the next state, depends on two previous states. However, we can turn this into a Markov chain. Define the following states
		\begin{quote}
			$RR$: Rained yesterday and today.\\
			$R\overline{R}$: Rained yesterday, but not today.\\
			$\overline{R}R$: Not rained yesterday, but rained today.\\
			$\overline{R}\overline{R}$: Not rained yesterday and today.
		\end{quote}
		Suppose that we are at state $RR$. Suppose that it rained yesterday and also today. Thus we are at state $RR$. If it rains tomorrow, then we will be still at state $RR$. That is because, That is because the yesterday of tomorrow is today! So if it rains tomorrow, since today (yesterday of tomorrow) was also rainy, thus if it rains tomorrow then we will stay at state $RR$. If it does not rain tomorrow, then we will get to state $\overline{R}R$. The following matrix is the transition matrix for this Markov chain
		\[M = \begin{pmatrix}
			0,7 & 0.3 & 0 & 0 \\
			0 & 0 & 0.4 & 0.6 \\
			0.5 & 0.5 & 0 & 0 \\
			0 & 0 & 0.2 & 0.8
		\end{pmatrix}\]
		Now, to calculate the probability of raining on Thursday, given it rained on Monday and Tuesday, we first need to calculate the two step transition probability.
		\[
		M^2 = \begin{pmatrix}
			\boxed{0.49} & 0.21 & \boxed{0.12} & 0.18 \\
			0.2  & 0.2  & 0.12 & 0.48 \\
			0.35 & 0.15 & 0.2  & 0.3  \\
			0.1  & 0.1  & 0.16 & 0.64
		\end{pmatrix}
		\]
		The probability to rain on Thursday is the sum of the boxed elements in the matrix above. So the desired probability is 
		\[ p = 0.61. \]
	\end{solution}
	
\end{example}



\begin{example}
	\label{exm:MarkovChain-EmptyFullUrns}
	Suppose that balls are successively distributed among 8 urns, with each ball being equally likely to be put in any of these urns. What is the probability that there will be exactly 3 nonempty urns after 9 balls have been distributed? [Question from Ross]
	\begin{solution}
		Before going through the solution, it might be more informative to explicitly write down what is the sample space $ \Omega $. At each time step, we basically throwing a 8 sided dice, and then put a ball at the urn number $ i $ if the output of the dice is $ i $. So, each time we repeat the experiment, we will get a sequence of number each of which is one of $ 1,2,\cdots,8 $. So the sample space will be the set of all sequences consisting of number $ 1,\cdots,8 $.
		\[ \Omega = \set{21342\hdots, 44513\hdots, 11234\hdots, 88432\hdots, \cdots}. \]
		So, the outputs of the throwing dice at different steps are independent and identically distributed random variables. I.e. for a fixed $ \omega \in \Omega $, The $ t$-th element of the sequence is a random variable $ Y_t $ and all of the random variables $ \set{Y_t}_t $ are independent and identically distributed. Note that the sample space associated with these random variables is $ \set{1,2,3,4,5,6,7,8} $ (i.e. the sample space of a 8 sided dice experiment).w
		
		Let the random variable $X_n$ be the number of filled (non-empty) urns at step n. So the state space will be $S = \set{0,1,2,3,4,5,6,7,8}$, which is represented in the following graph.
		\begin{center}
			\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.2cm,
				semithick,scale=0.4]
				\tikzstyle{every state}=[circle, draw, fill=orange!50,
				inner sep=0pt, minimum size=15pt]
				
				\node[state] (A0)               {$0$};
				\node[state] (A1) [right of=A0] {$1$};
				\node[state] (A2) [right of=A1] {$2$};
				\node[state] (A3) [right of=A2] {$3$};
				\node[state] (A4) [right of=A3] {$4$};
				\node[state] (A5) [right of=A4] {$5$};
				\node[state] (A6) [right of=A5] {$6$};
				\node[state] (A7) [right of=A6] {$7$};
				\node[state] (A8) [right of=A7] {$8$};
%				\path 
%				(A) edge [loop left] node {$\frac{1}{2}$} (A)
%				(A) edge [bend left] node {$\frac{1}{2}$} (B)
%				(B) edge [loop right] node {$\frac{1}{2}$} (B)
%				(B) edge [bend left] node {$\frac{1}{2}$} (A);
				
			\end{tikzpicture}
		\end{center}
		This picture is not yet complete and we need to include the transition probabilities. We will do so by the first step argument. First, observe that $P(0,0) = 0$, because if we start with all of the urns empty, then after one step, we have put a ball somewhere, thus it is impossible to end up with zero filled urn. Similarly, $P(8,8) = 1$, that is because if all of the urns are filled, then adding any new ball somewhere to any of the urns will keep the number of filled urns at 8. Then for $X_0 =n$, i.e. starting with $n$ filled urns, we have
		\[ \prob_n(X_1=n-1) = 0. \]
		That is because starting with $n$ filled urns, after doing one step, it is not possible to have less urns filled. I.e. after each step, we can either end up with more filled urns or the same number of filled urns. For $P(n,n)$, define the event $E$ be the event of putting the ball in any of the filled urns. Thus $E^c$ will be the probability of putting the ball at one of the empty urns. 
		\[ \prob_n(X_1 = n) = \underbrace{\prob_n(X_1=n|E)}_{1}\underbrace{\prob_n(E)}_{n/8} + \underbrace{\prob_n(X_1=n|E^c)}_{0}\underbrace{\prob_n(E^c)}_{(8-n)/8} = \frac{n}{8}. \]
		Now for $\prob(n,n+1)$ we can write
		\[ \prob_n(X_1 = n+1) = \underbrace{\prob_n(X_1=n+1|E)}_{0}\underbrace{\prob_n(E)}_{n/8} + \underbrace{\prob_n(X_1=n+1|E^c)}_{1}\underbrace{\prob_n(E^c)}_{(8-n)/8} = 1-\frac{n}{8}. \]
		Thus the completed graph will be
		\begin{center}
			\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.2cm,
				semithick,scale=0.4]
				\tikzstyle{every state}=[circle, draw, fill=orange!50,
				inner sep=0pt, minimum size=15pt]
				
				\node[state] (A0)               {$0$};
				\node[state] (A1) [right of=A0] {$1$};
				\node[state] (A2) [right of=A1] {$2$};
				\node[state] (A3) [right of=A2] {$3$};
				\node[state] (A4) [right of=A3] {$4$};
				\node[state] (A5) [right of=A4] {$5$};
				\node[state] (A6) [right of=A5] {$6$};
				\node[state] (A7) [right of=A6] {$7$};
				\node[state] (A8) [right of=A7] {$8$};
				
				\path 
				(A0) edge [bend left] node {$1$} (A1)
				(A1) edge [bend left] node {$7/8$} (A2)
				(A2) edge [bend left] node {$6/8$} (A3)
				(A3) edge [bend left] node {$5/8$} (A4)
				(A4) edge [bend left] node {$4/8$} (A5)
				(A5) edge [bend left] node {$3/8$} (A6)
				(A6) edge [bend left] node {$2/8$} (A7)
				(A7) edge [bend left] node {$1/8$} (A8)
				
				(A1) edge [loop below] node {$1/8$} (A1)
				(A2) edge [loop below] node {$2/8$} (A2)
				(A3) edge [loop below] node {$3/8$} (A3)
				(A4) edge [loop below] node {$4/8$} (A4)
				(A5) edge [loop below] node {$5/8$} (A5)
				(A6) edge [loop below] node {$6/8$} (A6)
				(A7) edge [loop below] node {$7/8$} (A7)
				(A8) edge [loop right] node {$1$} (A8)
				
				
				;
				%				\path 
				%				(A) edge [loop left] node {$\frac{1}{2}$} (A)
				%				(A) edge [bend left] node {$\frac{1}{2}$} (B)
				%				(B) edge [loop right] node {$\frac{1}{2}$} (B)
				%				(B) edge [bend left] node {$\frac{1}{2}$} (A);
				
			\end{tikzpicture}
		\end{center}
		The corresponding transition matrix will be
		\[
		M = \begin{pmatrix}
			0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
			0 & 1/8 & 7/8 & 0 & 0 & 0 & 0 & 0 & 0 \\
			0 & 0 & 1/8 & 6/8 & 0 & 0 & 0 & 0 & 0 \\
			0 & 0 & 0 & 3/8 & 5/8 & 0 & 0 & 0 & 0 \\
			0 & 0 & 0 & 0 & 4/8 & 4/8 & 0 & 0 & 0 \\
			0 & 0 & 0 & 0 & 0 & 5/8 & 3/8 & 0 & 0 \\
			0 & 0 & 0 & 0 & 0 & 0 & 6/8 & 2/8 & 0 \\
			0 & 0 & 0 & 0 & 0 & 0 & 0 & 7/8 & 1/8 \\
			0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
		\end{pmatrix}
		\]
		The probability that after 9 steps, there are exactly three empty urns is $(M^9)_{(0,3)}$, which is
		\[ p = (M^9)_{(0,3)} \approx 0.007572. \]
	\end{solution}
\end{example}

\begin{example}
	It is a good practice to derive the value of the transition probability of a simple Markov chain using the first principles. Consider the Markov chain representing a lamp that turns on with probability $1/2$ and turns off with probability $1/2$, and stays at the old state with probability $1/2$. Thus we will have the following diagram for this Markov chain.
	\input{Images/explicitDerivationMarkovChainExample.tex}\\
	In this example, the state space is $S = \{0,1\}$, and the sample space is
	\[ \Omega = \{ (x_1,x_2,\cdots): x_i \in S \} \]
	which is basically the set of all sequences of one's and zero's. Given this, the random variables $(X_n)_n$ defined t be
	\[  X_n (\omega) = x_n, \]  
	where $\omega \in \Omega$ and $x_n$ is the $n$-th letter in $\omega$. Intuitively speaking, we know that 
	\[  P(1,0) = \prob(X_{n+1} = 1 | X_n = 0) = \frac{1}{2}. \]
	However, here we want to derive that number more explicitly by working directly with the elements of the probability space. First, we need to determine the event associated with $X_{n+1} = 1$. This is the event that has elements where the $n+1$-th position is 1. I.e.
	\[  E = \{  (x_1,x_2, \cdots, x_n, 1, x_{n+2}, \cdots) : x_i \in S\}.  \]
	Similarly, we have
	\[ F = \{ (x_1,x_2, \cdots, x_{n-1},0,x_{n+1},\cdots): x_i \in S \}. \]
	So we have
	\[ \prob(X_{n+1} = 1 | X_n = 0)  = \prob(E|F) = \frac{\prob(E\cap F)}{\prob(F)} =\frac{\prob(E\cap F)}{\prob(F\cap E) + \prob(F\cap E^c)} = \frac{\frac{1}{\abs{\Omega}}}{\frac{1}{\abs{\Omega}} + \frac{1}{\abs{\Omega}}} = \frac{1}{2}. \]
	Note that $\prob(E\cap F) = \frac{1}{\abs{\Omega}}$, since out of many combinations of the sequence of zeros and ones, there is one one sequence whose $n$-th place is 0 and $n+1$-th place is 1. Furthermore, $\prob(F\cap E^c) = \frac{1}{\abs{\Omega}}$ as there is only one string where its $n$-th and $(n+1)$-th string are both zero. 
\end{example}

\begin{example}
	In a sequence of independent flips of a fair coin, let N denote the number of flips until there is a run of three consecutive heads. Find
	\begin{enumerate}[(a)]
		\item $\prob(N\leq 8)$,
		\item $\prob(N = 8)$.
	\end{enumerate}
	\begin{solution}
		Let $X_n$ denote the number of consecutive heads at step $n$. For instance for the outcome $\omega \in \Omega$ where $\omega = HTTHTTHHHTTHT\hdots$, $X_2(\omega) = 0$ since the second symbol is $T$ thus there is no consecutive heads. But $X_4(\omega) = 1$, as there is one consecutive heads at step 4. Lastly $X_9(\omega) = 3$, since there is three consecutive heads at step 9. This Markov chain will have the following transition diagram.
		
		\begin{center}
			\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2.1cm,
				semithick,scale=0.7]
				\tikzstyle{every state}=[circle, draw, fill=orange!50,
				inner sep=0pt, minimum size=15pt]
				
				\node[state] (A1)              {$1$};
				\node[state] (A2) [right of = A1] {$2$};
				\node[state] (A0) [above=of $(A1)!0.5!(A2)$,yshift=-1cm]   {$0$};
				\node[state] (A3) [right of = A2] {$3$};

				\path 
				(A0) edge [loop above] node {$0.5$} (A0)
				(A0) edge [bend left] node [sloped,below] {$0.5$} (A1)
				(A1) edge [bend left] node [sloped] {$0.5$} (A0)
				(A2) edge node [above, sloped] {$0.5$} (A0)
				(A1) edge node [below] {$0.5$} (A2)
				(A2) edge node {$0.5$} (A3)
				(A3) edge [loop right] node {$1$} (A3)
				;
				
%				\path 
%				(A) edge [loop left] node {$\frac{1}{2}$} (A)
%				(A) edge [bend left] node {$\frac{1}{2}$} (B)
%				(B) edge [loop right] node {$\frac{1}{2}$} (B)
%				(B) edge [bend left] node {$\frac{1}{2}$} (A);
				
			\end{tikzpicture}
		\end{center}
	The transition probabilities are simply computed by the first step argument. For instance, for $P(0,1)$ we have
	\[ \prob_0(X_1 = 1) = \underbrace{\prob_0(X_1 = 1|H)}_{1}\underbrace{\prob_0(H)}_{1/2} + \underbrace{\prob_0(X_1 = 1|T)}_{0}\underbrace{\prob_0(T)}_{1/2}, \]
	where $H$ is the event that the flipped coin is heads and $H^c = T$. The transition matrix for this Markov chain will be
	\[
	M = \begin{pmatrix}
		0.5 & 0.5 & 0 & 0 \\
		0.5 & 0 & 0.5 & 0 \\
		0.5 & 0 & 0 & 0.5 \\
		0 & 0 & 0 & 1 \\
	\end{pmatrix}
	\]
	Since the state $3$ is an absorbing state, then if we get there we will be there for the rest of our life! Thus the probability that the random walker has got there for $N\leq 8$ is simply $(M^8)_{(0,3)}$. Then
	\[ \prob(N\leq 8) = 0.4180. \]
	Now for part (b), the probability that the random walker has arrived at the state 3 right at the step 8, is
	\[ \prob(N = 8) = \prob(N\leq 8) - \prob(N\leq 7) = 0.0508. \]
	
	There is yet another approach that we can compute the probability $\prob(N=8)$. To do this, we need to consider 4 states $S = \set{0,1,2,3,4}$ where the state 4 is of when 3 consecutive heads has occurred at the past. So when the random walker enters the state 3 at some time, it moves to the state $4$ at the next time and remains there forever. The state diagram will be
	
	\begin{center}
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2cm,
			semithick,scale=0.7]
			\tikzstyle{every state}=[circle, draw, fill=orange!50,
			inner sep=0pt, minimum size=15pt]
			
			\node[state] (A1)              {$1$};
			\node[state] (A2) [right of = A1] {$2$};
			\node[state] (A0) [above=of $(A1)!0.5!(A2)$,yshift=-1cm]   {$0$};
			\node[state] (A3) [right of = A2] {$3$};
			\node[state] (A4) [right of = A3] {$4$};
			
			
			\path 
			(A0) edge [loop above] node {$0.5$} (A0)
			(A0) edge [bend left] node [sloped,below] {$0.5$} (A1)
			(A1) edge [bend left] node [sloped] {$0.5$} (A0)
			(A2) edge node [above, sloped] {$0.5$} (A0)
			(A1) edge node [below] {$0.5$} (A2)
			(A2) edge node {$0.5$} (A3)
			(A3) edge node {$1$} (A4)
			(A4) edge [loop right] node {$1$} (A4)
			;
			
			%				\path 
			%				(A) edge [loop left] node {$\frac{1}{2}$} (A)
			%				(A) edge [bend left] node {$\frac{1}{2}$} (B)
			%				(B) edge [loop right] node {$\frac{1}{2}$} (B)
			%				(B) edge [bend left] node {$\frac{1}{2}$} (A);
			
		\end{tikzpicture}
	\end{center}
	Then the transition matrix will be
	\[
	M = \begin{pmatrix}
		0.5 & 0.5 & 0 & 0 & 0 \\
		0.5 & 0 & 0.5 & 0 & 0 \\
		0.5 & 0 & 0 & 0.5 & 0 \\
		0 & 0 & 0 & 0 & 1 \\
		0 & 0 & 0 & 0 & 1
	\end{pmatrix}
	\]
	Then the probability $\prob(N=8) = (M^8)_{(0,3)} = 0.05080.$
	\end{solution}
\end{example}


\begin{example}[Gambler's Ruin]
	Suppose Alice and Bob have in total of $N$ coins. Alice and Bob play a game with a fair coin. When Alice wins, gets a coin from Bop, and vise versa. What is the probability that Alice wins if she starts with $0\leq a \leq N$ coins.
	
	\begin{solution}
		There are many ways to tackle a probability problem like this and the solution presented here is not the only way to find the solution to this problem. We want to model this with Markov chain whose state space is $\{0,1,2,\cdots,N\}$. Thus $X_n$ represents the fortune of Alice after playing the games for $n$ times. 
		\input{Images/GamblersRuinExample.tex} \\
		Let $p_a$ be the probability of Alice wining if she starts with $a$ coins. First, observe that $p_0 = 0$ and $p_N= 1$. Let $E$ denote that event of Alice wining the whole game. Also, let $F_1$ be the event in which she looses the first game and $F_2$ the event in which she wins the first game. Then
		\[ p_a = \prob_a(E) =  \underbrace{\prob_a(E | F_1)}_{\prob(E|F_1,X_0=a)} \prob(F_1) + \underbrace{\prob_a(E|F_1^c)}_{\prob(E|F_1^c,X_0=a)}\prob(F_1^c) \]
		(note that this identity is actually true for any set $F_1$, but here $F_1$ is the specific event explained above). The probability that she looses or wins the first game is $\frac{1}{2}$. Also, observe that $\prob_a(E|F_1) = p_{a+1}$ (since if she wins the first game she will have one more coin) and $\prob_a(E|F_1^c) = p_{a-1}$. Thus 
		\[ p_a = \frac{1}{2}p_{a+1} + \frac{1}{2}p_{a-1}. \]
		Now we can solve this recurrent equation with the characterization polynomial which is $2 = X + 1/X$ or $X^2 - 2X + 1 = (X-1)^2 = 0$. Thus the characteristic polynomial has a double root. Thus 
		\[ p_a = (Aa + B)(1)^a = Aa + B. \]
		Since $p_0 = 0,\ p_N =1$, then it turns out that
		\[ p_a = \frac{a}{N}. \]
	\end{solution}
\end{example}

\begin{example}[Gambler's Ruin with Draw]
	Let Alice and Bob play Rock-Paper-Scissors. If Alice and Bob has a total of $N$ coins, and at each play, the winner gets one coin from the loser, what is the probability that Alice will win the game if he starts with $a$ coins. When they draw, then they repeat the game (or equivalently, they play another game without any coins exchange).
	
	\begin{solution}
		We need to do a first step analysis similar to what we did before. Let $E$ be the event that Alice wins the whole game, and the event $F=F_{-1}\cup F_0 \cup F_1$ where
		\begin{quote}
			$F_{-1}$: Alice loses the first game,\\
			$F_0$: Alice draws the first game,\\
			$F_1$: Alice wins the first game.
		\end{quote}
		It is clear that $\prob(F) = 1$, since the components are mutually disjoint. Thus $E\cap F_{-1},\ E\cap F_0,\ E\cap F_1$ are also mutually disjoints where. Thus we can write
		\[\prob_a(E) = \prob_a(E\cap F_{-1}) + \prob_a(E\cap F_0) + \prob_a(E\cap F_1)
				= \prob_a(E|F_{-1})\prob_a(F_{-1}) + \prob_a(E|F_0)\prob_a(F_0) + \prob_a(E|F_1)\prob_a(F_1).
		\]
		Since the game is fair we know
		\[ \prob_a(F_{-1}) = \prob_a(F_0) = \prob_a(F_1) = \frac{1}{3}.  \]
		Furthermore, we know
		\[ \prob_a(E|F_{-1}) = p_{a-1}, \qquad \prob_a(E|F_0) = p_a, \qquad \prob_a(E|F_1) = p_{a+1}. \]
		Thus the first step analysis will lead to the following identity.
		\[  \prob_a(E) = p_a = \frac{1}{3} ( p_{a-1} + p_{a} + p_{a+1}),\]
		which after simplification becomes
		\[ 2p_a = p_{a-1} + p_{a+1}, \]
		which is the same recursive formula we got in the previous example. So the possibility of the draw, will not change the behaviour of the system.
	\end{solution}
\end{example}

\begin{example}
	Consider the a simple random walker on the following graph. Let $B = \{ T_{\tilde{x}} < T_{\set{\tilde{z},\tilde{y}}} \}$. Compute the probability $\prob_0(B)$.
	
	\begin{center}
		\begin{tikzpicture}[scale=1.5, every node/.style={circle, draw}]
			\tikzstyle{every node}=[circle, draw, fill=white,
			inner sep=0pt, minimum width=15pt]
			
			\node[fill=cyan!50] (a) at (0,0) {0};
			\node[fill=orange!50] (z1) at (1/2,0) {$z$};
			\node[fill=orange!50] (z2) at (2/2,0) {};
			\node[fill=orange!50] (z3) at (3/2,0) {\ };
			\node[fill=orange!50] (z4) at (4/2,0) {\ };
			\node[fill=red!50] (ze) at (5/2,0) {$\tilde{z}$};
			
			\node[fill=orange!50] (x1) at (-1/2,1/2) {$x$};
			\node[fill=green!50] (xe) at (-1,1) {$\tilde{x}$};
			
			\node[fill=orange!50] (y1) at (-1/2,-1/2) {$y$};
			\node[fill=orange!50] (y2) at (-2/2,-2/2) {};
			\node[fill=red!50] (ye) at (-3/2,-3/2) {$\tilde{y}$};
			
			
			\draw (a) -- (z1);
			\draw (z1) -- (z2);
			\draw (z2) -- (z3);
			\draw (z3) -- (z4);
			\draw (z4) -- (ze);
			
			\draw (a) -- (y1);
			\draw (y1) -- (y2);
			\draw (y2) -- (ye);
			
			\draw (a) -- (x1);
			\draw (x1) -- (xe);
			
		\end{tikzpicture}
	\end{center}
	
	\begin{solution}
		This problem is simply asking what is the probability that we hit $\tilde{x}$ state before hitting any of $\tilde{y}$ or $\tilde{z}$ states, given the fact that the random walker starts from the state $0$. To keep unnecessary details out of the way, we have only labeled the vertices that we will use in our analysis. We will have the following notation to simplify the solution
		\[ p_v = \prob_v(B), \]
		where $v$ is any vertex in the graph. Note that starting at 0, i.e. $X_0=0$, then going to any of the states $x,y$, or $z$, are mutually disjoint events, and the probability of the union of these events is one. With our first time step analysis (see \autoref{prop:FirstTimeStepArgument}) we can write
		\[ \prob_0(B) = \frac{1}{3} ( p_x + p_y + p_z). \]
		Now we need to analyze each of terms in the RHS. Let's start with $p_z$. Consider two events $\{ T_0 < T_{\tilde{z}}  \}$ and $\{ T_0 > T_{\tilde{z}}  \}$, where the first time is the event where the random walker hits the $0$ state before hitting the $\tilde{z}$ step first, and the second one is the vice versa. These two events are disjoint and the probability of the union is 1. Thus we write the conditional expansion of $p_z$ based on these events
		\[ p_z = \prob_z(B) = \prob_z(B|T_0 < T_{\tilde{z}})\prob_z(T_0 < T_{\tilde{z}}) + \prob_z(B|T_0 > T_{\tilde{z}})\prob_z(T_0 > T_{\tilde{z}}). \]
		We know that $\prob_z(B|T_0 > T_{\tilde{z}}) = \prob(B|X_0=z,X_i=\tilde{z})$ for some $i > 0$. From Markov property it follows that 
		\[ \prob(B|X_0=z,X_i=\tilde{z}) = \prob(B|X_i=\tilde{z}) = \prob(B|X_0 = \tilde{z})  = p_{\tilde{z}}.\]
		Also $\prob_z(B|T_0<T_{\tilde{z}}) = \prob_0(B) = p_0$ by the Markov property. Lastly, $\prob_z(T_0<T_{\tilde{z}})$ is determined by the Gambler's ruin method we say before, which is basically
		\[ \prob_z(T_0 < T_{\tilde{z}}) = \frac{5}{4}, \qquad \prob_z(T_0>T_{\tilde{z}}) = \frac{1}{5}. \]
		By doing the same kind of analysis for $p_x$ as well as $p_y$ we will get
		\[ p_z = \frac{4}{5}p_0 , \qquad p_y = \frac{2}{3}p_0, \qquad p_x =\frac{1}{2}p_0 + \frac{1}{2}. \]
		Now by substituting in the identity we got from the first time step argument, we can fine that 
		\[ p_0 = \frac{15}{31}, \]
		And this completes our solution for the problem.
	\end{solution}
	
\end{example}

\begin{example}
	Consider the graph $\gamma=  (V,E)$ drawn below. Set $Z = \{2,3\}$, and $W = \set{6,9}$. Compute $\prob_0(T_Z<T_W)$. In colors: we start at blue, win if we reach green, and lose of we reach red.
	
	\begin{center}
		\begin{tikzpicture}[scale=1.5, every node/.style={circle, draw}]
			\tikzstyle{every node}=[circle, draw, fill=orange!50,
			inner sep=0pt, minimum width=15pt]
			
			\node[fill=blue!50] (n0) at (1/2,0) {0};
			\node (n1) at (0/2,0) {1};
			\node[fill=green!50] (n2) at (-1/2,-1/2) {2};
			\node[fill=green!50] (n3) at (-1/2,1/2) {3};
			\node (n4) at (-2/2,2/2) {4};
			\node (n5) at (2/2,-1/2) {5};
			\node[fill=red!50] (n6) at (3/2,-2/2) {6};
			\node (n7) at (2/2,1/2) {7};
			\node (n8) at (3/2,2/2) {8};
			\node[fill=red!50] (n9) at (3/2,0/2) {9};

			
			\draw (n0) -- (n1);
			\draw (n1) -- (n2);
			\draw (n1) -- (n3);
			\draw (n3) -- (n4);
			\draw (n0) -- (n7);
			\draw (n0) -- (n5);
			\draw (n5) -- (n6);
			\draw (n7) -- (n9);
			\draw (n7) -- (n8);
			
		\end{tikzpicture}
	\end{center}
\end{example}

\begin{solution}
	As always, we start with our powerful tool in hand, which is the first step argument (which is basically a special form of the more general conditional expansion). We start with first step argument at state $0$. We will get
	\[ \prob_0(B) = \frac{1}{3} (\prob_1(B) + \prob_7(B) + \prob_5(B) ), \]
	and now we need to analyze each of the terms in the right hand side. We start with $\prob_5(B)$ which is the most straight forward one. As we saw in the last example, we can analyze this state with a conditional expansion on the two disjoint events, whose union probability is 1. Let those two events be $\set{T_6 < T_0}$ (where the random walker hits the state $6$ before hitting the state $0$), and $\set{T_6 > T_0}$, where the random walker hits the state $0$ before hitting the state $6$. Thus the expansion will be
	\[ \prob_5(B) = \prob_5(B|T_6 < T_0) \prob_5(T_6 < T_0) + \prob_5(B|T_6 > T_0)\prob_5(T_6 > T_0). \]
	We know that if we hit the state $6$ before $0$, we have no chance to hit any of the green states (we will lose). Thus
	\[ \prob_5(B|T_6<T_0) = 0. \]
	And from the Gambler's ruin we know that $\prob_5(T_6>T_0) = 1/2$, and from the Markov property we know that $\prob_5(B|T_6>T_0) = \prob_0(B)$, because the conditional probability $\prob_5(B|T_6>T_0)$ is basically stating what is the probability of $B$ happening, if we start from $5$ and $X_i = 0$ for some $i$ in the future. Thus 
	\[ \prob_5(B) = \frac{\prob_0(B)}{2}. \]
	Now, we need to analyze the term $\prob_1(B)$. Again, at this step, we do another first step analysis.
	\[  \prob_1(B) = \frac{1}{3} (\underbrace{\prob_3(B)}_{=1} + \underbrace{\prob_2(B)}_{=1} +\prob_0(B)) = \frac{2+\prob_0(B)}{3}. \]
	Note that from the assumption, we know that if we reach any of green states, then we are declared winner, that is why we have $\prob_3(B) = \prob_2(B) = 1$. Now it only remains to analyze the term $\prob_7(B)$. Again, similar to the case above, we do a first time step argument
	\[ \prob_7(B) = \frac{1}{3} ( \prob_0(B) + \underbrace{\prob_8(B)}_{=\prob_7(B)} + \underbrace{\prob_9(B)}_{=0} ) \implies \prob_7(B) = \frac{\prob_0(B)}{2}.\]
	Note that $\prob_8(B) = \prob_7(B)$ by a first stem analysis when starting at the state $8$. Putting all of these terms back to the original identity we derived the first, we can conclude that 
	\[ p_0 = \prob_0(B) = \frac{2}{5}. \]
\end{solution}







\section{Solved Problems}
\input{sections/SolvedProblemsMarkovChainII/Q1.tex}
\input{sections/SolvedProblemsMarkovChainII/Q2.tex}
\input{sections/SolvedProblemsMarkovChainII/Q3.tex}
\input{sections/SolvedProblemsMarkovChainII/Q4.tex}
\input{sections/SolvedProblemsMarkovChainII/Q5.tex}

