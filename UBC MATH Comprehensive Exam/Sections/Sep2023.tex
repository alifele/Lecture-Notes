\chapter{September 2023}


\section{Algebra}

\begin{problem}
	\begin{enumerate}[(a)]
		\item Prove that any module over $ \Z[i] $ is a direct sum of a free module and a torsion module. Is the same true for modules over $ \Z[\sqrt{-5}] $?
		\item Let $ I = 3+2i $ be the ideal in $ \Z[i] $ generated by the element $ 3+2i $. Describe the quotient $ \Z[i]/I $.
	\end{enumerate}
\end{problem}


\section{Linear Algebra}
\begin{problem}
	\begin{enumerate}[(a)]
		\item Find a lower triangular matrix $ L $ such that $ LL^T = A $, where 
		\[ A = \begin{pmatrix}
			1 & 1 & 0 & 2 \\
			1 & 5 & 2 & 2 \\
			0 & 2 & 2 & 1 \\
			2 & 2 & 1 & 6
		\end{pmatrix} \]
		\item Compute $ \det(A) $.
		
		\item Find the volume in $ \R^4 $ of the set $ S_A = \set{x\in \R^4: x^T A x \leq 1}.  $
	\end{enumerate}
\end{problem}


\begin{solution}
	\begin{enumerate}[(a)]
		\item Let $ L $ be
		\[ L = \begin{pmatrix}
			l_{11} & 0 & 0 & 0 \\
			l_{21} & l_{22} & 0 & 0 \\
			l_{31} & l_{32} & l_{33} & 0 \\
			l_{41} & l_{42} & l_{43} & l_{44} \\
		\end{pmatrix} \]
		So $ A = LL^T $ we will have
		\[ A = \begin{pmatrix}
			l_{11}^2 & l_{11}l_{21} & l_{11}l_{31} & l_{11}l_{41} \\
			l_{11}l_{21} & l_{21}^2 + l_{22}^2 & l_{21}l_{31} + l_{22}l_{32} & l_{21}l_{41} + l_{22}l_{42} \\
			l_{11}l_{31} & l_{31}l_{21} + l_{32}l_{22} & l_{31}^2 + l_{32}^2 + l_{33}^2 & l_{31}l_{41} + l_{32}l_{42} + l_{33}l_{43} \\
			l_{41}l_{11} & l_{41}l_{21} + l_{42}l_{22} & l_{41}l_{31} + l_{42}l_{32} + l_{43}l_{33} & l_{41}^2 + l_{42}^2 + l_{43}^2 + l_{44}^2
		\end{pmatrix}  \]
		By solving the equations formed by the first row we have
		\[ l_{11} = 1,\ l_{21} = 1,\ l_{31}=0,\ l_{41} = 2. \]
		Furthermore
		\[ l_{22} = 2,\ l_{32} = 1,\ l_{33}=1, \]
		and lastly
		\[ l_{42} = 0, l_{43} = 1, l_{44} = 1. \]
		So the matrix $ L $ will be
		\[ L = \begin{pmatrix}
			1 & 0 & 0 & 0 \\
			1 & 2 & 0 & 0 \\
			0 & 1 & 1 & 0 \\
			2 & 0 & 1 & 1
		\end{pmatrix} \]
		
		\item We will expand relative to the last column as it has more zeros.
		\[ \det(L) = \det\begin{pmatrix}
			1 & 0 & 0 \\
			1 & 2 & 0 \\
			0 & 1 & 1 
		\end{pmatrix}. \]
		Again, expanding relative to the last column we will have
		\[ \det(L) = \det\begin{pmatrix}
			1 & 0 \\
			1 & 2
		\end{pmatrix} = 2. \]
		
		\item First, we find a suitable linear transformation that can map the volume to another volume for which we know how to calculate its volume. Consider the linear transformation $ x = L^{-T}  y $. Since $ x^T A x = (y^T \inv{L}) L L^T (L^{-T}x) = y^T y $, thus the set $ x^T A x \leq 1  $ will be mapped to the 4-ball (4 dimensional ball). So its volume will be
		\[ \abs{x^T A x \leq 1} = \det(L) \abs{y^T y \leq 1} = 2 \abs{S^4}. \]
		(Note: The volume of the 4-ball is $ \pi^2/2 $.)
	\end{enumerate}
\end{solution}



\begin{problem}
	Let $ P_n $ be the $ n+1 $-dimensional space of polynomials of degree $ n $ with real coefficients, and let $ <\cdot,\cdot> $ be the inner product defined as
	\[ <p,q> = \int_{-1}^{1} p(x)q(x)\ dx. \]
	\begin{enumerate}[(a)]
		\item Find an orthogonal basis $ \set{u_0, u_1, u_2} $ for $ P_2 $ such that $ u_j \in P_j $, and $ u_j(1) > 0 $.
		\item Using the basis in part (a), express the operator $ F[p] := \int_{-1}^{1} p(x) dx $ acting on $ P_2 $ as a $ 1\times 3 $ matrix. 
		\item Using the basis in part (a), express the derivative operator $ D[p]:= \frac{d}{dx}p(x) $ as a $ 3\times 3 $ matrix. 
	\end{enumerate}
\end{problem}
\begin{solution}
	\begin{enumerate}[(a)]
		\item We start with the Gram-Schmidt orthogonalization. Let $ \set{c,x,x^2} $ be the basis vectors that we want to orthogonalize. Let $ u_0 = c $. Then the first vector will be $ \hat{u}_0 = u_0/\norm{u_0} = 1/\sqrt{2}  $. To find the second vector we have
		\[ u_1 = x - <x,\hat{u}_0>\hat{u}_0 = x - \frac{1}{2}\int_{-1}^{1}x\ dx  = x. \]
		So the second normal vector will be $ \hat{u}_1 = u_1 / \norm{u_1} = \sqrt{\frac{3}{2}}x. $ To find the third vector we have
		\begin{align*}
			u_2 &= x^2 - (<x^2,\hat{u}_0>\hat{u}_0 + <x^2,\hat{u}_1>\hat{u}_1) \\
			&= x^2 - (\frac{1}{2}\int_{-1}^{1}x^2 dx + \frac{3}{2}\int_{-1}^{1}x^3 dx)  \\
			&= x^2 - (1/3 + 0) = x^2 - 1/3.
		\end{align*}
		So the third normal vector will be $ \hat{u}_2 = u_2 / \norm{u_2} = 3/2\sqrt{\frac{5}{2}}(x^2 - 1/3) $. However, since the question has not asked for normal basis vectors, for the following sections of the question we will use the following orthogonal (not orthonormal) basis vectors
		\[ u_1 = 1,\quad u_1 = x,\quad u_2 = x^2 - \frac{1}{3}. \]
		
		\item It is enough to see what is the effect of this operator on the basis vectors
		\[ F[u_0] = \int_{-1}^{1} 1 dx = 2, \quad F[u_1] = \int_{-1}^{1} x dx = 0,\quad F[u_2] = \int_{-1}^{1} (x^2 - 1/3)dx = 2/3 - 2/3 = 0. \]
		So the matrix representation of this operator will be
		\[ F = \begin{pmatrix}
			2 & 0 & 0
		\end{pmatrix}. \]
		
		\item Similarly to the solution above, 
		\[ D[u_0] = 0, \quad D[u_1] = 1, D[u_2] = 2x, \]
		so the matrix representation will be 
		\[ D = \begin{pmatrix}
			0 & 1 & 0 \\
			0 & 0 & 2 \\
			0 & 0 & 0
		\end{pmatrix} \]
	\end{enumerate}
\end{solution}

\begin{problem}
	Recall that an orthogonal projection matrix is a matrix $ P $ that satisfies 
	\[ P^2 = P, \quad P = P^T. \]
	Suppose $ P $ is an $ n\times n $ projection matrix with $ \rank(P) = k $. In the following, $ I_m $ denotes the $ m\times m $ identity matrix. 
	
	\begin{enumerate}[(a)]
		\item List all the eigenvalues of $ P $, including multiplicity. Be sure to justify your reasoning.
		\item Show that $ P = AA^T $ for some $ n\times k $ matrix $ A $ such that $ A^TA = I_k $.
		\item Suppose $ P_1, P_2 $ are two $ n\times n $ projection matrices with rank $ k $. Show that there exists an $ n\times n $ orthonormal matrix $ U $ (i.e. such that $ U^T U = I_n, UU^T = I_n$) such that $ P_2 = UP_1 U^T $.
	\end{enumerate}
\end{problem}
\begin{solution}
	\begin{enumerate}[(a)]
		\item The projection matrix $ P $ has only two eigenvalues $ \lambda_1 = 1 $ and $ \lambda_2 = 0 $. The eigenvectors corresponding to $ \lambda_2 $ eigenvalue are the basis vectors of the null-space of $ P $ (that has dimension $ n - k $), and the eigenvectors corresponding to $ \lambda_1 $ are the basis vectors of the orthogonal sub-space to the null space of $ P $. Thus $ \lambda_2 $ has multiplicity $ n-k $ and $ \lambda_1 $ has multiplicity $ k $. 
		
		\item Since $ P $ is symmetric, then we can choose the eigenvectors to form an orthogonal basis. Let $ U = [U_1\ U_2] $ be the matrix that its columns are the eigenvectors and $ U_1 $ are the one with eigenvalue 1 while $ U_2 $ are the one with eigenvalue 0. Note that since the columns in $ U $ are orthogonal, then $ \inv{U} = U^T $. Let $ D $ be the diagonal matrix of $ P $, then we can write
		\[ P = U D U^T = [U_1\ U_2] \matt{I_k}{0}{0}{0} \vectt{U_1^T}{U_2^T} = U_1 U_1^T. \]
		Note that $ U_1^T U_1  = I_k$ since $ U $ is orthogonal matrix.
		
		\item From part (b) we know that there are matrices $ A_1, A_2 $ such that 
		\[ P_1 = A_1A_1^T,\qquad P_2 = A_2A_2^T. \]
		Define $ U = A_1A_2^T $. Then
		\[ P_1 = A_1A_1^T = A_1 (A_2^TA_2 A_2^T A_2) A_1^T = (A_1A_2^T) A_2A_2^T (A_2A_1^T) = U P_2 U^T. \]
	\end{enumerate}
\end{solution}


\section{Real Analysis}
\begin{problem}
	Let $ S $ be the part of the paraboloid $ z = 2 - x^2 - y^2 $ above the cone $ z = \sqrt{x^2+y^2} $, with upward orientation. Let
	\[ F = (\tan\sqrt{z}) + \sin(y^3) \hat{i} + e^{-x^2} \hat{j} + z \hat{k}. \]
	Evaluate the flux integral $ \iint_S F\cdot dS.\ $
\end{problem}
\begin{solution}
	{\color{red} \noindent TODO: Final answer to be added.}
\end{solution}


\begin{problem}
	Let $ f(x) = \sum_{n=1}^{\infty}\sin(nx)x^n$ for those $ x $ for which the series converges. Note that this is NOT a power series. 
	\begin{enumerate}[(a)]
		\item Show that $ f $ is defined and continuous on $ (-1,1) $.
		\item Shoat the $ f $ is differentiable and that $ f' $ is continuous on $ (-1,1) $.
	\end{enumerate}
\end{problem}
\begin{solution}
	\begin{enumerate}[(a)]
		\item We use the Weierstrass M-test to show that the series converges uniformally on $ (-1,1) $. To see this let $ r \in (0,1) $. Then on $ [-r,r] $ we have $ \abs{\sin(nx)x^n} \leq r^n $. Since $ \sum r^n < \infty $ (by the geometric series) then by Weierstrass M-test the series $ \sum_n \sin(nx)x^n $ converges on $ [-r,r] $ uniformly and absolutely for all $ r\in (0,1) $. This implies uniform and absolute converges on $ (-1,1) $. To show the continuity of the series, observe that $ \sin(nx)x^n $ is continuous for all $ n $. Thus this continuity carries over through the uniform converges. 
		
		\item First, observe that each term in the sum is continuously differentiable. Denote the $ n $-th term by $ f_n(x) $, then we will have
		\[ f_n(x) = n\cos(nx)x^n + nx^{n-1}\sin(nx) = nx^{n-1} (x\cos(nx) + \sin(nx)). \]
		For $ x \in (-1,1) $, the term inside the parenthesis will be
		\[ \abs{x\cos nx + \sin nx} \leq \abs{x}\abs{\cos nx} + \abs{\sin nx} \leq 2. \]
		Let $ r \in (0,1) $ and $ x \in [-r,r] $, then we will have 
		\[ nx^{n-1} \leq nr^{n-1} \quad \forall x \in [-r,r]. \]
		Observe that the series $\sum_n nr^{n-1} $ converges for $ r\in (-1,1) $ (you can see this easily by the ratio test). So for $ r\in (0,1) $
		\[ f_k(x) \leq M_k  \qquad \forall x\in (-r,r). \]
		for some $ M_k > 0 $ (to be precise $ M_k = 2kr^{k-1} $) where $ \sum_k M_k < \infty $. So by the Weierstrass M-test $ \sum_k f'_k(x) $ converges uniformly on any compact subset $ [-r,r] $ for $ r\in (0,1) $, and because each term is continuous, the $ f' $ is also continuous on $ (-1,1) $. So far have observed that $ \sum_k f_k(x) $ converges on compact subsets of $ (-1,1) $, $ \sum_k f'_k(x) $ converges on compact subsets of $ (-1,1) $, and $ f_k $ is continuously differentiable. So we can do a term by term differentiation. 
	\end{enumerate}
\end{solution}

\begin{problem}
	Let $ \set{x_n} $ be a sequence of positive real numbers, and define
	\[ \alpha = \liminf_{n\to\infty}\frac{x_{n+1}}{x_n},\qquad \beta = \limsup_{n\to\infty}\frac{x_{n+1}}{x_n}. \]
	Note that $ \alpha = \infty $ and $ \beta = \infty $ may occur.
	\begin{enumerate}[(a)]
		\item Prove that if $ \beta < 1 $, the sequence $ \set{x_n} $ converges. 
		\item Prove that if $ \alpha > 1 $, the sequence $ \set{x_n} $ diverges. 
		\item Give an example of a  convergent sequence $ \set{x_n} $ for which $ \alpha = 1/2 $.
		\item Give an example of a divergent sequence $ \set{x_n} $ for which $ \beta = 1 $.
	\end{enumerate}
\end{problem}
\begin{solution}
	\begin{enumerate}[(a)]
		\item We choose $ \epsilon>0 $ small enough such that $ r = \beta + \epsilon < 1 $. Since $ \beta $ is the limsup of the sequence $ x_{n+1}/x_n $, then we know that $ \exists N \in \N $ such that $ \forall n > N $ we have $ x_{n+1}/x_n < r $. Calling $ x_{n} = C $ we see that the each term in sequence $ x_{N}, x_{N+1},\dots $ will be dominated by $ C, rC, r^2C,\dots $. Since the latter sequence is summable (since $ r<1 $), the former is summable as well. This implies that $ \sum_n x_n $ converges. 
		
		\item We choose $ \epsilon>0 $ small enough such that $ r = \alpha - \epsilon > 1 $. So there exists $ N\in \N $ such that $ \forall n > N $ we have $ x_{n+1}/x_n > r $. Calling $ x_n = C $ we see that each term in the sequence $ C, rC, r^2C, \dots $ is dominated by $ x_{n},x_{n+1},x_{n+2},\dots $.  Since the former diverges, the latter diverges as well. This implies that $ \sum_n x_n $ diverges. 
		
		\item Let $ \set{x_n} $ be the geometric series $ 1,r,r^2,\cdots $ with $ r = 1/2 $. Then $ \alpha = r $ and we know that the series $ \sum_n r^n  $ converges to 2.
		
		\item One classic example is $ x_n = 1/n $, the harmonic series. 
	\end{enumerate}
\end{solution}


\section{Complex Analysis}
\begin{problem}
	\begin{enumerate}[(a)]
		\item Find
		\[ \int_C \left(  \frac{z}{(z-1)(z^2+1)} + \frac{e^z}{z-3i}  \right) dz, \]
		where $ C $ is the counterclockwise oriented circle centered at $ (0,0) $ of radius 2.
		\item Find all values of $ z \in \C $ such that $ f(z) = 2(x^3-3xy^2+y) + i(3yx^2-y^3) $ is analytic at $ z $.
	\end{enumerate}
	
\end{problem}
\begin{solution}
	\begin{enumerate}[(a)]
		\item We use the generalized Cauchy theorem. To state the theorem, let $ \Omega $ be an open set containing a closed curve and its interior and $ f $ be a holomorphic function on $ \Omega $ except at poles $ z_1,\cdots,z_n $ inside the closed curve, then
		\[ \int_\gamma  f(z) dz = 2\pi i (\sum_{i=1}^n \operatorname{res}_{z_i}f). \]
		Observe that the integrand has 4 residues, three of which lies inside the closed curve $ C $, i.e. $ z_1=1, z_2 = i, z_3 = -i $. We now need to calculate the residue of the integrand at these points. For $ z_1 = 1 $ we have
		\[ \operatorname{res}_{z_1}f = \lim_{z\to1} (z-1)f(z) = \frac{1}{2}. \]
		Similarly for $ z_2 = i $
		\[ \operatorname{res}_{z_2}f = \lim_{z\to i} (z-i)f(z) = \frac{1}{2(i-1)}. \]
		And finally for $ z_3 = -i $
		\[ \operatorname{res}_{z_2}f = \lim_{z\to i} (z-i)f(z) = \frac{-1}{2(i+1)}. \]
		So the sum of residues at the poles inside $ C $ is zero. This implies that the integral evaluates to zero.
		
		\item We will use the converse of the Cauchy-Riemann equations, i.e. we demand the partial derivatives to exist and be continuous, and the Cauchy-Riemann equations to hold. The partial derivatives of $ u,v $ are continuous. So we only demand the C-R equations to hold.
		\[ u_x = v_y, \qquad u_y = -v_x. \]
		Observe that $ u_x = 2(3x^2-3y^2), u_y = 2(-6xy+1), v_x=6xy, v_y=3x^2-3y^2. $
		Thus we need to have
		\[ 2(3x^2-3y^2) = 3x^2-3y^2, \qquad -12xy+2 = -6xy. \]
		The first equation results in $ x^2 = y^2  $ and the second equation results in $ xy = 1/3 $. So $ f $ is holomorphic at only the points where $ x = y = \pm \frac{1}{\sqrt{3}} $. I.e. $ z = \pm\frac{1}{\sqrt{3}}(1+i) $.
	\end{enumerate}
	
\end{solution}


\begin{problem}
	Find the domain of analyticity of $ f(z) = \sqrt{\log(z+1) - \frac{\pi}{2}i} $, where the square root is given by the principal branch and $ \log(z) $ is the principal branch of log function.
\end{problem}
\begin{solution}
	We need to consider the branch cuts of the log function and the square root function. For the latter, if $ w = \log(z+1) - \frac{\pi}{2}i $ the branch cut is where $ w \leq 0 $. Using the fact that $ \log(z+1) = \ln\abs{z+1} + i\arg(z) $, we need to have
	\[ \ln\abs{z+1} \leq 0 \qquad \arg(z) = \pi/2. \]
	The first equation above implies that $ \abs{z+1}\leq 1 $ and the second equation implies that $ z = -1 + it $ for $ t\geq 0 $. So the branch cut for square root will be the set $ \set{-1+it:\ t \in [0,1] } $. Furthermore the branch cut of the function $ \log(z+1) $ is the set $ \set{t:\ t\leq -1} $. So the domain of analyticity of the function $ f $ will be
	\[ \set{-1+it:\ t \in [0,1] } \cup \set{t:\ t\leq -1}. \]
\end{solution}

\begin{problem}
	Suppose that $ f $ is an analytic function on $ H = \set{z\in \C:\ \real(z)\leq 0} $ with
	\[ f(-1) = f'(-1) = 0 \qquad \text{and} \qquad f''(-1) = \frac{i}{2}. \]
	\begin{enumerate}[(a)]
		\item Show that $ g(z)=f(z)/(z+1)^2 $ is analytic on $ H $. Find the residue of $ g $ at $ -1 $ and the residue of $ f(z)/(z+1)^3 $ at $ -1 $.
		\item Suppose $ \abs{f(z)}\leq \frac{1}{2}\abs{z+1}^2 $. Show that $ \abs{f(-3/2)}\leq 9/80 $.
	\end{enumerate}
\end{problem}

\begin{solution}
	\begin{enumerate}[(a)]
		\item Since $ f $ is holomorphic on $ H $, then at every point of $ H $ it has a power series. In particular
		\[ f(z) = (z-1) + (z-1)f'(z) + (z-1)^2f''(z)/2 + (z-1)^3f'''(z)/6 + \cdots. \]
		Since $ f(-1) = f'(-1) = 0 $, we have
		\[ f(z) = (z-1)^2h(z) \]
		for some holomorphic function $ h $ that is non-vanishing close to $ z=-1 $. So
		\[ g(z) = f(z)/(z+1)^2 = h(z). \]
		The residue of $ g(z) $ at $ z=-1 $ is zero. However, for $ f(z)/(z+1)^3 $ we can write
		\[ f(z)/(z+1)^3 = h(z)/(z+1). \]
		The residue of this function at $ z =-1 $ is calculated by
		\[ \lim_{z\to -1}(z+1)h(z)/(z+1) = h(-1). \]
		To calculate $ h(-1) $ observe that 
		\[ f''(z)  = 2h(z) + \text{other terms with factor $ (z-1) $}. \]
		So we will have $ f''(-1) = 2h(-1) = i/2 $. So $ h(-1) = i/4 $. So the residue of the function above at $ z = -1 $ is $ i/4 $.
		\item See the remark below. {\color{red} \noindent TODO: Final answer to be added.}
	\end{enumerate}
\end{solution}
\begin{remark}
	I was not able to solve the problem. But I have a feeling that I need to use the Cauchy's estimate for the $ n $-th derivative for some appropriate chosen radius $ R $
	\[ \abs{f^{(n)}(z)} \leq \frac{n!}{R^n}M, \qquad M = \sup_{z\in C}\abs{f(z)}, \]
	where $ C $ is a disk centered at $ z $ with radius $ R $.
\end{remark}


\section{September 2022}
\begin{problem}
	Find the shortest distance from $ x $ to $ U = \operatorname{span}\set{u_1,u_2} \subseteq \R^4 $ where 
	\[ u_1 = \begin{bmatrix}
		1 \\ 1 \\ 1 \\ 1 
	\end{bmatrix},\qquad
	u_2 = \begin{bmatrix}
		2 \\ 0 \\ 2 \\ 0 
	\end{bmatrix}, \qquad
	x = \begin{bmatrix}
		1 \\ 1 \\ 1 \\ 0
	\end{bmatrix}.
	 \]
\end{problem}
\begin{solution}
	First, we form a matrix that its column spaces is the same as $ U $. I.e.
	\[ A = \begin{bmatrix}
		1 & 2 \\
		1 & 0 \\
		1 & 2 \\
		1 & 0
	\end{bmatrix}. \]
	We can write $ x = x_{U} + x_\perp $. Since $ x_{U} $ is in the column space, then $ \exists c\in U $ such that $ A c = x_{U} $. However, by definition we know that $ x_\perp $ is in $ U_\perp $. Thus it belongs to the null space of $ A^T $. I.e. $ A^T x_\perp = 0 $. We can write $ A^T (x - x_U) = A^T(x- Ac) = 0 $.
	\[ A^T A c= A^T x. \]
	This is the systems of equations
	\[ \begin{bmatrix}
		4 & 4 \\
		4 & 8
	\end{bmatrix}
	\begin{bmatrix}
		c_1 \\ c_2 
	\end{bmatrix}
	= \begin{bmatrix}
		3 \\ 4
	\end{bmatrix} \]
	By manipulating the augmented matrix we find that 
	\[ c_1 = 1/2, \qquad c_2 = 1/4. \]
	So 
	\[ x_U = Ac = \frac{1}{2}\begin{bmatrix}
		2 \\ 1 \\ 2 \\1 
	\end{bmatrix}, \]
	and
	\[ x_\perp = \frac{1}{2}\begin{bmatrix}
		0 \\ 1 \\ 0 \\ -1
	\end{bmatrix}. \]
	So the shortest distance from $ x $ to $ U $ is
	\[ \norm{x_\perp} = \frac{\sqrt{2}}{2}. \]	
\end{solution}

\begin{problem}
	Let $ A $ be a real $ 3\times 3 $ matrix and suppose that the vectors
	\[ v_1 = \begin{bmatrix}
		1 \\ 1 \\ 0
	\end{bmatrix}, \qquad
	v_2 = \begin{bmatrix}
		1 \\ 2 \\ 0
	\end{bmatrix}, \qquad
	v_3 = \begin{bmatrix}
		2 \\ 1 \\ 0
	\end{bmatrix}, \qquad
	v_4 = \begin{bmatrix}
		0 \\ 0 \\ 1
	\end{bmatrix}, \]
	are the eigenvectors of $ A $. Show that $ A $ is symmetric.
\end{problem}

\begin{solution}
	Denote the corresponding eigenvalues as $ \lambda_1,\lambda_2,\lambda_3 $, and $ \lambda_4 $. Observe that $ v_1,v_2,v_3 $ are linearly dependent. Because 
	\[ v_1 = \frac{v_2+v_3}{3}. \]
	We can write $ v_1 = av_2 + bv_3 $ for some $ a=b=1/3 $ for simplicity. So we will have
	\[ Av_2 = \lambda_2 v_2, \quad Av_3 = \lambda_3 v_3, \quad \lambda_1 v_1 = Av_1= A(av_1+bv_2) = a\lambda_1 v_1 + b\lambda_2v_2. \]
	This implies that
	\[ \lambda_1 = \lambda_2 = \lambda_3. \]
	So we observe that the $ xy $ plane is an eigenspace for this matrix with eigenvalue $ \lambda $ and any vector in the plane is an eigenvector. This suggests that the restriction of $ A $ to the $ xy $ plane acts as a multiplication. So $ A $ will have the following structure
	\[ A = \begin{pmatrix}
		\mu & 0 & 0 \\
		0 & \mu & 0 \\
		0 & 0 & \lambda_4
	\end{pmatrix} \]
	where $ \mu = \lambda_1 = \lambda_2 = \lambda_3 $. So $ A $ is a symmetric matrix.
\end{solution}

\begin{problem}
	Recall the matrix norm $ \norm{A} = \sup_{x\neq 0} \frac{\norm{A x}}{\norm{x}} $.
	\begin{enumerate}[(a)]
		\item Let $ A $ be an $ n\times n $ real matrix with eigenvalues $ \lambda_1,\dots,\lambda_n $, and singular values $ \sigma_1 ,\dots, \sigma_n $. What is $ \norm{A} $? Justify your answer.
		\item Determine the matrix norm $ \norm{A} $ for the matrix 
		\[ A = \frac{1}{\sqrt{2}} \matt{1}{-1}{1}{1}\matt{6}{0}{0}{5} \matt{0}{1}{-1}{0} \matt{4}{0}{0}{2}. \]
	\end{enumerate}
\end{problem}



