\chapter{September 2023}


\section{Algebra}

\begin{problem}
	\begin{enumerate}[(a)]
		\item Prove that any module over $ \Z[i] $ is a direct sum of a free module and a torsion module. Is the same true for modules over $ \Z[\sqrt{-5}] $?
		\item Let $ I = 3+2i $ be the ideal in $ \Z[i] $ generated by the element $ 3+2i $. Describe the quotient $ \Z[i]/I $.
	\end{enumerate}
\end{problem}


\section{Linear Algebra}
\begin{problem}
	\begin{enumerate}[(a)]
		\item Find a lower triangular matrix $ L $ such that $ LL^T = A $, where 
		\[ A = \begin{pmatrix}
			1 & 1 & 0 & 2 \\
			1 & 5 & 2 & 2 \\
			0 & 2 & 2 & 1 \\
			2 & 2 & 1 & 6
		\end{pmatrix} \]
		\item Compute $ \det(A) $.
		
		\item Find the volume in $ \R^4 $ of the set $ S_A = \set{x\in \R^4: x^T A x \leq 1}.  $
	\end{enumerate}
\end{problem}


\begin{solution}
	\begin{enumerate}[(a)]
		\item Let $ L $ be
		\[ L = \begin{pmatrix}
			l_{11} & 0 & 0 & 0 \\
			l_{21} & l_{22} & 0 & 0 \\
			l_{31} & l_{32} & l_{33} & 0 \\
			l_{41} & l_{42} & l_{43} & l_{44} \\
		\end{pmatrix} \]
		So $ A = LL^T $ we will have
		\[ A = \begin{pmatrix}
			l_{11}^2 & l_{11}l_{21} & l_{11}l_{31} & l_{11}l_{41} \\
			l_{11}l_{21} & l_{21}^2 + l_{22}^2 & l_{21}l_{31} + l_{22}l_{32} & l_{21}l_{41} + l_{22}l_{42} \\
			l_{11}l_{31} & l_{31}l_{21} + l_{32}l_{22} & l_{31}^2 + l_{32}^2 + l_{33}^2 & l_{31}l_{41} + l_{32}l_{42} + l_{33}l_{43} \\
			l_{41}l_{11} & l_{41}l_{21} + l_{42}l_{22} & l_{41}l_{31} + l_{42}l_{32} + l_{43}l_{33} & l_{41}^2 + l_{42}^2 + l_{43}^2 + l_{44}^2
		\end{pmatrix}  \]
		By solving the equations formed by the first row we have
		\[ l_{11} = 1,\ l_{21} = 1,\ l_{31}=0,\ l_{41} = 2. \]
		Furthermore
		\[ l_{22} = 2,\ l_{32} = 1,\ l_{33}=1, \]
		and lastly
		\[ l_{42} = 0, l_{43} = 1, l_{44} = 1. \]
		So the matrix $ L $ will be
		\[ L = \begin{pmatrix}
			1 & 0 & 0 & 0 \\
			1 & 2 & 0 & 0 \\
			0 & 1 & 1 & 0 \\
			2 & 0 & 1 & 1
		\end{pmatrix} \]
		
		\item We will expand relative to the last column as it has more zeros.
		\[ \det(L) = \det\begin{pmatrix}
			1 & 0 & 0 \\
			1 & 2 & 0 \\
			0 & 1 & 1 
		\end{pmatrix}. \]
		Again, expanding relative to the last column we will have
		\[ \det(L) = \det\begin{pmatrix}
			1 & 0 \\
			1 & 2
		\end{pmatrix} = 2. \]
		
		\item First, we find a suitable linear transformation that can map the volume to another volume for which we know how to calculate its volume. Consider the linear transformation $ x = L^{-T}  y $. Since $ x^T A x = (y^T \inv{L}) L L^T (L^{-T}x) = y^T y $, thus the set $ x^T A x \leq 1  $ will be mapped to the 4-ball (4 dimensional ball). So its volume will be
		\[ \abs{x^T A x \leq 1} = \det(L) \abs{y^T y \leq 1} = 2 \abs{S^4}. \]
		(Note: The volume of the 4-ball is $ \pi^2/2 $.)
	\end{enumerate}
\end{solution}



\begin{problem}
	Let $ P_n $ be the $ n+1 $-dimensional space of polynomials of degree $ n $ with real coefficients, and let $ <\cdot,\cdot> $ be the inner product defined as
	\[ <p,q> = \int_{-1}^{1} p(x)q(x)\ dx. \]
	\begin{enumerate}[(a)]
		\item Find an orthogonal basis $ \set{u_0, u_1, u_2} $ for $ P_2 $ such that $ u_j \in P_j $, and $ u_j(1) > 0 $.
		\item Using the basis in part (a), express the operator $ F[p] := \int_{-1}^{1} p(x) dx $ acting on $ P_2 $ as a $ 1\times 3 $ matrix. 
		\item Using the basis in part (a), express the derivative operator $ D[p]:= \frac{d}{dx}p(x) $ as a $ 3\times 3 $ matrix. 
	\end{enumerate}
\end{problem}
\begin{solution}
	\begin{enumerate}[(a)]
		\item We start with the Gram-Schmidt orthogonalization. Let $ \set{c,x,x^2} $ be the basis vectors that we want to orthogonalize. Let $ u_0 = c $. Then the first vector will be $ \hat{u}_0 = u_0/\norm{u_0} = 1/\sqrt{2}  $. To find the second vector we have
		\[ u_1 = x - <x,\hat{u}_0>\hat{u}_0 = x - \frac{1}{2}\int_{-1}^{1}x\ dx  = x. \]
		So the second normal vector will be $ \hat{u}_1 = u_1 / \norm{u_1} = \sqrt{\frac{3}{2}}x. $ To find the third vector we have
		\begin{align*}
			u_2 &= x^2 - (<x^2,\hat{u}_0>\hat{u}_0 + <x^2,\hat{u}_1>\hat{u}_1) \\
			&= x^2 - (\frac{1}{2}\int_{-1}^{1}x^2 dx + \frac{3}{2}\int_{-1}^{1}x^3 dx)  \\
			&= x^2 - (1/3 + 0) = x^2 - 1/3.
		\end{align*}
		So the third normal vector will be $ \hat{u}_2 = u_2 / \norm{u_2} = 3/2\sqrt{\frac{5}{2}}(x^2 - 1/3) $. However, since the question has not asked for normal basis vectors, for the following sections of the question we will use the following orthogonal (not orthonormal) basis vectors
		\[ u_1 = 1,\quad u_1 = x,\quad u_2 = x^2 - \frac{1}{3}. \]
		
		\item It is enough to see what is the effect of this operator on the basis vectors
		\[ F[u_0] = \int_{-1}^{1} 1 dx = 2, \quad F[u_1] = \int_{-1}^{1} x dx = 0,\quad F[u_2] = \int_{-1}^{1} (x^2 - 1/3)dx = 2/3 - 2/3 = 0. \]
		So the matrix representation of this operator will be
		\[ F = \begin{pmatrix}
			2 & 0 & 0
		\end{pmatrix}. \]
		
		\item Similarly to the solution above, 
		\[ D[u_0] = 0, \quad D[u_1] = 1, D[u_2] = 2x, \]
		so the matrix representation will be 
		\[ D = \begin{pmatrix}
			0 & 1 & 0 \\
			0 & 0 & 2 \\
			0 & 0 & 0
		\end{pmatrix} \]
	\end{enumerate}
\end{solution}

\begin{problem}
	Recall that an orthogonal projection matrix is a matrix $ P $ that satisfies 
	\[ P^2 = P, \quad P = P^T. \]
	Suppose $ P $ is an $ n\times n $ projection matrix with $ \rank(P) = k $. In the following, $ I_m $ denotes the $ m\times m $ identity matrix. 
	
	\begin{enumerate}[(a)]
		\item List all the eigenvalues of $ P $, including multiplicity. Be sure to justify your reasoning.
		\item Show that $ P = AA^T $ for some $ n\times k $ matrix $ A $ such that $ A^TA = I_k $.
		\item Suppose $ P_1, P_2 $ are two $ n\times n $ projection matrices with rank $ k $. Show that there exists an $ n\times n $ orthonormal matrix $ U $ (i.e. such that $ U^T U = I_n, UU^T = I_n$) such that $ P_2 = UP_1 U^T $.
	\end{enumerate}
\end{problem}
\begin{solution}
	\begin{enumerate}[(a)]
		\item The projection matrix $ P $ has only two eigenvalues $ \lambda_1 = 1 $ and $ \lambda_2 = 0 $. The eigenvectors corresponding to $ \lambda_2 $ eigenvalue are the basis vectors of the null-space of $ P $ (that has dimension $ n - k $), and the eigenvectors corresponding to $ \lambda_1 $ are the basis vectors of the orthogonal sub-space to the null space of $ P $. Thus $ \lambda_2 $ has multiplicity $ n-k $ and $ \lambda_1 $ has multiplicity $ k $. 
		
		\item Since $ P $ is symmetric, then we can choose the eigenvectors to form an orthogonal basis. Let $ U = [U_1\ U_2] $ be the matrix that its columns are the eigenvectors and $ U_1 $ are the one with eigenvalue 1 while $ U_2 $ are the one with eigenvalue 0. Note that since the columns in $ U $ are orthogonal, then $ \inv{U} = U^T $. Let $ D $ be the diagonal matrix of $ P $, then we can write
		\[ P = U D U^T = [U_1\ U_2] \matt{I_k}{0}{0}{0} \vectt{U_1^T}{U_2^T} = U_1 U_1^T. \]
		Note that $ U_1^T U_1  = I_k$ since $ U $ is orthogonal matrix.
		
		\item From part (b) we know that there are matrices $ A_1, A_2 $ such that 
		\[ P_1 = A_1A_1^T,\qquad P_2 = A_2A_2^T. \]
		Define $ U = A_1A_2^T $. Then
		\[ P_1 = A_1A_1^T = A_1 (A_2^TA_2 A_2^T A_2) A_1^T = (A_1A_2^T) A_2A_2^T (A_2A_1^T) = U P_2 U^T. \]
	\end{enumerate}
\end{solution}


\section{Real Analysis}
\begin{problem}
	Let $ S $ be the part of the paraboloid $ z = 2 - x^2 - y^2 $ above the cone $ z = \sqrt{x^2+y^2} $, with upward orientation. Let
	\[ F = (\tan\sqrt{z}) + \sin(y^3) \hat{i} + e^{-x^2} \hat{j} + z \hat{k}. \]
	Evaluate the flux integral $ \iint_S F\cdot dS.\ $
\end{problem}


\begin{problem}
	Let $ f(x) = \sum_{n=1}^{\infty}\sin(nx)x^n$ for those $ x $ for which the series converges. Note that this is NOT a power series. 
	\begin{enumerate}[(a)]
		\item Show that $ f $ is defined and continuous on $ (-1,1) $.
		\item Shoat the $ f $ is differentiable and that $ f' $ is continuous on $ (-1,1) $.
	\end{enumerate}
\end{problem}
\begin{solution}
	\begin{enumerate}[(a)]
		\item We use the Weierstrass M-test to show that the series converges uniformally on $ (-1,1) $. To see this let $ r \in (0,1) $. Then on $ [-r,r] $ we have $ \abs{\sin(nx)x^n} \leq r^n $. Since $ \sum r^n < \infty $ (by the geometric series) then by Weierstrass M-test the series $ \sum_n \sin(nx)x^n $ converges on $ [-r,r] $ uniformly and absolutely for all $ r\in (0,1) $. This implies uniform and absolute converges on $ (-1,1) $. To show the continuity of the series, observe that $ \sin(nx)x^n $ is continuous for all $ n $. Thus this continuity carries over through the uniform converges. 
		
		\item First, observe that each term in the sum is continuously differentiable. Denote the $ n $-th term by $ f_n(x) $, then we will have
		\[ f_n(x) = n\cos(nx)x^n + nx^{n-1}\sin(nx) = nx^{n-1} (x\cos(nx) + \sin(nx)). \]
		For $ x \in (-1,1) $, the term inside the parenthesis will be
		\[ \abs{x\cos nx + \sin nx} \leq \abs{x}\abs{\cos nx} + \abs{\sin nx} \leq 2. \]
		Let $ r \in (0,1) $ and $ x \in [-r,r] $, then we will have 
		\[ nx^{n-1} \leq nr^{n-1} \quad \forall x \in [-r,r]. \]
		Observe that the series $\sum_n nr^{n-1} $ converges for $ r\in (-1,1) $ (you can see this easily by the ratio test). So for $ r\in (0,1) $
		\[ f_k(x) \leq M_k  \qquad \forall x\in (-r,r). \]
		for some $ M_k > 0 $ (to be precise $ M_k = 2kr^{k-1} $) where $ \sum_k M_k < \infty $. So by the Weierstrass M-test $ \sum_k f'_k(x) $ converges uniformly on any compact subset $ [-r,r] $ for $ r\in (0,1) $, and because each term is continuous, the $ f' $ is also continuous on $ (-1,1) $. So far have observed that $ \sum_k f_k(x) $ converges on compact subsets of $ (-1,1) $, $ \sum_k f'_k(x) $ converges on compact subsets of $ (-1,1) $, and $ f_k $ is continuously differentiable. So we can do a term by term differentiation. 
	\end{enumerate}
\end{solution}
