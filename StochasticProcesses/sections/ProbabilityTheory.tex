\chapter{Probability Theory}

%\section[Fundamental Concepts]{\hyperlink{toc}{Fundamental Concepts}}
\section{Foundamentals}

The main concept in the field of statistics and probability is the set theory. Basically all we deal with the sets. The whole theroy of statistics can be built on that. Let's discuss some foundamental concepts in statistics and then build the theory.

\subsection{Random Experiment}
To understand the meaning of random experiment, do not over think! The first thing that comes into our minds when we hear the word "random experiment" is its definition! In a nutshell, random experiment is an experiment that its outcome is unkown to us. Like:

\begin{itemize}
	\item Tossing two coin
	\item Rolling a dice
	\item Measuring the number of possible ReadWrite operations on a piece of EEPROM chip
\end{itemize}

Do not overthink about that. Yes we can go further and discuss stuff like "we can compute the exact movement of dice or coin so it is not random but determenistic" and etc. Here I will not touch the philosophical topics that are very deep and do not necessarily converge the a unified point of view!

The random experiments can be modeled and despite the fact that a random experiment is random, we can deduce many useful information from modeling that. To model a random experiment, we use three important concepts: sample space, events, probability. In the following section, we will discuss each of them in detail.


\subsection{Sample Space}

\begin{definition}[Sample Space]
	
	Sample space $\Omega$ is simply a set that contains \emph{all possible outcomes} of a random experiment/
	
\end{definition}

For each of random experiments described above, we can define a sample space. For example:

\begin{itemize}
	\item $\Omega$ of Tossing Tow Coins: $$\Omega = \{ HH,HT,TH,TT \}$$
	\item $\Omega$ of Rolling a Dice: $$\Omega = \{ 1,2,3,4,5,6 \}$$
	\item $\Omega$ of Rolling Two Dices: $$\Omega = \{ (1,1),(1,2), \ldots, (1,6), \ldots ,(6,6)  \}$$
	\item $\Omega$ of Number of possible ReadWrite operations on a EEPROM chip: $$\Omega = \mathbb{N}$$
\end{itemize}



\subsection{Events}
\begin{definition}[Events]
	Event $E$ is a set of outcomes of a random experiment and is the subset of sample space $\Omega$. 
	$$E \in \Omega$$
\end{definition}


For example for any of the sample spaces specified above, we can define so many possible events. In fact any set that is a subset of the sample space is a valid event of that sample space. For example:

\begin{itemize}
	
	\item Tossing Three Coins
	\begin{itemize}
		\item There are at least on Heads: $$E = \{ HHH,HHT,HTH,THH,HTT,THT,TTH \}$$
		\item There are only two Tails: $$E = \{ TTH,THT,HTT \}$$
	\end{itemize}
	
	\item Rolling Two Dices
	\begin{itemize}
		\item The sum of two dices is 4: $$E = \{ (1,3),(2,2),(3,1) \}$$
		\item there are at least one prime number in the outcome:
		$$E = \{ (1,2),(1,3),(1,5),(2,1),(3,1),(5,1),(2,2),(2,3),(2,5), \ldots ,(5,5)\}$$
	\end{itemize}
	
\end{itemize}

Since we have define everything on the basics of set theory, then now we can correspond the everyday concepts to specific operations in the set theory.

\begin{example}{The Mapping Between Everyday Language and Sets in the Theory of Probability}
	
	\begin{itemize}
		\item At least one of two events $A,B \in \Omega$ happens: $E = A \cup B$.
		\item Tow events $A,B \in \Omega$ occures at the same time: $E = A \cap B$.
		\item Event $A \in \Omega$ does not happen: $E = \overline{A} = \Omega - A$.
		\item The event $A$ happens but $B$ does not happen: $E = A - B$.
		
	\end{itemize}
	
\end{example}



In probability and statistics, we are dealing with three important concepts: sample space $\Omega$, event $E$, and probability $P$.


\begin{definition}[Disjoint events]
	
	If two events has no common elements (i.e. $A \cap B = \varnothing$) then we say that two events are \emph{disjoint}. Basically, if two sets in the venn diagram has nothing is common they are considerent to be disjoint sets.
	
	
	For example for the random experiment of tossing two coins, the events 1) both coins are heads: $A = \{HH\}$ and 2) both coins are tails: $B = \{TT\}$. Two events $A,B$  are two disjoint events. \textbf{Two events being  disjoing is NOT the same as being independent}. We will talk about independet events in future.
	
\end{definition}

Note that since the events are basically sets, we can use theorems of set theory to solve the problems. 

\begin{theorem}[De Morgan's Laws]
	
	If $A,B$ are two sets then:
	
	$$\overline{A \cap B} = \overline{A} \cup \overline{B}$$
	
	$$\overline{A \cup B} = \overline{A} \cap \overline{B}$$
	
\end{theorem}

\begin{proof}
	the proof is left as an excerise!
\end{proof}


\subsection{Probability}

The last foundamental ingeridient in modeling a random experiment, is to define a probability for each event. The probability should intuitively reflect how likely an event is probable to happen. This probability should satisfy some foundamental properties which are explained as follows.

\begin{definition}[Axioms of probability (Kolmogorov axioms)]
	
	Suppose that $A, B \in \Omega$ is an event and $\mathbb{P}$ is a probability function. Then $\prob$ should satisfy the following properites:
	
	\begin{enumerate}
		
		\item $ 0 \leq \prob(A) \leq 1$
		\item $\prob(\Omega) = 1$
		\item For the events $E_1, E_2, ..., E_n \in \Omega$ that are mutually exclusive (i.e. disjoint events): $$\prob(\bigcup_{i} E_i) = \sum_i \prob(E_i)$$
	\end{enumerate}
	
	
\end{definition}



These axioms are called the foundamental axioms of probability and also the Kolmogorov axioms. We are free to define any kind of probabilty function that we want but it is important that 1) It should align with our common sense, 2) It should satisfy the Kolmogorov axioms. 

Using the axioms above, we can observe and prove several interesting properties of the probability function. In the following box we have expressed some of them.

\begin{theorem}[Basic Properties of the Probability Function]
	
	Suppose that $\prob$ is a probability function and $A,B \in \Omega$ are events of the sample space $\Omega$. We can show that the probability function has the following properties:
	
	\begin{enumerate}
		
		\item $\prob(\varnothing) = 0$
		
		\item If $A \subset B$ then $\prob(A) \leq \prob(B)$.
		
		\item $\prob(\overline{A}) = 1 - \prob(A)$.
		
		\item $\prob(A \cup B) = \prob(A) + \prob(B) - \prob(A \cap B)$.
		
	\end{enumerate}
	
\end{theorem}


\begin{proof}
	The properties can be proved using the basic set theory theorems.
	
	\begin{enumerate}
		
		\item Since $\emptyset$ is the complement of $\Omega$, so these two sets are disjoint (i.e. $\emptyset \cap \Omega = \emptyset$). On the other hand from the set theory we know that $\emptyset \cup \Omega = \Omega$. So $\prob(\emptyset \cup \Omega) = \prob(\Omega)$. On the other hand, using the third axiom we can write: $\prob(\emptyset \cup \Omega) = \prob(\emptyset) + \prob(\Omega)$. Comparing the two recent equations we can conclude that $\prob(\emptyset) = 0$.
		
		
		
	\end{enumerate}
	
	
	
	The proofs for 2,3,4 are left as a exercise. However, the solutions can be found in the book "Statistical Modeling and Computation by Kroese" chapter 1. 
	
	
\end{proof}



\begin{example}[Defining a simple probability function]
	
	Let's define a probability function for the rolling n dice experiment that is both aligned with our common sense and also satisfy the Kolmogorov equations. Suppose that the $\Omega$ is the sample space and $E \in \Omega$ is an event. Then let's define:
	
	$$\prob(E) = \frac{\lvert E \rvert}{\lvert \Omega \rvert}$$
	
	in which the $\lvert E \rvert$ means the cardinality (number of elements) of the set $E$.
	
\end{example}

\subsection{Isomorphism between random experiments}
Often, there is this intuition that certain random experiments are really the same, although they might look very different from each other. For instance, consider two random experiments. In one, we are playing a dice successively and asking what is the probability that after 5 plays, 1 is not appeared. The second experiment is that we have 6 Urns and we place balls in them successively, i.e. at each step one ball is placed in one of the urns and the chance of a ball to end up in any of the urns in equal. These two experiment, although very different, but looks very similar. There is one way that we can formalize this wage intuition, and that is the notion of isomorphism between sets. We say two sets are isomorphic if there is a bijection between them. And the reason that the previously mentioned experiments feel the same is that the sample space $\Omega$ of these two experiments are in fact isomorphic. 

\section{Random Variables}
Often, we are interested in the some measurements of the outcome of a random experiment rather than knowing the outcome it self. For instance, if the experiment of tossing two dice, we might be interested in asking the question if the sum of two dice is 6, and not concerned over whether the actual outcome was (3,3) or (2,4), etc. These quantities of interest are called random variables. The following definition put this into a more formal definition.

\begin{definition}
	Let $(\Omega, E, \prob)$ be a probability space. Then a random variable $X$ is a function $X: \Omega \to S$, where $S$ called the state space.
\end{definition}

\begin{remark}
	The state space $S$ must have some properties, i.e. being measurable, etc. You can read more about this on the Wikipedia of random variables. Also, the state space $S$ if often $\R$, or in the case of a discrete time Markov chain, $S$ is a finite set (that can be the edge set of a graph).
\end{remark}

Since the value of a random variable is determined by the outcomes of the random experiment, we can assign probabilities to the possible values of the random variable. We use the following notation for this purpose.

\begin{definition}[Notation for probability of random variables]
	Let $X$ be a random variable. Then we define event 
	\[ E = \set{X = a} = \set{\omega \in \Omega: X(\omega) = a}. \]
	Then the following notations are usually used interchangeably:
	\[ \prob(X=a) = \prob(\set{X=a})  \]
	both of which is simply $\prob(E)$.
\end{definition}

\begin{example}
	Let $X$ be a random variable defined to be the sum of two fair dice. Then 
	\begin{align*}
		&\prob(\set{X =2}) = \prob(\set{(1,1)}) = \frac{1}{36},\\
		&\prob(\set{X=3}) = \prob(\set{(1,2),(2,1)}) = \frac{2}{36},\\
		&\prob(\set{X=13}) = \prob(\emptyset) = 0.
	\end{align*}
\end{example}

\begin{example}
	Suppose that we toss a coin having probability $p$ of coming up heads. We continue tossing the coin until we see a heads. Let the random variable $N$ be the number of times we toss the coin. Describe this random variable.
	
	\begin{solution}
		Although, we can always solve this kind of questions in an ad hoc way by just simply following our intuition, but it is always a best practice to try to fine tune our abstract thinking with our intuitive understandings in these kind of example. Then we can use of abstract thinking capability to solve problems that are almost impossible to address by solely depending on the intuition. So, it is a good idea to try to see how does the set $\Omega$ look like. The set $\Omega$ will be the set of all finite string of all $T$ letters terminated with $H$. In other words
		\[ \Omega = \set{H,TH, TTH, TTTH, TTTTH, \cdots}. \]
		Then the random variable $N: \Omega \to \Z$ is basically the length of the string. For instance, if $\omega = TTH \in \Omega$, then $N(\omega) = 3$. Let's calculate
		\[ \prob(N = 3) = \prob(\set{\omega \in \Omega: N(\omega) = 3}). \]
		To solve this, we need to define appropriate events and then condition our probability on those events. Define $F_n$ be the event where the $n$ first outcomes are tails. For instance
		\[ F_1 = \set{TH, TTH, TTTH,\cdots},\ F_2 = \set{TTH, TTTH, TTTTH, \cdots},\ \cdots.\]
		And let $E = \set{N=3} = \set{TTH}$. Then we can condition $\prob(E)$ on $F_2$ 
		\[ \prob(E) = \prob(E|F_2) \prob(F_2) + \prob(E|F_2^c) \prob(F_2^c). \]
		Note that $F_2^c = \set{H, TH}$, this $\prob(E|F_2^c) = \prob(E \cap F_2^c)/\prob(F_2^c) = 0$. Now we need to determine $\prob(F_2)$. Again, we can condition this event on $F_1$. Then we can write
		\[ \prob(F_2) = \prob(F_2|F_1)\prob(F_1) + \prob(F_2|F_1^c) \prob(F_1^c). \]
		with the same argument as above $\prob(F_2|F_1^c) = 0$. Combining these equations we will get
		\[ \prob(E) = \prob(E|F_2) \prob(F_2|F_1) \prob(F_1). \]
		Now these probabilities are easy to calculate which leads to the final answer
		\[ \prob(E) = (1-p)(1-p) p.  \]
		And by induction we can conclude
		\[ \prob(\set{N = n}) = (1-p)^n p.  \]
	\end{solution}
\end{example}


\begin{example}
	Suppose that independent trials, each of which results in $m$ possible outcomes with respective probabilities $p_1, p_2, \hdots,p_m$ such that $\sum_{i=1}^{m}p_i = 1$. Are continually performed. Let $X$ be the number of trials needed until each outcome has occurred at least once. Describe the properties of this random variable.
	\begin{solution}
		It is sometime a good idea to try to imagine what does the sample space look like. Let $\Sigma=\set{s_1, s_2, s_3, \hdots, s_m}$ be a set of $m$ distinct symbols. Then each time we are continually performing the experiment, we are getting each of these symbols with corresponding probability $p_m$. Thus the sample space will be the set of all infinite sequences of these symbols. In other words
		\[ \Omega = \set{\text{all infinite sequence of symbols from $\Sigma$}}. \]
		Then the random number $X(\omega)$ for $\omega \in \Omega$ is basically the length of the prefix string of $\omega$ in which any of the symbols in $\Sigma$ has been occurred at least once. 
	\end{solution}
\end{example}

\subsection{Cumulative Distribution of Random Variable}
The notion of the cumulative distribution of a random variable comes handy in most of the future calculations. Also, this distribution can be used to derive other notions of distributions what are extremely important in applications. 

\begin{definition}[Cumulative distribution]
	Let $X$ be a random variable $X:\Omega \to \R$. Then the cumulative distrubition $F: \R \to \R$ is defined as
	\[ F(x) = \prob(\set{X \leq x}).  \]
\end{definition}

\begin{proposition}
	The cumulative distribution of a random variable has the following properties.
	\begin{enumerate}[(i),itemsep=0pt, topsep=5pt]
		\item $\prob(a<X\leq b) = F(b) - F(a).$
		\item $F(x)$ is a non-decreasing function of $x$.
	\end{enumerate}
\end{proposition}
\begin{proof}
	\begin{enumerate}[(i)]
		\item 
		\[ \prob(\set{a<X\leq b}) = \prob(\set{X\leq b} \cap \set{X\leq a}^c) = -\prob(\Omega) + \prob(\set{X\leq b}) + \underbrace{\prob(\set{X\leq a}^c)}_{1-\prob(\set{X\leq a})} = F(b) - F(a).  \]
		\item Let $b_1, b_2 \in \R$ and $b_1 \leq b_2$. Then $\set{X\leq b_1} \subseteq \set{X\leq b_2}$. This implies $$\prob(\set{X\leq b_1}) \leq \prob(\set{X\leq b_2}) \implies F(b_1) \leq F(b_2).$$
		This implies that $F(x)$ is a non-decreasing function. 
	\end{enumerate}
\end{proof}


\section{Probability Generating Function}
In this section we will go through the details of the probability generating function. We start with the following definition.

\begin{definition}[Probability Generating Function]
	Let $ X $ be a random variable with state space $ S = \Z_+ $. Then the probability generating function for this random variable is a function define as
	\[  G_X(s) = \E{s^X} = \sum_{x \in S}s^x \prob(X=x).  \]
\end{definition}

In different areas of mathematics, we often can define something algebraic that is very easy to handle (like differentiation, etc) and carries the important information of the object under study. One of these algebraic symbolic objects is the Tutte polynomial, Chromatic polynomial, matching polynomial, etc. These polynomials are kind of modeling the object under study with tools that are easy to handle. The probability generating function is one of those symbolic objects. Because of the way that is crafted, it carries most of the information about the random variable, while the actual object as a function might have poor properties. This will be more clear in the following proposition. In a nutshell, the probability generating function is more of a symbolic thing rather than actual function with meaning full properties. That is why we generally evaluate this function (and its derivatives) at point 0 or 1. 


\begin{proposition}[Properties of the probability generating function]
	Let $ X $ be a random variable, and $ G_X(s) $ its probability generating function. Then we have
	\begin{enumerate}[(i)]
		\item $ G_X(1) = 1 $.
		\item $ \E{X} = G_X'(1)  $.
		\item $ \var{X} = G_X''(1) - G_X'(1)^2 + G_X'(1) $
		\item Let $X, Y$ be independent random variables. Then we have
		\[  G_{X+Y}(s) = G_X(s) G_Y(s). \]
		\item Let $ X_1, X_2, \cdots $ be iid random variables, and $ N $ be a random variable taking values in $ \Z_+ $. Define $ T = X_1 + X_2 + \cdots + X_N $. Then we have
		\[ G_T(s) = (G_N \circ G_{X_1})(s). \]
	\end{enumerate}
\end{proposition}

\begin{proof}
	The proof for part i,ii, iii, and iv basically follows immediately from the definition. So we will only provide the proof for part iv.\\
	$ T $ is the sum of $ N $ iid random variables where $ N $ is itself a random variable. We can make it a normal variable by using the law of total probabilities.
	\[ G_T(s) = G_{\sum_i^N X_i}(s) = \sum_{n=0}^{\infty}  G_{\sum_i^n X_i}(s) \prob(N = n)  = \sum_{n=0}^{\infty}(G_{X_1})^n\prob(N=n) = G_N(G_{X_1})(s) \]
	and this completes the proof.
\end{proof}

The item (iv) in the proposition above is very important, as it makes the hard calculations easy to do. See the following example for more details.

\begin{example}
	We select a number $ N $ from $ \set{1,2,3,\cdots,100} $ randomly and then generate $ N $ random numbers $ X_1, X_2, \cdots X_N $ from the distribution $ \operatorname{Unif}[0,1]$. Then we compute $ T = X_1 + X_2 + \cdots +X_N $. What is the average of $ T $? 
	
	\begin{solution}
		We know that 
		\[ \E{T} = G'_T(1). \]
		Thus we need to calculate the probability generating function $ G_T(s) $. From part (iv) of the proposition above we know that $ G_T = G_N \circ G_{X_1} $. Thus we will have
		\[ G'_T = G_{X_1}' G_N'\circ G_{X_1}.  \]
		Thus evaluating at $ s=1 $ we will have
		\[ G'_T(1) = G_{X_1}'(1) G_N'(\underbrace{G_{X_1}(1)}_{1}) = \E{X_1} \E{N}. \]
		On the other hand we have $ \E{N} = 50 $ and $ \E{X_1} = 1/2 $. Then 
		\[ \E{T} = 25. \]
 	\end{solution}
\end{example}

