\chapter{Ordinary Differential Equations}

\section{Introduction}

Let's start by studying the following first order differential equation for $u$
\[ u' + mu = f, \tag{1}\]
where $m\in \R$ and $f:\R\to\R$ is a continuous function. In fact, we are trying to find a function that its derivative plus some constant times the function itself produces the function $f$. One way to tackle this problem is to multiply both sides by $e^{mx}$. Then, we will get
\[ e^{mx}u' + mue^{mx} = f e^{mx},\quad x\in \R. \]
Now the trick is to do a similar thing as completing the square in algebra, with only difference that we are aiming at completing the derivative. In other words
\[ (e^{mx} u(x))' = f(x)e^{mx}, \quad x\in\R. \]
Now by integrating both sides (or, equivalently, using the fundamental theorem of calculus) we will get
\[ e^{mx}u(x) - u(0) = \int_{0}^{x}f(s)e^{ms} ds. \]
By a little rearrangement of the terms we will get
\[ u(x) = ce^{-mx} + \int_{0}^{1}f(s)e^{m(s-x)}ds, \quad c \in \R \]
Now we can see that on only there is one function that satisfies that particular relation imposed by the differential equation, there is in fact a continuum of functions satisfying the differential equations that are parameterized by $c\in \R$. It turns out that the set of all such functions, as a set, has some very interesting properties. Let's call this set $\mathcal{A}$. As we discussed above, the elements of this set is parameterized by $c\in\R$. We can also specify this set as
\begin{equation*}
	\mathcal{A} = \set{u\ |\ u(x)=ce^{-mx} + \int_{0}^{x}f(s)e^{m(s-x)}ds\ \forall c\in \R}
\end{equation*}

\textbf{Note that we will assume that the function $f$ is Lipschitz continuous. Then we will be sure that all of the possible solutions of the ODE above are in set $\mathcal{A}$}. Studying this set more closely, reveals the fact that this set is actually a linear space, or, a vector space. This is true since
\begin{enumerate}
	\setlength\itemsep{0em}
	\item [(A1)] $u,v\in \mathcal{A} \implies u+v = v+u \in \mathcal{A}$.
	\item [(A2)] $\forall u,v,r \in \mathcal{A} \wh u+(v+r) = v+(u+r).$
	\item [(A3)] $\mathcal{O} \in \mathcal{A}$ such that $v+\mathcal{O} = \mathcal{O} + v = v$ for all $v\in \mathcal{A}$.
	\item [(A4)] $\forall v\in \mathcal{A},\ \exists u \in \mathcal{A} \st v + u = u + v = \mathcal{O}.$	
	\item []
	\item [(M1)] $\forall v \in \mathcal{A} \wh \mathcal{I}\cdot v = v\cdot \mathcal{I} = v$.
	\item [(M2)] $\forall v \in \mathcal{A} \wh \mathcal{O}\cdot v = v\cdot \mathcal{O} = \mathcal{O}$
	\item [(M3)] $\forall v\in \mathcal{A},\ a,b \in \R \wh a(bv) = (ab)v$ 
	\item []
	\item [(D1)] $\forall u,v\in \mathcal{A},\ a\in \R \wh a(u+v) = au + av.$
	\item [(D2)] $\forall u \in \mathcal{A},\ a,b\in \R \wh (a+b)u = au + bu. $
\end{enumerate}
\begin{proof}
	All of the properties of this set follows immediately from the fact that $\R$ is a vector space. To see this, see the following proof for (A1).
	Let $u,v \in \mathcal{A}$. Then $\exists c_1, c_2 \in \R$ such that 
	\[ u(x) = c_1e^{-mx} + \int_{0}^{x}f(s)e^{m(s-x)}ds, \quad v(x) = c_2e^{-mx} + \int_{0}^{x}f(s)e^{m(s-x)}ds. \]
	Thus 
	\[ (u+v)(x) = (c_1+c_2)e^{-mx} + \int_{0}^{x}f(s)e^{m(s-x)}ds. \]
	Since $c_1 + c_2 \in \R$, then $u+v \in \mathcal{A}$.
\end{proof}

So far, we have fined a set of functions $\mathcal{A}$ that solves the differential equation. However, now, we can ask for more requirement. For instance, we can ask for functions that satisfy certain initial conditions, i.e. $u(0) = u_0$. Or we can ask for functions that are defined on some interval, say $[0,1]$ that satisfy certain boundary conditions like $u(0) + u'(1) = 3$, or $u(0) = u(1)$, etc. For the case of specifying an initial condition, say $x(0) = x_0$, we can find a unique $x\in \mathcal{A}$ that solves the ODE and satisfies this initial value problem (choose $x\in \mathcal{A}$ that has $c= x_0$).


\begin{beCareful}
	Consider the following initial value problem
	\[ \dot{x} = x^{2/3}, \qquad x(0) = 0. \]
	Then at any open interval that the function $x(t)$ does not take the value 0, we can write the ODE as
	\[ \frac{\dot{x}}{x^{2/3}} = 1.  \]
	Now by integration we get the set of all solutions of the ODE 
	\[ \mathcal{A} = \set{x:[a,b]\to \R\ :\ x(t)=(\frac{x+c}{3})^3,\ x(t)\neq 0\ \forall t\in [a,b]}. \]
	Clearly, the constant solution $x(t)\equiv 0$ doe not belong to the set $\mathcal{A}$. However, we can easily verify that $x(t)\equiv 0$ is a solution to the initial value problem. So when the function $f$ is not descent enough (not Lipschitz continues in this case), then the set $\mathcal{A}$ does not contain all of the solutions for the initial value problem. So in conclusion, the initial value problem has two solutions $x(t) = t^3/3$ that belongs to $\mathcal{A}$ and $x(t) \equiv 0$ which is not in $\mathcal{A}$.\\
	However, if the function  $f$ (RHS of the initial value problem) is Lipschitz continuous, then by the Picard iteration argument we can show that there is always a unique solution that can be achieved by the integration\footnote{see the chapter 1 of the book "Ordinary Differential Equations: Qualitative Theory" by Barreira.}. 
\end{beCareful}

However, in the case of specifying boundary conditions (boundary condition problems), like demanding $u(0)=u(1)$ the situation is not as clear as the initial value problem. Given that the RHS function is Lipschitz continuous and all of the solutions of the ODE lives in the set $\mathcal{A}$, then our task is basically look for functions in $\mathcal{A}$ (which is basically isomorphic to $\R$) to see which of them satisfy the boundary condition. Then we might find no solutions, or a unique solution, or more than one solution (note the similarity with finding the solutions of a linear system $AX=B$ that based on the characterizations of the matrix $A$ we might have different scenarios for the solutions.)

Back to our example above, we find that the solutions of 
\[ u' + mu = f\] 
are all in the set
\begin{equation*}
	\mathcal{A} = \set{u\ |\ u(x)=ce^{-mx} + \int_{0}^{x}f(s)e^{m(s-x)}ds\ \forall c\in \R}
\end{equation*}
So we can determine which functions in $\mathcal{A}$ satisfies our boundary condition. This leads to the following equation
\[ c  = ce^{-m} + \int_{0}^{1}f(s)e^{m(s-1)}\ ds, \]
which implies
\[ \boxed{c = \frac{1}{1-e^{-m}}\int_{0}^{1}e^{m(s-1)}f(s)\ ds, \qquad m\neq 0}. \]
Thus when $m\neq 0$, we have a unique function in $\mathcal{A}$ that satisfies the boundary condition. However, when $m=0$, then the above equation does not make sense. Then the function $u\in \mathcal{A}$ where
\[ u(x) = c+  \int_{0}^{x}f(s)\ ds. \]
To satisfy the boundary condition, we need to have
\[ u(0) = u(1) \implies c = c+\int_{0}^{1}f(s) ds \implies \boxed{\int_{0}^{1}f(s)\ ds = 0}. \]
So in the case where $m=0$, if $\int_{0}^{1}f(s)ds=0$, then we have infinitely many solutions for the boundary value problem. But if $\int_{0}^{1}f(s)ds \neq 0$, then there is no solutions for the boundary value problem.

\begin{summary}
	Consider the following ODE
	\[ u' + mu = f. \]
	where $f$ is Lipschitz continuous. Then the set of all solutions to this ODE is 
	\[ 	\mathcal{A} = \left\{u\ |\ u(x)=ce^{-mx} + \int_{0}^{x}f(s)e^{m(s-x)}ds\ \forall c\in \R \right\}.\]
	Then for any initial value $u(0) = u_0$, we can find a unique $u\in\mathcal{A}$ that satisfies the initial value problem ($c=u_0$). However, for the boundary value problem $u(0)=u(1)$ we will have the following cases
	\begin{itemize}
		\item $m\neq 0$. Then there is a unique $u\in\mathcal{A}$ where
		\[ c = \frac{1}{1-e^{-m}}\int_{0}^{1}e^{m(s-1)}f(s)\ ds \]
		\item $m =0$. Then there are two cases
		\begin{itemize}
			\item $\int_{0}^{1}f(s)ds = 0$. We will have infinite number of solutions $\forall c\in R$ for the BVP.
			\item $\int_{0}^{1}f(s)ds \neq 0$. We will have no solutions for BVP.
		\end{itemize}
	\end{itemize}
\end{summary}

We can think about the boundary value problem in a more systematic way. First note that all the functions $u:[0,1]\to\R$ that satisfies the boundary condition $u(0) = u(1)$ for a vector space (easy to check). Thus we can think about our boundary value condition in the following way
\begin{quote}
	Let $\mathcal{B} = {u:\mathcal{C}^1([0,1],\R): u(0) = u(1) }$ be a Banach space. This is a linear space equipped with the norm $\norm{u} = \max\set{\norm{u}_\infty, \norm{u'}_\infty}$ (thus $\mathcal{B}$ is a Hilbert space). Let $Y = \mathcal{C}([0,1],\R)$ equipped with the suprimum norm. Consider for any $m\in \R$, the linear operator $L_m:X\to Y$ define as $L_mu =u'+mu$. Given any $f \in Y$ find those $u \in \mathcal{B}$ such that $L_m u = f.$
\end{quote}
If we have a unique solution, then we can write $u = \inv{L_m}f$ where $\inv{L_m}$ is the inverse operator of $L_m$. So the uniqueness of the solution is the question invertibility of the operator $L_m$. This operator is the inverse of a differential operator, thus it is an integral operator. For the specific example that we solved above, we can easily calculate this integral operator. This inverse operator exists if we have a unique solution. So we will consider the boundary value problem we solved above when $m \neq 0$. Then we know that 
\[ u(x) = ce^{-mx} + \int_{0}^{x} e^{m(s-x)}f(s)\ ds, \qquad c = \frac{1}{1-e^{-m}}\int_{0}^{1}e^{m(s-1)}f(s)ds.  \]
By substituting the value of $c$ we can write
\[  u(x) = \frac{e^{-mx}}{1-e^{-m}}\int_{0}^{1}e^{m(s-1)}f(s)\ ds  + \int_{0}^{x} e^{m(s-x)}f(s)\ ds \]
To merge the integrals into a single integral, we write 
\[  u(x) = \frac{e^{-mx}}{1-e^{-m}}\int_{0}^{1}e^{m(s-1)}f(s)\ ds  + \int_{0}^{1} H(s,x)e^{m(s-x)}f(s)\ ds \]
where $H(s,x)$ is step function with $H(s,x) = 1$ when $s< x$ and $H(s,x) = 0$ when $x<s$. Then we can write the integral above as
\[ u(x) = \int_{0}^{1}G(s,x)f(s)\ ds = \inv{L_m}f(t),\qquad
G(s,x) = \frac{1}{1-e^{-m}}\begin{cases}
	e^{m(s-x)} \quad 0<s< x<1, \\
	e^{m(s-x-1)} \quad 0<x<s<1.
\end{cases}
 \]
thus for this specific boundary value problem we have
\[ \boxed{\inv{L_m}f(t) = \int_{0}^{1} G(s,x) f(s)\ ds}. \] 
The function $G$ is called the Green's function. The Green's function can give us the exact solution of certain boundary value problems, but the most important thing about the Green's function is that it contains lots of analytic and quantitative information about the solution that we can utilize even before solving the integral\footnote{To see some of these quantitative information from the Green's function see page 4 of "Greens function in the theory of ordinary differential equations" by  Alberto Cabada.}.


\section{Construction of Green's function}
Consider the following $n$ dimensional boundary value problem
\[ x(t)' = A(t) x(t) + f(t), \]
with the boundary condition
\[ Bx(a) + Cx(b) = h, \]
where $n \in \N$, $a,b \in \R$ that $a<b$, $A \in \mathscr{L}^1(J,\mathscr{M}_{n\times n})$, $f \in \mathscr{L}^1(J,\R^n)$, $B,C \in \mathscr{M_{n\times n}}$, $h \in \R^n$, and $x \in \mathscr{AC}(J,\R^n)$. As usual, we denote by  $\mathscr{L}^1$ the set of all Lebesgue integrable function on $J$ and by $\mathscr{AC}(J,\R^n)$ the set of absolutely continuous functions on $J$.

\section{Sturm-Liouville theory}


